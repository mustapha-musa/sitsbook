<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Improving the Quality of Training Samples | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes</title>
<meta name="author" content="Gilberto Camara">
<meta name="author" content="Rolf Simoes">
<meta name="author" content="Felipe Souza">
<meta name="author" content="Charlotte Pelletier">
<meta name="author" content="Alber Sanchez">
<meta name="author" content="Pedro Ribeiro Andrade">
<meta name="author" content="Karine Ferreira">
<meta name="author" content="Gilberto Queiroz">
<meta name="description" content="Selecting good training samples for machine learning classification of satellite images is critical to achieving accurate results. Experience with machine learning methods has demonstrated that...">
<meta name="generator" content="bookdown 0.32 with bs4_book()">
<meta property="og:title" content="Improving the Quality of Training Samples | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes">
<meta property="og:type" content="book">
<meta property="og:image" content="/images/cover_sits_book.png">
<meta property="og:description" content="Selecting good training samples for machine learning classification of satellite images is critical to achieving accurate results. Experience with machine learning methods has demonstrated that...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Improving the Quality of Training Samples | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes">
<meta name="twitter:description" content="Selecting good training samples for machine learning classification of satellite images is critical to achieving accurate results. Experience with machine learning methods has demonstrated that...">
<meta name="twitter:image" content="/images/cover_sits_book.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/IBM_Plex_Serif-0.4.4/font.css" rel="stylesheet">
<link href="libs/IBM_Plex_Mono-0.4.4/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""><strong>sits</strong>: Satellite Image Time Series Analysis on Earth Observation Data Cubes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="setup.html">Setup</a></li>
<li><a class="" href="acknowledgements.html">Acknowledgements</a></li>
<li><a class="" href="introduction-to-sits.html">Introduction to SITS</a></li>
<li><a class="" href="earth-observation-data-cubes.html">Earth observation data cubes</a></li>
<li><a class="" href="operations-on-data-cubes.html">Operations on Data Cubes</a></li>
<li><a class="" href="working-with-time-series.html">Working with time series</a></li>
<li><a class="active" href="improving-the-quality-of-training-samples.html">Improving the Quality of Training Samples</a></li>
<li><a class="" href="machine-learning-for-data-cubes.html">Machine Learning for Data Cubes</a></li>
<li><a class="" href="image-classification-in-data-cubes.html">Image Classification in Data Cubes</a></li>
<li><a class="" href="validation-and-accuracy-measurements.html">Validation and accuracy measurements</a></li>
<li><a class="" href="uncertainty-and-active-learning.html">Uncertainty and active learning</a></li>
<li><a class="" href="ensemble-prediction-from-multiple-models.html">Ensemble Prediction from Multiple Models</a></li>
<li><a class="" href="visualising-and-exporting-data.html">Visualising and Exporting data</a></li>
<li><a class="" href="technical-annex.html">Technical Annex</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="improving-the-quality-of-training-samples" class="section level1 unnumbered">
<h1>Improving the Quality of Training Samples<a class="anchor" aria-label="anchor" href="#improving-the-quality-of-training-samples"><i class="fas fa-link"></i></a>
</h1>
<p>Selecting good training samples for machine learning classification of satellite images is critical to achieving accurate results. Experience with machine learning methods has demonstrated that the number and quality of training samples are critical factors in obtaining accurate results <span class="citation"><a href="references.html#ref-Maxwell2018" role="doc-biblioref">[26]</a></span>. Large and accurate datasets are preferable, regardless of the algorithm used, while noisy training samples can negatively impact classification performance <span class="citation"><a href="references.html#ref-Frenay2014" role="doc-biblioref">[27]</a></span>. Thus, it is beneficial to use pre-processing methods to improve the quality of samples and eliminate those that may have been incorrectly labeled or possess low discriminatory power.</p>
<p>One needs to distinguish between wrongly labelled samples and differences that result from natural variability of class signatures. When training data is collected over a large geographic region, natural variability of vegetation phenology leads to different patterns being assigned to the same label. A related issue is the limitation of crisp boundaries to describe the natural world. Class definitions use idealized descriptions (e.g., “a savanna woodland has tree cover of 50% to 90% ranging from 8 to 15 meters in height”). In practice, the boundaries between classes are fuzzy and sometimes overlap, making it hard to distinguish between them. To help users improve sample quality, <code>sits</code> provides methods for evaluate training data</p>
<div id="geographical-variability-of-training-samples" class="section level2 unnumbered">
<h2>Geographical variability of training samples<a class="anchor" aria-label="anchor" href="#geographical-variability-of-training-samples"><i class="fas fa-link"></i></a>
</h2>
<p>When working with machine learning classification of Earth observation data, it is important to evaluate if the training samples are well distributed in the study area. In many cases, training data comes from ground surveys made at chosen location. When working in large areas, ideally one needs a representative sample which captures spatial variability. In practice, however, ground surveys or other means of data collection are limited to selected areas. In many case, the geographical distribution of the training data does not cover the study area equally. Such mismatch can be a problem for achieving a good quality classification. As stated by Meyer and Pebesma<span class="citation"><a href="references.html#ref-Meyer2022" role="doc-biblioref">[28]</a></span>: “large gaps in geographic space do not always imply large gaps in feature space”.</p>
<p>Meyer and Pebesma<span class="citation"><a href="references.html#ref-Meyer2022" role="doc-biblioref">[28]</a></span> propose the use of spatial distance distribution plot, which display two distributions of nearest-neighbor distances: sample-to-sample and prediction-location-to-sample. The difference between the two distributions reflects the degree of spatial clustering in the reference data. Ideally, the two distributions should be similar. Cases where the sample-to-sample distance distribution does not match prediction-location-to-sample distribution indicate possible problems of training data collection.</p>
<p><code>sits</code> implements spatial distance distribution plots with the <code><a href="https://rdrr.io/pkg/sits/man/sits_geo_dist.html">sits_geo_dist()</a></code> function. This function asks users to provide their training data in the <code>samples</code> parameter, and the study area in the <code>roi</code> parameter expressed as an <code>sf</code> object. Additional parameters are <code>n</code> (maximum number of samples for each distribution) and <code>crs</code> (coordinate reference system for the samples). By default, <code>n</code> is 1000, and <code>crs</code> is “EPSG:4326”. The example below shows how to use <code><a href="https://rdrr.io/pkg/sits/man/sits_geo_dist.html">sits_geo_dist()</a></code>.</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># read a shapefile for the state of Mato Grosso, Brazil</span></span>
<span><span class="va">mt_shp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.file.html">system.file</a></span><span class="op">(</span><span class="st">"extdata/shapefiles/mato_grosso/mt.shp"</span>,</span>
<span>  package <span class="op">=</span> <span class="st">"sits"</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># convert to an sf object</span></span>
<span><span class="va">mt_sf</span> <span class="op">&lt;-</span> <span class="fu">sf</span><span class="fu">::</span><span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_read.html">read_sf</a></span><span class="op">(</span><span class="va">mt_shp</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate sample-to-sample and sample-to-prediction distances</span></span>
<span><span class="va">distances</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_geo_dist.html">sits_geo_dist</a></span><span class="op">(</span></span>
<span>  samples <span class="op">=</span> <span class="va">samples_modis_ndvi</span>,</span>
<span>  roi <span class="op">=</span> <span class="va">mt_sf</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># plot sample-to-sample and sample-to-prediction distances</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">distances</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-81"></span>
<img src="sitsbook_files/figure-html/unnamed-chunk-81-1.png" alt="SOM map for the Cerrado samples" width="100%"><p class="caption">
Figure 34: SOM map for the Cerrado samples
</p>
</div>
<p>The plot shows a mismatch between the sample-to-sample and the sample-to-prediction distribution. Most samples are closer to each other then they are close to the locatiom where values need to be predicted. In this case, there are many areas where few or no samples have been collected and where the prediction uncertainty will be higher. In this and similar cases, users should invest in improving the distribution of training samples. If that is not possible, they should be aware that areas with insufficient samples could have lower accuracy, and that fact should be reported to potential users of their results.</p>
</div>
<div id="hierachical-clustering-for-sample-quality-control" class="section level2 unnumbered">
<h2>Hierachical clustering for sample quality control<a class="anchor" aria-label="anchor" href="#hierachical-clustering-for-sample-quality-control"><i class="fas fa-link"></i></a>
</h2>
<p>The package provides two clustering methods to assess sample quality: (a) Agglomerative Hierarchical Clustering (AHC); (b) Self-organizing Maps (SOM). These methods have different computational complexities. AHC has a computational complexity of <span class="math inline">\(\mathcal{O}(n^2)\)</span> given the number of time series <span class="math inline">\(n\)</span>, whereas SOM complexity is linear with respect to n. For large data, AHC requires an substantial amount of memory and running time; in these cases, SOM is recommended. In this section, we describe how to run AHC in <code>sits</code>. The SOM-based technique is presented in the following section.</p>
<p>Agglomerative hierarchical clustering (AHC) computes the dissimilarity between any two elements from a data set. Depending on the distance functions and linkage criteria, the algorithm decides which two clusters are merged at each iteration. This approach is useful for exploring samples due to its visualization power and ease of use <span class="citation"><a href="references.html#ref-Keogh2003" role="doc-biblioref">[29]</a></span>. In <code>sits</code>, AHC is implemented using <code><a href="https://rdrr.io/pkg/sits/man/sits_clustering.html">sits_cluster_dendro()</a></code>.</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># take a set of patterns for 2 classes</span></span>
<span><span class="co"># create a dendrogram, plot, and get the optimal cluster based on ARI index</span></span>
<span><span class="va">clusters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_clustering.html">sits_cluster_dendro</a></span><span class="op">(</span></span>
<span>  samples <span class="op">=</span> <span class="va">cerrado_2classes</span>,</span>
<span>  bands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"NDVI"</span>, <span class="st">"EVI"</span><span class="op">)</span>,</span>
<span>  dist_method <span class="op">=</span> <span class="st">"dtw_basic"</span>,</span>
<span>  linkage <span class="op">=</span> <span class="st">"ward.D2"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-82"></span>
<img src="sitsbook_files/figure-html/unnamed-chunk-82-1.png" alt="Example of hierarchical clustering for a two class set of time series" width="90%"><p class="caption">
Figure 35: Example of hierarchical clustering for a two class set of time series
</p>
</div>
<p>The <code><a href="https://rdrr.io/pkg/sits/man/sits_clustering.html">sits_cluster_dendro()</a></code> function has one mandatory parameter (<code>samples</code>), where users should provide the samples to be evaluated. Optional parameters include <code>bands</code>, <code>dist_method</code> and <code>linkage</code>. The <code>dist_method</code> parameter specifies how to calculate the distance between two time series. We recommend a metric that uses dynamic time warping (DTW)<span class="citation"><a href="references.html#ref-Petitjean2012" role="doc-biblioref">[30]</a></span>, as DTW is reliable method for measuring differences between satellite image time series <span class="citation"><a href="references.html#ref-Maus2016" role="doc-biblioref">[31]</a></span>. The options available in <code>sits</code> are based on those provided by package <code>dtwclust</code>, which include <code>dtw_basic</code>, <code>dtw_lb</code>, and <code>dtw2</code>. Please check <code><a href="https://rdrr.io/pkg/dtwclust/man/tsclust.html">?dtwclust::tsclust</a></code> for more information on DTW distances.</p>
<p>The <code>linkage</code> parameter defines the distance metric between clusters. The recommended linkage criteria are: <code>complete</code> or <code>ward.D2</code>. Complete linkage prioritizes the within-cluster dissimilarities, producing clusters with shorter distance samples, but results are sensitive to outliers. As an alternative, Ward proposes to use the sum-of-squares error to minimize data variance <span class="citation"><a href="references.html#ref-Ward1963" role="doc-biblioref">[32]</a></span>; his method is available as <code>ward.D2</code> option to the <code>linkage</code> parameter. To cut the dendrogram, the <code><a href="https://rdrr.io/pkg/sits/man/sits_clustering.html">sits_cluster_dendro()</a></code> function computes the adjusted rand index (ARI) <span class="citation"><a href="references.html#ref-Rand1971" role="doc-biblioref">[33]</a></span> and returns the height where the cut of the dendrogram maximizes the index . In the example, the ARI index indicates that six (6) clusters are present. The result of <code><a href="https://rdrr.io/pkg/sits/man/sits_clustering.html">sits_cluster_dendro()</a></code> is a time series tibble with one additional column, called “cluster”. The function <code><a href="https://rdrr.io/pkg/sits/man/sits_cluster_frequency.html">sits_cluster_frequency()</a></code> provides information on the composition of each cluster.</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># show clusters samples frequency</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_cluster_frequency.html">sits_cluster_frequency</a></span><span class="op">(</span><span class="va">clusters</span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt;          
#&gt;             1   2   3   4   5   6 Total
#&gt;   Cerrado 203  13  23  80   1  80   400
#&gt;   Pasture   2 176  28   0 140   0   346
#&gt;   Total   205 189  51  80 141  80   746</code></pre>
<p>The cluster frequency table shows that each cluster has a predominance of either “Cerrado” or “Pasture” class with the exception of cluster 3 which has a mix of samples from both classes. Such confusion may have resulted from incorrect labeling, inadequacy of selected bands and spatial resolution, or even a natural confusion due to the variability of the land classes. To remove cluster 3, use <code><a href="https://dplyr.tidyverse.org/reference/filter.html">dplyr::filter()</a></code>. The resulting clusters still contained mixed labels, possibly resulting from outliers. In this case, users may want to remove the outliers and leave only the most frequent class using <code><a href="https://rdrr.io/pkg/sits/man/sits_cluster_clean.html">sits_cluster_clean()</a></code>. After cleaning the samples, the result set of samples is likely to improve the classification results.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># remove cluster 3 from the samples</span></span>
<span><span class="va">clusters_new</span> <span class="op">&lt;-</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">clusters</span>, <span class="va">cluster</span> <span class="op">!=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co"># clear clusters, leaving only the majority class</span></span>
<span><span class="va">clean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_cluster_clean.html">sits_cluster_clean</a></span><span class="op">(</span><span class="va">clusters_new</span><span class="op">)</span></span>
<span><span class="co"># show clusters samples frequency</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_cluster_frequency.html">sits_cluster_frequency</a></span><span class="op">(</span><span class="va">clean</span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt;          
#&gt;             1   2   4   5   6 Total
#&gt;   Cerrado 203   0  80   0  80   363
#&gt;   Pasture   0 176   0 140   0   316
#&gt;   Total   203 176  80 140  80   679</code></pre>
</div>
<div id="using-som-for-sample-quality-control" class="section level2 unnumbered">
<h2>Using SOM for sample quality control<a class="anchor" aria-label="anchor" href="#using-som-for-sample-quality-control"><i class="fas fa-link"></i></a>
</h2>
<p><a href="https://www.kaggle.com/esensing/using-som-for-sample-quality-control-in-sits" target="_blank"><img src="https://kaggle.com/static/images/open-in-kaggle.svg"></a></p>
<p>As an alternative for hierarchical clustering for quality control of training samples, SITS provides a clustering technique based on self-organizing maps (SOM). SOM is a dimensionality reduction technique <span class="citation"><a href="references.html#ref-Kohonen1990" role="doc-biblioref">[34]</a></span>, where high-dimensional data is mapped into a two dimensional map, keeping the topological relations between data patterns. As the shown below, the SOM 2D map is composed by units called neurons. Each neuron has a weight vector, with the same dimension as the training samples. At the start, neurons are assigned a small random value and then trained by competitive learning. The algorithm computes the distances of each member of the training set to all neurons and finds the neuron closest to the input, called the best matching unit.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-85"></span>
<img src="images/som_structure.png" alt="SOM 2D map creation (source: Santos et al.(2021). Reproduction under fair use doctrine." width="90%" height="90%"><p class="caption">
Figure 36: SOM 2D map creation (source: Santos et al.(2021). Reproduction under fair use doctrine.
</p>
</div>
<p>The input data for quality assessment is a set of training samples, which are high-dimensional data; for example, a time series with 25 instances of 4 spectral bands has 100 dimensions. When projecting a high-dimensional data set into a 2D SOM map, the units of the map (called neurons) compete for each sample. Each time series will be mapped to one of the neurons. Since the number of neurons is smaller than the number of classes, each neuron will be associated to many time series. The resulting 2D map will be a set of clusters. Given that SOM preserves the topological structure of neighborhoods in multiple dimensions, clusters that contain training samples of a given class will usually be neighbors in 2D space. The neighbors of each neuron of a SOM map provide information on intraclass and interclass variability which is used to detect noisy samples. The methodology of using SOM for sample quality assessment is discussed in detail in the reference paper <span class="citation"><a href="references.html#ref-Santos2021a" role="doc-biblioref">[35]</a></span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-86"></span>
<img src="images/methodology_bayes_som.png" alt="Using SOM for class noise reduction (source: Santos et al.(2021). Reproduction under fair use doctrine." width="90%" height="90%"><p class="caption">
Figure 37: Using SOM for class noise reduction (source: Santos et al.(2021). Reproduction under fair use doctrine.
</p>
</div>
<p>As an example, we take a set of time series from the Cerrado region of Brazil, the second largest biome in South America with an area of more than 2 million km2. This data ranges from 2000 to 2017 and includes 50,160 land use and cover samples divided into 12 classes(“Dense_Woodland”, “Dunes”, “Fallow_Cotton”, “Millet_Cotton”, “Pasture”, “Rocky_Savanna”, “Savanna”, “Savanna_Parkland”, “Silviculture”, “Soy_Corn”, “Soy_Cotton”, “Soy_Fallow”). Each time series covers 12 months (23 data points) from MOD13Q1 product, and has 4 bands (“EVI”, “NDVI”, “MIR”, and “NIR”). We use bands “NDVI” and “EVI” for faster processing.</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># take only the NDVI and EVI bands</span></span>
<span><span class="va">samples_cerrado_mod13q1_2bands</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_select.html">sits_select</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">samples_cerrado_mod13q1</span>,</span>
<span>  bands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"NDVI"</span>, <span class="st">"EVI"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># show the summary of the samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_labels_summary.html">sits_labels_summary</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">samples_cerrado_mod13q1_2bands</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt; # A tibble: 12 × 3
#&gt;    label            count    prop
#&gt;    &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt;
#&gt;  1 Dense_Woodland    9966 0.199  
#&gt;  2 Dunes              550 0.0110 
#&gt;  3 Fallow_Cotton      630 0.0126 
#&gt;  4 Millet_Cotton      316 0.00630
#&gt;  5 Pasture           7206 0.144  
#&gt;  6 Rocky_Savanna     8005 0.160  
#&gt;  7 Savanna           9172 0.183  
#&gt;  8 Savanna_Parkland  2699 0.0538 
#&gt;  9 Silviculture       423 0.00843
#&gt; 10 Soy_Corn          4971 0.0991 
#&gt; 11 Soy_Cotton        4124 0.0822 
#&gt; 12 Soy_Fallow        2098 0.0418</code></pre>
</div>
<div id="creating-the-som-map" class="section level2 unnumbered">
<h2>Creating the SOM map<a class="anchor" aria-label="anchor" href="#creating-the-som-map"><i class="fas fa-link"></i></a>
</h2>
<p>To perform the SOM-based quality assessment, the first step is to run <code><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map()</a></code> which uses the <code>kohonen</code> R package <span class="citation"><a href="references.html#ref-Wehrens2018" role="doc-biblioref">[36]</a></span> to compute a SOM grid, controlled by five parameters. The grid size is given by <code>grid_xdim</code> and <code>grid_ydim</code>. The starting learning rate is <code>alpha</code>, which decreases during the interactions. To measure separation between samples, use <code>distance</code> (either “sumofsquares” or “euclidean”). The number of iterations is set by <code>rlen</code>. For more details, please consult <code><a href="https://rdrr.io/pkg/kohonen/man/supersom.html">?kohonen::supersom</a></code>.</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># clustering time series using SOM</span></span>
<span><span class="va">som_cluster</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map</a></span><span class="op">(</span><span class="va">samples_cerrado_mod13q1_2bands</span>,</span>
<span>  grid_xdim <span class="op">=</span> <span class="fl">15</span>,</span>
<span>  grid_ydim <span class="op">=</span> <span class="fl">15</span>,</span>
<span>  alpha <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span>  distance <span class="op">=</span> <span class="st">"euclidean"</span>,</span>
<span>  rlen <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># plot the som map</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">som_cluster</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-88"></span>
<img src="sitsbook_files/figure-html/unnamed-chunk-88-1.png" alt="SOM map for the Cerrado samples" width="100%"><p class="caption">
Figure 38: SOM map for the Cerrado samples
</p>
</div>
<p>The output of the <code><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map()</a></code> is a list with 3 elements: (a) the original set of time series with two additional columns for each time series: <code>id_sample</code> (the original id of each sample) and <code>id_neuron</code> (the id of the neuron to which it belongs); (b) a tibble with information on the neurons. For each neuron, it gives the prior and posterior probabilities of all labels which occur in the samples assigned to it; and (c) the SOM grid. To plot the SOM grid, use <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code>. The neurons are labelled using majority voting.</p>
<p>The SOM grid shows that most classes are associated to neurons close to each other. The are exceptions. Some “Pasture” neurons are far from the main cluster, because the transition between areas of open savanna and pasture is not always well defined and depends on climate and latitude. Also, the neurons associated to “Soy_Fallow” are dispersed in the map; this indicates possible problems in distinguishing this class from the other agricultural classes. The SOM map can be used to remove outliers, as shown below.</p>
</div>
<div id="measuring-confusion-between-labels-using-som" class="section level2 unnumbered">
<h2>Measuring confusion between labels using SOM<a class="anchor" aria-label="anchor" href="#measuring-confusion-between-labels-using-som"><i class="fas fa-link"></i></a>
</h2>
<p>The second step in SOM-based quality assessment is understanding the confusion between labels. The function <code><a href="https://rdrr.io/pkg/sits/man/sits_som_evaluate_cluster.html">sits_som_evaluate_cluster()</a></code> groups neurons by their majority label and produces a tibble. For each label, the tibble show the percentage of samples with a different label that have been mapped to a neuron whose majority is that label.</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># produce a tibble with a summary of the mixed labels</span></span>
<span><span class="va">som_eval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som_evaluate_cluster.html">sits_som_evaluate_cluster</a></span><span class="op">(</span><span class="va">som_cluster</span><span class="op">)</span></span>
<span><span class="co"># show the result</span></span>
<span><span class="va">som_eval</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt; # A tibble: 77 × 4
#&gt;    id_cluster cluster        class          mixture_percentage
#&gt;         &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;                       &lt;dbl&gt;
#&gt;  1          1 Dense_Woodland Dense_Woodland           80.9    
#&gt;  2          1 Dense_Woodland Pasture                   5.26   
#&gt;  3          1 Dense_Woodland Rocky_Savanna             7.15   
#&gt;  4          1 Dense_Woodland Savanna                   3.69   
#&gt;  5          1 Dense_Woodland Silviculture              2.95   
#&gt;  6          1 Dense_Woodland Soy_Corn                  0.00889
#&gt;  7          1 Dense_Woodland Soy_Fallow                0.00889
#&gt;  8          2 Dunes          Dunes                   100      
#&gt;  9          3 Fallow_Cotton  Fallow_Cotton            64.8    
#&gt; 10          3 Fallow_Cotton  Millet_Cotton             5.47   
#&gt; # … with 67 more rows</code></pre>
<p>Many labels are associated to clusters where there are some samples with a different label. Such confusion between labels arises because visual labeling of samples is subjective and can be biased. In many cases, interpreters use high-resolution data to identify samples. However, the actual images to be classified are captured by satellites with lower resolution. In our case study, a MOD13Q1 image has pixels with 250 x 250 meter resolution and as such the correspondence between labelled locations in high-resolution images and mid to low-resolution images is not direct. The confusion by class can be visualized in a bar plot using <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code>, as shown below. The bar plot shows some confusion between the classes associated to the natural vegetation typical of the Brazilian Cerrado (“Savanna”, “Savanna_Parkland”, “Rocky_Savanna”). This mixture is due to the large variability of the natural vegetation of the Cerrado biome, which makes it difficult to draw sharp boundaries between each label. Some confusion is also visible between the agricultural classes. The “Millet_Cotton” class is a particularly difficult one, since many of the samples assigned to this class are confused with “Soy_Cotton” and “Fallow_Cotton”.</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># plot the confusion between clusters</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">som_eval</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-90"></span>
<img src="sitsbook_files/figure-html/unnamed-chunk-90-1.png" alt="Confusion between classes as measured by SOM." width="90%"><p class="caption">
Figure 39: Confusion between classes as measured by SOM.
</p>
</div>
</div>
<div id="detecting-noisy-samples-using-som" class="section level2 unnumbered">
<h2>Detecting noisy samples using SOM<a class="anchor" aria-label="anchor" href="#detecting-noisy-samples-using-som"><i class="fas fa-link"></i></a>
</h2>
<p>The third step in the quality assessment uses the discrete probability distribution associated to each neuron, which is included in the <code>labelled_neurons</code> tibble produced by <code><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map()</a></code>. More homogeneous neurons (those with a single class of high probability) are assumed to be composed of good quality samples. Heterogeneous neurons (those with two or more classes with significant probability) are likely to contain noisy samples. The algorithm computes two values for each sample:</p>
<ul>
<li><p><em>prior probability</em>: the probability that the label assigned to the sample is correct, considering only the samples contained in the same neuron. For example, if a neuron has 20 samples, of which 15 are labeled as “Pasture” and 5 as “Forest”, all samples labeled “Forest” are assigned a prior probability of 25%. This is an indication that the “Forest” samples in this neuron may not be of good quality.</p></li>
<li><p><em>posterior probability</em>: the probability that the label assigned to the sample is correct, considering the neighboring neurons. Take the case of the above-mentioned neuron whose samples labeled “Pasture” have a prior probability of 75%. What happens if all the neighboring samples have “Forest” as a majority label? To answer this question, we use Bayesian inference to estimate if these samples are noisy based on the neighboring neurons <span class="citation"><a href="references.html#ref-Santos2021" role="doc-biblioref">[37]</a></span>. The Bayesian inference method, described in the Technical Annex, recalculates the class probabilities in a neuron, based in its neighbors.</p></li>
</ul>
<p>To identify noisy samples, we take the result of the <code><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map()</a></code> function as the first argument to the function <code><a href="https://rdrr.io/pkg/sits/man/sits_som_clean_samples.html">sits_som_clean_samples()</a></code>. This function finds out which samples are noisy, those that are clean, and some that need to be further examined by the user. It requires the <code>prior_threshold</code> and <code>posterior_threshold</code> parameters according to the following rules:</p>
<ul>
<li>If the prior probability of a sample is less than <code>prior_threshold</code>, the sample is assumed to be noisy and tagged as “remove”;</li>
<li>If the prior probability is greater or equal to <code>prior_threshold</code> and the posterior probability calculated by Bayesian inference is greater or equal to <code>posterior_threshold</code>, the sample is assumed not to be noisy and thus is tagged as “clean”;</li>
<li>If the prior probability is greater or equal to <code>prior_threshold</code> and the posterior probability is less than <code>posterior_threshold</code>, we have a situation the sample is part of the majority level of those assigned to its neuron, but its label is not consistent with most of its neighbors. This is an anomalous condition and is tagged as “analyze”. Users are encouraged to inspect such samples to find out whether they are in fact noisy or not.</li>
</ul>
<p>The default value for both <code>prior_threshold</code> and <code>posterior_threshold</code> is 60%. The <code><a href="https://rdrr.io/pkg/sits/man/sits_som_clean_samples.html">sits_som_clean_samples()</a></code> has an additional parameter (<code>keep</code>) which indicates which samples should be kept in the set based on their prior and posterior probabilities. The default for <code>keep</code> is <code>c("clean", "analyze")</code>. As a result of the cleaning, about 900 samples have been considered to be noisy and thus removed.</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som_clean_samples.html">sits_som_clean_samples</a></span><span class="op">(</span></span>
<span>  som_map <span class="op">=</span> <span class="va">som_cluster</span>,</span>
<span>  prior_threshold <span class="op">=</span> <span class="fl">0.6</span>,</span>
<span>  posterior_threshold <span class="op">=</span> <span class="fl">0.6</span>,</span>
<span>  keep <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"clean"</span>, <span class="st">"analyze"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># print the new sample distribution</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_labels_summary.html">sits_labels_summary</a></span><span class="op">(</span><span class="va">new_samples</span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt; # A tibble: 10 × 3
#&gt;    label            count    prop
#&gt;    &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt;
#&gt;  1 Dense_Woodland    8334 0.206  
#&gt;  2 Dunes              550 0.0136 
#&gt;  3 Fallow_Cotton      152 0.00375
#&gt;  4 Pasture           5743 0.142  
#&gt;  5 Rocky_Savanna     6603 0.163  
#&gt;  6 Savanna           7943 0.196  
#&gt;  7 Savanna_Parkland  2065 0.0510 
#&gt;  8 Soy_Corn          4227 0.104  
#&gt;  9 Soy_Cotton        3540 0.0874 
#&gt; 10 Soy_Fallow        1350 0.0333</code></pre>
<p>All samples of the class which had the highest confusion with others(“Millet_Cotton”) have been removed. Most samples of class “Silviculture” (planted forests) have also been removed, since in the SOM map they have been confused with natural forests and woodlands. Further analysis includes calculating the SOM map and confusion matrix for the new set, as shown in the following example.</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># evaluate the misture in the SOM clusters of new samples</span></span>
<span><span class="va">new_cluster</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">new_samples</span>,</span>
<span>  grid_xdim <span class="op">=</span> <span class="fl">15</span>,</span>
<span>  grid_ydim <span class="op">=</span> <span class="fl">15</span>,</span>
<span>  alpha <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span>  distance <span class="op">=</span> <span class="st">"euclidean"</span>,</span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_cluster_mixture</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som_evaluate_cluster.html">sits_som_evaluate_cluster</a></span><span class="op">(</span><span class="va">new_cluster</span><span class="op">)</span></span>
<span><span class="co"># plot the mixture information.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">new_cluster_mixture</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-93"></span>
<img src="sitsbook_files/figure-html/unnamed-chunk-93-1.png" alt="Cluster confusion plot for samples cleaned by SOM" width="90%"><p class="caption">
Figure 40: Cluster confusion plot for samples cleaned by SOM
</p>
</div>
<p>As expected, the new confusion map shows a significant improvement over the previous one. This result should be interpreted carefully, since it may be due to different effects. The most direct interpretation is that “Millet_Cotton” and “Silviculture” cannot be easily separated from the other classes, given the current attributes (a time series of “NDVI” and “EVI” indices from MODIS images). In such situations, users should consider improving the number of samples from the less represented classes, including more MODIS bands, or working with higher resolution satellites. Results of the SOM method should be interpreted based on the users’ understanding of the ecosystems and agricultural practices of the study region.</p>
<p>A further comparison between the original and clean samples is to run a 5-fold validation on the original and on the cleaned sample sets using <code><a href="https://rdrr.io/pkg/sits/man/sits_kfold_validate.html">sits_kfold_validate()</a></code> and a random forests model. The SOM procedure improves the validation results from 95% on the original data set to 99% in the cleaned one. This improvement should not be interpreted as providing better fit for the final map accuracy. A 5-fold validation procedure only measures how well the machine learning model fits the samples; it is not an accuracy assessment of classification results. The result only indicates that the resulting training set after the SOM sample removal procedure is more internally consistent than the original one. For more details on accuracy measures, please see chapter on “Validation and Accuracy Measures”.</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># run a k-fold validation</span></span>
<span><span class="va">assess_orig</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_kfold_validate.html">sits_kfold_validate</a></span><span class="op">(</span></span>
<span>  samples <span class="op">=</span> <span class="va">samples_cerrado_mod13q1_2bands</span>,</span>
<span>  folds <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  ml_method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_rfor.html">sits_rfor</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># print summary</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_accuracy_summary.html">sits_accuracy_summary</a></span><span class="op">(</span><span class="va">assess_orig</span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt; Overall Statistics                          
#&gt;  Accuracy : 0.945         
#&gt;    95% CI : (0.943, 0.947)
#&gt;     Kappa : 0.936</code></pre>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">assess_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_kfold_validate.html">sits_kfold_validate</a></span><span class="op">(</span></span>
<span>  samples <span class="op">=</span> <span class="va">new_samples</span>,</span>
<span>  folds <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  ml_method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_rfor.html">sits_rfor</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># print summary</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_accuracy_summary.html">sits_accuracy_summary</a></span><span class="op">(</span><span class="va">assess_new</span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt; Overall Statistics                          
#&gt;  Accuracy : 0.99          
#&gt;    95% CI : (0.989, 0.991)
#&gt;     Kappa : 0.989</code></pre>
<p>The SOM-based analysis discards samples which can be confused with samples of other classes. After removing noisy samples or uncertain classes, the data set obtains a better validation score since there is less confusion between classes. Users should analyse the results with care. Not all discarded samples are low quality ones. Confusion between samples of different classes can result from inconsistent labeling or from the lack of capacity of satellite data to distinguish between chosen classes. When many samples are discarded, as in the current example, it is advisable to revise the whole classification schema. The aim of selecting training data should always be to match the reality in the ground to the power of remote sensing data to identify differences. No analysis procedure can replace actual user experience and knowledge of the study region.</p>
</div>
<div id="reducing-sample-imbalance" class="section level2 unnumbered">
<h2>Reducing sample imbalance<a class="anchor" aria-label="anchor" href="#reducing-sample-imbalance"><i class="fas fa-link"></i></a>
</h2>
<p>Many training samples for Earth observation data analysis are imbalanced. This situation arises when the distribution of samples associated to each class is uneven. One example is the Cerrado data set used in this chapter. The three most frequent classes (“Dense Woodland”, “Savanna” and “Pasture”) include 53% of all samples, while the three least frequent classes (“Millet-Cotton”, “Silviculture”, and “Dunes”) comprise only 2.5% of the data set. Sample imbalance is an undesirable property of a training set. Since machine learning algorithms tend to be more accurate for classes with many samples. The instances belonging to the minority group are misclassified more often than those belonging to the majority group. Thus, reducing sample imbalance can have a positive effect on classification accuracy<span class="citation"><a href="references.html#ref-Johnson2019" role="doc-biblioref">[38]</a></span>.</p>
<p>The function <code><a href="https://rdrr.io/pkg/sits/man/sits_reduce_imbalance.html">sits_reduce_imbalance()</a></code> deals with class imbalance; it oversamples minority classes and undersamples majority ones. Oversampling requires generation of synthetic samples. The package uses the SMOTE method that estimates new samples by considering the cluster formed by the nearest neighbors of each minority class. SMOTE takes two samples from this cluster and produces a new one by a random interpolation between them <span class="citation"><a href="references.html#ref-Chawla2002" role="doc-biblioref">[39]</a></span>.</p>
<p>To perform undersampling, <code><a href="https://rdrr.io/pkg/sits/man/sits_reduce_imbalance.html">sits_reduce_imbalance()</a></code> builds a SOM map for each majority class, based on the required number of samples to be selected. Each dimension of the SOM is set to <code>ceiling(sqrt(new_number_samples/4))</code> to allow a reasonable number of neurons to group similar samples. After calculating the SOM map, the algorithm extracts four samples per neuron to generate a reduced set of samples that approximates the variation of the original one.</p>
<p>The <code><a href="https://rdrr.io/pkg/sits/man/sits_reduce_imbalance.html">sits_reduce_imbalance()</a></code> algorithm has two parameters: <code>n_samples_over</code> and <code>n_samples_under</code>. The first parameter ensures that all classes with samples less than its value are oversampled. The second parameter controls undersampling; all classes with more samples than its value are undersampled. The following example shows the use of <code><a href="https://rdrr.io/pkg/sits/man/sits_reduce_imbalance.html">sits_reduce_imbalance()</a></code> in the Cerrado data set used in this chapter. We generate a balanced data set where all classes have between 1000 and 1500 samples. We use <code><a href="https://rdrr.io/pkg/sits/man/sits_som_evaluate_cluster.html">sits_som_evaluate_cluster()</a></code> to estimate the confusion between classes of the balanced data set.</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># reducing imbalances in the Cerrado data set</span></span>
<span><span class="va">balanced_samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_reduce_imbalance.html">sits_reduce_imbalance</a></span><span class="op">(</span></span>
<span>  samples <span class="op">=</span> <span class="va">samples_cerrado_mod13q1_2bands</span>,</span>
<span>  n_samples_over <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  n_samples_under <span class="op">=</span> <span class="fl">1500</span>,</span>
<span>  multicores <span class="op">=</span> <span class="fl">4</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># print the balanced samples</span></span>
<span><span class="co"># some classes have more than 1500 samples due to the SOM map</span></span>
<span><span class="co"># each class has betwen 10% and 6% of the full set</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_labels_summary.html">sits_labels_summary</a></span><span class="op">(</span><span class="va">balanced_samples</span><span class="op">)</span></span></code></pre></div>
<pre class="sourceCode"><code>#&gt; # A tibble: 12 × 3
#&gt;    label            count   prop
#&gt;    &lt;chr&gt;            &lt;int&gt;  &lt;dbl&gt;
#&gt;  1 Dense_Woodland    1600 0.0966
#&gt;  2 Dunes             1000 0.0604
#&gt;  3 Fallow_Cotton     1000 0.0604
#&gt;  4 Millet_Cotton     1000 0.0604
#&gt;  5 Pasture           1600 0.0966
#&gt;  6 Rocky_Savanna     1480 0.0894
#&gt;  7 Savanna           1600 0.0966
#&gt;  8 Savanna_Parkland  1588 0.0959
#&gt;  9 Silviculture      1000 0.0604
#&gt; 10 Soy_Corn          1584 0.0957
#&gt; 11 Soy_Cotton        1580 0.0954
#&gt; 12 Soy_Fallow        1524 0.0921</code></pre>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># clustering time series using SOM</span></span>
<span><span class="va">som_cluster_bal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som.html">sits_som_map</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">balanced_samples</span>,</span>
<span>  grid_xdim <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  grid_ydim <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  alpha <span class="op">=</span> <span class="fl">1.0</span>,</span>
<span>  distance <span class="op">=</span> <span class="st">"euclidean"</span>,</span>
<span>  rlen <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># produce a tibble with a summary of the mixed labels</span></span>
<span><span class="va">som_eval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/sits/man/sits_som_evaluate_cluster.html">sits_som_evaluate_cluster</a></span><span class="op">(</span><span class="va">som_cluster_bal</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># show the result</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">som_eval</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-100"></span>
<img src="sitsbook_files/figure-html/unnamed-chunk-100-1.png" alt="Confusion by cluster for the balanced data set" width="90%"><p class="caption">
Figure 41: Confusion by cluster for the balanced data set
</p>
</div>
<p>As shown in the Figure, the balanced data set shows less confusion per class than the unbalanced one. In this case, many of the classes which were confused with other in the original confusion map are now better represented. Reducing class imbalance should be tried as an alternative to reducing the number of samples of the classes using SOM. In general, users should try to balance their training data for better performance.</p>
</div>
<div id="conclusion" class="section level2 unnumbered">
<h2>Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"><i class="fas fa-link"></i></a>
</h2>
<p>The quality of training data is critical to improve the accuracy of maps resulting from machine learning classification methods. To address this challenge, the <code>sits</code> package provides three methods for improving training samples. For large datasets, we recommend using both imbalance reducing and SOM-based algorithms. The SOM-based method identifies potential mislabeled samples and outliers that require further investigation. The results demonstrate a positive impact on the overall classification accuracy.</p>
<p>Users need to take care when defining their classification schema. The complexity and diversity of our planet defies simple class names with hard boundaries. Due to representational and data handling issues, all classification systems have a limited number of categories, which inevitably fail to properly describe the nuances of the planet’s landscapes. All representation systems are thus limited and application-dependent. As stated by Janowicz <span class="citation"><a href="references.html#ref-Janowicz2012" role="doc-biblioref">[40]</a></span>: “geographical concepts are situated and context-dependent and can be described from different, equally valid, points of view; thus, ontological commitments are arbitrary to a large extent”.</p>
<p>The availability of big data and satellite image time series is a further challenge. In principle, image time series can capture more subtle changes for land classification. In practice, experts need to conceive classification systems and training data collection by understanding how time series information relate to actual land change. Methods for quality analysis such as those presented in this chapter cannot replace user understanding and informed choices.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="working-with-time-series.html">Working with time series</a></div>
<div class="next"><a href="machine-learning-for-data-cubes.html">Machine Learning for Data Cubes</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#improving-the-quality-of-training-samples">Improving the Quality of Training Samples</a></li>
<li><a class="nav-link" href="#geographical-variability-of-training-samples">Geographical variability of training samples</a></li>
<li><a class="nav-link" href="#hierachical-clustering-for-sample-quality-control">Hierachical clustering for sample quality control</a></li>
<li><a class="nav-link" href="#using-som-for-sample-quality-control">Using SOM for sample quality control</a></li>
<li><a class="nav-link" href="#creating-the-som-map">Creating the SOM map</a></li>
<li><a class="nav-link" href="#measuring-confusion-between-labels-using-som">Measuring confusion between labels using SOM</a></li>
<li><a class="nav-link" href="#detecting-noisy-samples-using-som">Detecting noisy samples using SOM</a></li>
<li><a class="nav-link" href="#reducing-sample-imbalance">Reducing sample imbalance</a></li>
<li><a class="nav-link" href="#conclusion">Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><strong>sits</strong>: Satellite Image Time Series Analysis on Earth Observation Data Cubes</strong>" was written by Gilberto Camara, Rolf Simoes, Felipe Souza, Charlotte Pelletier, Alber Sanchez, Pedro Ribeiro Andrade, Karine Ferreira, Gilberto Queiroz. It was last built on 2023-03-06.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
