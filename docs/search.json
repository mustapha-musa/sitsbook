[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Satellite images provide key information Earth’s environment impacts caused human actions. Petabytes Earth observation data now open free, making full extent image archives available researchers experts. Remote sensing experts can now track environmental change using satellite image time series. Using image time series, analysts make best use full extent big Earth observation data collections, capturing subtle changes ecosystem health condition improving distinction different land classes.book introduces sits, open-source R package land use land cover classification big Earth observation data using satellite image time series. Users build regular data cubes cloud services Amazon Web Services, Microsoft Planetary Computer, Brazil Data Cube, Digital Earth Africa. sits API includes assessment training sample quality, machine learning deep learning classification algorithms, Bayesian post-processing methods smoothing uncertainty assessment. evaluate results, sits supports best practice accuracy assessments.","code":""},{"path":"index.html","id":"who-this-book-is-for","chapter":"Preface","heading":"Who this book is for","text":"target audience sits community remote sensing experts Earth Sciences background want use state---art data analysis methods minimal investment programming skills. package provides clear direct set functions, easy learn master. Users minimal background R programming can start using sits right away. yet familiar R need learn introductory concepts.R user like quickly master needed run sits, please read Parts 1 2 Garrett Golemund’s book, “Hands-Programming R”(https://rstudio-education.github.io/hopr/>). already R user like update skills latest trends, please read book Hadley Wickham Gareth Golemund, “R Data Science”. (https://r4ds..co.nz/). Important concepts spatial analysis presented Edzer Pebesma Roger Bivand book “Spatial Data Science” (https://r-spatial.org/book/).","code":""},{"path":"index.html","id":"software-version-described-in-this-book","chapter":"Preface","heading":"Software version described in this book","text":"version sits package described book version 1.3.0.","code":""},{"path":"index.html","id":"main-reference-for-sits","chapter":"Preface","heading":"Main reference for sits","text":"use sits work, please cite following paper:Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, Karine Ferreira. “Satellite Image Time Series Analysis Big Earth Observation Data”. Remote Sensing, 13, p. 2428, 2021. https://doi.org/10.3390/rs13132428.","code":""},{"path":"index.html","id":"intellectual-property-rights","chapter":"Preface","heading":"Intellectual property rights","text":"book licensed Attribution-NonCommercial-ShareAlike 4.0 International (CC -NC-SA 4.0) Creative Commons, described terms available https://creativecommons.org/licenses/-nc-sa/4.0/. sits package licensed GNU General Public License, version 3.0.","code":""},{"path":"setup.html","id":"setup","chapter":"Setup","heading":"Setup","text":"sits package relies sf terra R packages, turn require GDAL PROJ libraries. Please follow instructions installing sf terra together GDAL, provided Edzer Pebesma.","code":""},{"path":"setup.html","id":"support-for-gdal-and-proj","chapter":"Setup","heading":"Support for GDAL and PROJ","text":"","code":""},{"path":"setup.html","id":"windows-and-macos","chapter":"Setup","heading":"Windows and MacOS","text":"Windows MacOS users strongly encouraged install sf terra binary packages CRAN. install sits source, please install package Rtools access compiling environment.","code":""},{"path":"setup.html","id":"ubuntu","chapter":"Setup","heading":"Ubuntu","text":"Ubuntu versions 20.04 (focal) 22.04 (jammy), provide script fast installation, based work Dirk Eddelbuettel r2u project. script installs binary versions sits dependencies. requires R version 4.2.0 later. download script use:run script sudo:Alternatively, installation can done step--step. recommend using latest version GDAL, GEOS, PROJ4 libraries. , use repository ubuntugis-unstable, done follows:get error adding PPA repository, miss package software-properties-common. GDAL running docker containers, please add security flag --security-opt seccomp=unconfined start.","code":"wget https://raw.githubusercontent.com/e-sensing/sitsbook/master/utils/fast_sits_installation_ubuntu.shsudo sh fast_sits_installation_ubuntu.shsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install libudunits2-dev libgdal-dev libgeos-dev libproj-dev "},{"path":"setup.html","id":"debian","chapter":"Setup","heading":"Debian","text":"install Debian, use rocker geospatial dockerfiles.","code":""},{"path":"setup.html","id":"fedora","chapter":"Setup","heading":"Fedora","text":"following command installs required dependencies:","code":"sudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel"},{"path":"setup.html","id":"installing-the-sits-package","chapter":"Setup","heading":"Installing the sits package","text":"sits available CRAN installed R packages.source code repository GitHub https://github.com/e-sensing/sits. install development version sits, contains latest updates might unstable, users install devtools already available, install sits follows:run examples book, please also install “sitsdata” package.","code":"\ninstall.packages(\"sits\")\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sits@dev\", dependencies = TRUE)\noptions(download.file.method = \"wget\")\ndevtools::install_github(\"e-sensing/sitsdata\")"},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"","code":""},{"path":"acknowledgements.html","id":"funding-sources","chapter":"Acknowledgements","heading":"Funding Sources","text":"authors acknowledge funders supported development sits:Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology Space Applications (FUNCATE), establishment Brazil Data Cube,Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology Space Applications (FUNCATE), establishment Brazil Data Cube,Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD post-doc scholarships, equipment, travel support.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD post-doc scholarships, equipment, travel support.International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084- Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084- Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.","code":""},{"path":"acknowledgements.html","id":"community-contributions","chapter":"Acknowledgements","heading":"Community Contributions","text":"authors thank R-spatial community foundational work, including Marius Appel, Tim Appelhans, Robert Hijmans, Edzer Pebesma, Martijn Tennekes R packages gdalcubes, leafem, terra, sf/stars, tmap. greateful work Dirk Eddelbuettel Rcpp RcppArmadillo Ron Wehrens package kohonen. much indebted Hadley Wickham tidyverse, Daniel Falbel torch luz packages, RStudio team package leaflet. multiple authors machine learning packages randomForest, e1071 xgboost provided robust algorithms. like thank Python developers shared deep learning algorithms image time series classification: Vivien Sainte Fare Garnot, Zhiguang Wang, Maja Schneider, Marc Rußwurm. first author also thanks Roger Bivand benign influence things related R.","code":""},{"path":"acknowledgements.html","id":"reproducible-papers-used-in-building-sits","chapter":"Acknowledgements","heading":"Reproducible papers used in building sits","text":"thank authors papers making code available.Edzer Pebesma, “Simple Features R: Standardized Support Spatial Vector Data”. R Journal, 10(1):2018.Edzer Pebesma, “Simple Features R: Standardized Support Spatial Vector Data”. R Journal, 10(1):2018.Ron Wehrens Johannes Kruisselbrink, “Flexible Self-Organising Maps kohonen 3.0”. Journal Statistical Software, 87, 7 (2018). https://doi.org/10.18637/jss.v087.i07.Ron Wehrens Johannes Kruisselbrink, “Flexible Self-Organising Maps kohonen 3.0”. Journal Statistical Software, 87, 7 (2018). https://doi.org/10.18637/jss.v087.i07.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, “Deep learning time series classification: review”. Data Mining Knowledge Discovery, 33(4): 917–963, 2019. https://doi.org/10.1007/s10618-019-00619-1.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, “Deep learning time series classification: review”. Data Mining Knowledge Discovery, 33(4): 917–963, 2019. https://doi.org/10.1007/s10618-019-00619-1.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. “Temporal Convolutional Neural Network Classification Satellite Image Time Series”. Remote Sensing 11 (5), 2019. https://doi.org/10.3390/rs11050523.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. “Temporal Convolutional Neural Network Classification Satellite Image Time Series”. Remote Sensing 11 (5), 2019. https://doi.org/10.3390/rs11050523.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, “Breizhcrops: Time Series Dataset Crop Type Mapping”. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, “Breizhcrops: Time Series Dataset Crop Type Mapping”. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marius Appel Edzer Pebesma, “-Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library.” Data 4 (3): 1–16, 2020. https://doi.org/10.3390/data4030092Marius Appel Edzer Pebesma, “-Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library.” Data 4 (3): 1–16, 2020. https://doi.org/10.3390/data4030092Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, “Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention”, Conference Computer Vision Pattern Recognition, 2020. https://doi.org/10.1109/CVPR42600.2020.01234.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, “Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention”, Conference Computer Vision Pattern Recognition, 2020. https://doi.org/10.1109/CVPR42600.2020.01234.Vivien Garnot, Loic Landrieu, “Lightweight Temporal Self-Attention Classifying Satellite Images Time Series”, 2020. <arXiv:2007.00586>.Vivien Garnot, Loic Landrieu, “Lightweight Temporal Self-Attention Classifying Satellite Images Time Series”, 2020. <arXiv:2007.00586>.Maja Schneider, Marco Körner, “[Re] Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention.” ReScience C 7 (2), 2021. doi:10.5281/zenodo.4835356.Maja Schneider, Marco Körner, “[Re] Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention.” ReScience C 7 (2), 2021. doi:10.5281/zenodo.4835356.","code":""},{"path":"acknowledgements.html","id":"publications-using-sits","chapter":"Acknowledgements","heading":"Publications using sits","text":"section gathers publications used sits generate results.2023Bruno Adorno, Thales Körting, Silvana Amaral, “Contribution time-series data cubes classify urban vegetation types remote sensing”, Urban Forest & Urban Greening, vol. 79, 127817, January 2023. https://doi.org/10.1016/j.ufug.2022.1278172021Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, “Quality control class noise reduction satellite image time series”. ISPRS Journal Photogrammetry Remote Sensing, vol. 177, pp 75-88, 2021. https://doi.org/10.1016/j.isprsjprs.2021.04.014.Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, “Quality control class noise reduction satellite image time series”. ISPRS Journal Photogrammetry Remote Sensing, vol. 177, pp 75-88, 2021. https://doi.org/10.1016/j.isprsjprs.2021.04.014.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, “Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series”. Remote Sensing, 2021, 13(5), 974; https://doi.org/10.3390/rs13050974.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, “Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series”. Remote Sensing, 2021, 13(5), 974; https://doi.org/10.3390/rs13050974.2020Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira & Alexandre Carvalho. “Land use cover maps Mato Grosso State Brazil 2001 2017”. Nature Scientific Data 7, article 34 (2020). DOI: 10.1038/s41597-020-0371-4.Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira & Alexandre Carvalho. “Land use cover maps Mato Grosso State Brazil 2001 2017”. Nature Scientific Data 7, article 34 (2020). DOI: 10.1038/s41597-020-0371-4.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, “Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017”. Land, 9(1), 2020. DOI: 10.3390/land9010020.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, “Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017”. Land, 9(1), 2020. DOI: 10.3390/land9010020.Karine Ferreira, Gilberto Queiroz et al., “Earth Observation Data Cubes Brazil: Requirements, Methodology Products”. Remote Sensing, 12, 4033, 2020.Karine Ferreira, Gilberto Queiroz et al., “Earth Observation Data Cubes Brazil: Requirements, Methodology Products”. Remote Sensing, 12, 4033, 2020.Adeline Maciel, Lubia Vinhas, Michelle Picoli Gilberto Camara, “Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier”. Land, 9, 506, 2020. DOI: 10.3390/land9120506. DOI: 10.3390/rs12244033.Adeline Maciel, Lubia Vinhas, Michelle Picoli Gilberto Camara, “Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier”. Land, 9, 506, 2020. DOI: 10.3390/land9120506. DOI: 10.3390/rs12244033.2018Michelle Picoli, Gilberto Camara, et al., “Big Earth Observation Time Series Analysis Monitoring Brazilian Agriculture”. ISPRS Journal Photogrammetry Remote Sensing, 2018.","code":""},{"path":"introduction-to-sits.html","id":"introduction-to-sits","chapter":"Introduction to SITS","heading":"Introduction to SITS","text":"","code":""},{"path":"introduction-to-sits.html","id":"why-work-with-satellite-image-time-series","chapter":"Introduction to SITS","heading":"Why work with satellite image time series?","text":"Satellite images comprehensive source data environment. Covering large area Earth’s surface, images allow researchers study regional global changes. Sensors capture data multiple spectral bands measure physical, chemical, biological properties Earth’s surface. Covering location multiple times, satellites provide data changes environment survey areas difficult observe ground. Given unique features, images provide essential information many applications, including deforestation, crop production, food security, urban footprints, water scarcity, land degradation.time series set data points collected regular intervals time. Time series data used analyze trends, patterns, changes. Satellite image time series refer time series obtained collection images captured satellite period time, typically months years. Using time series, experts improve understanding ecological patterns processes. Instead selecting individual images specific dates comparing , researchers track change continuously [1].","code":""},{"path":"introduction-to-sits.html","id":"time-first-space-later","chapter":"Introduction to SITS","heading":"Time-first, space-later","text":"“Time-first, space-later” concept satellite image classification takes time series analysis first step analyzing remote sensing data, spatial information considered time series classified. time-first approach brings better understanding changes landscapes. Detecting tracking trends data, including seasonal long-term trends becomes feasible, well identifying anomalous events patterns data, wildfires, floods, droughts.space-later part requires spatial data analysis use neighborhood pixel. classification assigned pixel time series classification taken prior probability information. Using additional data pixel’s neighborhood, users obtain posterior probability distribution per pixel. Bayesian inference method allows combining spatial temporal information pixel.","code":""},{"path":"introduction-to-sits.html","id":"how-sits-works","chapter":"Introduction to SITS","heading":"How sits works","text":"sits package uses satellite image time series land classification, using time-first, space-later approach. data preparation part, collections big Earth observation images organized data cubes. spatial location data cube associated time series. Locations known labels train machine learning classifier, classifies time series data cube, shown Figure 1.\nFigure 1: Using time series land classification (source: authors)\npackage provides tools analysis, visualization classification satellite image time series. Users follow typical workflow:Select analysis-ready data image collection cloud providers AWS, Microsoft Planetary Computer, Digital Earth Africa Brazil Data Cube.Build regular data cube using chosen image collection.Obtain new bands indices operations data cubes.Extract time series samples data cube used training data.Perform quality control filtering time series samples.Train machine learning model using extracted samples.Use model classify data cube get class probabilities pixel.Post-process probability cube remove outliers.Produce labeled map post-processed probability cube.Evaluate accuracy classification using best practices.step workflow corresponds function sits API, shown table figure . functions convenient default parameters behavior. single function builds machine learning (ML) models. classification function processes big data cubes efficient parallel processing. Since sits API simple learn, users can achieve good results without -depth knowledge machine learning parallel processing.\nTable 1: sits API workflow land classification\n\nFigure 2: Main functions SITS API (source: authors).\n","code":""},{"path":"introduction-to-sits.html","id":"creating-a-data-cube","chapter":"Introduction to SITS","heading":"Creating a Data Cube","text":"two kinds data cubes sits: () irregular data cubes generated selecting image collections image collections cloud providers AWS Planetary Computer; (b) regular data cubes images fully covering chosen area, image spectral bands spatial resolution, images follow set adjacent regular time intervals. Machine learning applications need regular data cubes. details, please refer Chapter “Earth Observation Data Cubes”.first steps using sits : () select analysis-ready data image collection available cloud provider stored locally using sits_cube(); (b) collection regular, use sits_regularize() build regular data cube.section shows build data cube local images already organized regular data cube. data cube composed MODIS MOD13Q1 images Sinop region Mato Grosso, Brazil. images indexes “NDVI” “EVI” covering one-year period 2013-09-14 2014-08-29 (use “year-month-day” dates). 23 time instances, covering 16-day period. data available R package sitsdata.build data cube local files, users need provide information original source data obtained. case, sits_cube() needs parameters:source, cloud provider data obtained (case Brazil Data Cube “BDC”);collection, collection images extracted. case, data comes MOD13Q1 collection 6;data_dir, local directory image files stored;parse_info, stating file names store information tile, band date. case, local images stored TERRA_MODIS_012010_EVI_2014-07-28.tif.\nFigure 3: Color composite image MODIS cube 2013-09-14 (red = EVI, green = NDVI, blue = EVI).\nR object returned sits_cube() contains metadata describes contents data cube. metadata includes data source collection, satellite, sensor, tile collection, bounding box, projection, list files. file refers one band image one temporal instances cube.","code":"\n# create a data cube object based on the information about the files\nsinop <- sits_cube(\n  source = \"BDC\",\n  collection = \"MOD13Q1-6\",\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),\n  parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\")\n)\n# plot a the NDVI  for the first date (2013-09-14)\nplot(sinop,\n  band = \"NDVI\",\n  dates = \"2013-09-14\",\n  palette = \"RdYlGn\"\n)\n# show the R object that describes the data cube\nsinop#> # A tibble: 1 × 11\n#>   source collection satellite sensor tile        xmin      xmax      ymin      ymax crs                 file_i…¹\n#>   <chr>  <chr>      <chr>     <chr>  <chr>      <dbl>     <dbl>     <dbl>     <dbl> <chr>               <list>  \n#> 1 BDC    MOD13Q1-6  TERRA     MODIS  012010 -6181982. -5963298. -1353336. -1225694. \"PROJCRS[\\\"unnamed… <tibble>\n#> # … with abbreviated variable name ¹​file_info"},{"path":"introduction-to-sits.html","id":"the-time-series-table","chapter":"Introduction to SITS","heading":"The time series table","text":"handle time series information, sits uses tabular data structure. example shows table 1,218 time series obtained MODIS MOD13Q1 images. series four attributes: two bands (“NIR” “MIR”) two indexes (“NDVI” “EVI”). data set available package sitsdata.data structure associated time series table contains data metadata. first six columns contain metadata: spatial temporal information, label assigned sample, data cube data extracted. time_series column contains time series data spatiotemporal location. data also organized table, column dates columns values spectral band. details handle time series data, please see “Working Time Series” chapter.useful plot dispersion time series. follows, brevity select one label (“Forest”) one index (“NDVI”). resulting plot shows time series associated label attribute, highlighting median first third quartiles.\nFigure 4: Joint plot samples band NDVI class Forest.\n","code":"\n# load the MODIS samples for Mato Grosso from the \"sitsdata\" package\nlibrary(tibble)\nlibrary(sitsdata)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\nsamples_matogrosso_mod13q1[1:2, ]#> # A tibble: 2 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\nsamples_forest <- dplyr::filter(\n  samples_matogrosso_mod13q1,\n  label == \"Forest\"\n)\nsamples_forest_ndvi <- sits_select(\n  samples_forest,\n  band = \"NDVI\"\n)\nplot(samples_forest_ndvi)"},{"path":"introduction-to-sits.html","id":"training-a-machine-learning-model","chapter":"Introduction to SITS","heading":"Training a machine learning model","text":"next step train machine learning (ML) model using sits_train(). takes two inputs, samples (time series table) ml_method (function implements machine learning algorithm). result model used classification. ML algorithm requires specific parameters user-controllable. novice users, sits provides default parameters produce good result. details, please see “Machine Learning Data Cubes” chapter.Since time series data four attributes (“EVI”, “NDVI”, “NIR”, “MIR”) data cube images two, select “NDVI” “EVI” values use resulting data training. build classification model, use random forest model called sits_rfor() function.\nFigure 5: relevant variables trained random forests model.\n","code":"\n# select the bands \"ndvi\", \"evi\"\nsamples_2bands <- sits_select(\n  data = samples_matogrosso_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n\n# train a random forest model\nrf_model <- sits_train(\n  samples = samples_2bands,\n  ml_method = sits_rfor()\n)\n# plot the most important variables of the model\nplot(rf_model)"},{"path":"introduction-to-sits.html","id":"data-cube-classification","chapter":"Introduction to SITS","heading":"Data cube classification","text":"training machine learning model, next step classify data cube using sits_classify(). function produces set raster probability maps, one class. maps, value pixel proportional probability belongs class. function two mandatory parameters: data, data cube time series tibble classified; ml_model, trained ML model. Optional parameters include: () multicores, number cores used; (b) memsize, RAM used classification; (c) output_dir, directory classified files written. Details classification process available “Classification Images Data Cubes”.\nFigure 6: Probability map class Forest.\nclassification completed, plot probability maps class “Forest”. Probability maps useful visualize degree confidence classifier assigns labels pixel can used produce uncertainty information support active learning, described Chapter “Data Cube Classification”.","code":"\n# classify the raster image\nsinop_probs <- sits_classify(\n  data = sinop,\n  ml_model = rf_model,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp3\"\n)\n# plot the probability cube for class Forest\nplot(sinop_probs, labels = c(\"Forest\"), palette = \"BuGn\")"},{"path":"introduction-to-sits.html","id":"spatial-smoothing","chapter":"Introduction to SITS","heading":"Spatial smoothing","text":"working big EO data, much variability class. result, pixels misclassified. errors likely occur transition areas classes. address problems, sits_smooth() takes probability cube input uses class probabilities pixel’s neighborhood reduce labeling uncertainty. Plotting smoothed probability map class “Forest” shows outliers removed.\nFigure 7: Smoothed probability map class Forest.\n","code":"\n# perform spatial smoothing\nsinop_bayes <- sits_smooth(\n  cube = sinop_probs,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_bayes, labels = c(\"Forest\"), palette = \"BuGn\")"},{"path":"introduction-to-sits.html","id":"labelling-a-probability-data-cube","chapter":"Introduction to SITS","heading":"Labelling a probability data cube","text":"removing outliers using local smoothing, one can obtain labeled classification map using function sits_label_classification(). function assigns pixel class highest probability.\n\nFigure 8: Classification map Sinop\nresulting classification files can read QGIS. Links associated files available sinop_map object nested table file_info.shown “Introduction”, sits provides end--end API land use land cover classification. follows, chapter provides detailed description training, modelling classification workflow.","code":"\n# label the probability file\nsinop_map <- sits_label_classification(\n  cube = sinop_bayes,\n  output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_map, title = \"Sinop Classification Map\")\n# show the location of the classification file\nsinop_map$file_info[[1]]#> # A tibble: 1 × 13\n#>   band  start_date end_date   ncols nrows  xres  yres      xmin      xmax      ymin      ymax crs          path \n#>   <chr> <date>     <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>     <dbl>     <dbl>     <dbl> <chr>        <chr>\n#> 1 class 2013-09-14 2014-08-29   944   551  232.  232. -6181982. -5963298. -1353336. -1225694. \"PROJCRS[\\\"… ./te…"},{"path":"earth-observation-data-cubes.html","id":"earth-observation-data-cubes","chapter":"Earth observation data cubes","heading":"Earth observation data cubes","text":"","code":""},{"path":"earth-observation-data-cubes.html","id":"analysis-ready-data-image-collections","chapter":"Earth observation data cubes","heading":"Analysis-ready data image collections","text":"Analysis-ready data (ARD) images ready analysis without need preprocessing transformation. designed simplify accelerate analysis Earth observation (EO) data providing consistent high-quality data standardized across different sensors platforms. ARD data typically provided collection single files, pixel file containing single value spectral band given date.ARD collections available cloud services Amazon Web Service, Brazil Data Cube, Digital Earth Africa, Swiss Data Cube, Microsoft’s Planetary Computer. collections processed improve multidate comparability. Radiance measures top atmosphere converted ground reflectance measures. general, timelines images ARD image collection different. Images still contain cloudy missing pixels; bands images collection may different resolutions. Figure 9 shows example Landsat ARD image collection.\nFigure 9: ARD image collection (source: USGS). Reproduction based fair use doctrine.\nARD image collections organized spatial partitions. Sentinel-2/2A images follow MGRS tiling system, divides world 60 UTM zones 8 degrees longitude . zone blocks 6 degrees latitude. Blocks split tiles 110 x 110 km2 10 km overlap. Figure 10 shows MGRS tiling system part Northeastern coast Brazil, contained UTM zone 24, block M.\nFigure 10: MGRS tiling system used Sentinel-2 images (source: GISSurfer 2.0). Reproduction based fair use doctrine.\nLandsat 4/5/7/8/9 satellites use Worldwide Reference System (WRS-2), breaks coverage Landsat satellites images identified path row. path descending orbit satellite; WRS-2 system 233 paths per orbit path divided 119 rows,row refers ta latitudinal center line frame imagery. Images WRS-2 geometrically corrected UTM projection.\nFigure 11: WRS-2 tiling system used Landsat-5/7/8/9 images (source: INPE ESRI). Reproduction based fair use doctrine.\n","code":""},{"path":"earth-observation-data-cubes.html","id":"ard-image-collections-handled-by-sits","chapter":"Earth observation data cubes","heading":"ARD image collections handled by sits","text":"version 1.2.0, sits supports access following ARD image collections:Amazon Web Services (AWS): Open data Sentinel-2/2A level 2A collections Earth’s land surface.Brazil Data Cube (BDC): Open data collections Sentinel-2/2A, Landsat-8, CBERS-4/4A, MODIS images Brazil. collections organized regular data cubes.Digital Earth Africa (DEA): Open data collections Sentinel-2/2A Landsat-8 Africa.Microsoft Planetary Computer (MPC): Open data collections Sentinel-2/2A Landsat-4/5/7/8/9 Earth’s land areas.USGS: Landsat-4/5/7/8/9 collections available AWS, require payment access.Swiss Data Cube (SDC): Open data collection Sentinel-2/2A Landsat-8 images Switzerland.","code":""},{"path":"earth-observation-data-cubes.html","id":"regular-image-data-cubes","chapter":"Earth observation data cubes","heading":"Regular image data cubes","text":"Machine learning deep learning (ML/DL) classification algorithms require input data consistent. dimensionality data used training model data classified. gaps missing values. Thus, use ML/DL algorithms remote sensing data, ARD image collections converted regular data cubes. Following Appel Pebesma [2], regular data cube following definition properties:regular data cube four-dimensional structure dimensions x (longitude easting), y (latitude northing), time, bands.spatial dimensions refer single spatial reference system (SRS). Cells data cube constant spatial size respect cube’s SRS.temporal dimension composed set continuous equally-spaced intervals.every combination dimensions, cell single value.cells data cube spatiotemporal extent. spatial resolution cell X Y dimensions. temporal intervals . cell contains valid set measures. position space, data cube provide set valid time series. time interval, regular data cube provide valid 2D image (see Figure 11).\nFigure 12: Conceptual view data cubes (source: authors)\nCurrently, cloud service provides regular data cubes default Brazil Data Cube (BDC). Analysis-ready data (ARD) collections available AWS, MSPC, USGS DE Africa regular space time. Bands may different resolutions, images may cover entire time, time intervals regular. reason, subsets collections need converted regular data cubes processing. produce data cubes machine-learning data analysis, users first create irregular data cube ARD collection use sits_regularize(), described .","code":""},{"path":"earth-observation-data-cubes.html","id":"creating-data-cubes","chapter":"Earth observation data cubes","heading":"Creating data cubes","text":"obtain information ARD image collection cloud providers, sits uses STAC (SpatioTemporal Asset Catalogue) protocol, specification geospatial information adopted many large image collection providers. ‘spatiotemporal asset’ file represents information Earth captured certain space time. access STAC endpoints, sits uses rstac R package.function sits_cube() supports access image collections cloud services; following parameters:source: name provider.collection: collection available provider supported sits. find collections supported sits, see sits_list_collections().platform: optional parameter specifying platform case collections include one satellite.tiles: Set tiles image collection reference system. Either tiles roi specified.roi: region interest. Either: () named vector (lon_min, lon_max, lat_min, lat_max) WGS 84 coordinates; (b) sf object. images intersect convex hull roi selected.bands: (optional) bands used. missing, bands collection used.start_date: initial date temporal interval containing time series images.end_date: final date temporal interval containing time series images.result sits_cube() tibble description selected images required processing. contain actual data, pointers actual images. attributes individual image files can assessed listing file_info column tibble.","code":""},{"path":"earth-observation-data-cubes.html","id":"assessing-amazon-web-services","chapter":"Earth observation data cubes","heading":"Assessing Amazon Web Services","text":"Amazon Web Services (AWS) holds two kinds collections: open-data requester-pays. Open data collections can accessed without cost. Requester-pays collections require payment AWS account. Currently, sits supports collections SENTINEL-S2-L2A (requester-pays) SENTINEL-S2-L2A-COGS (open-data). collections include Sentinel-2/2A bands. bands 10m resolution B02, B03, B04, B08. 20m bands B05, B06, B07, B8A, B11, B12. Bands B01 B09 available 60m resolution. CLOUD band also available. example shows access one tile open data SENTINEL-S2-L2A-COGS collection. tiles parameter allows selection desired area according MGRS reference system.","code":"\n# create a data cube covering an area in the Rondonia state in the Brazilian Amazon\n# Sentinel-2 images over\ns2_20LKP_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LKP\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2018-07-12\",\n  end_date = \"2019-07-28\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-microsofts-planetary-computer","chapter":"Earth observation data cubes","heading":"Assessing Microsoft’s Planetary Computer","text":"Microsoft’s Planetary Computer (MPC) hosts two open data collections: SENTINEL-2-L2A LANDSAT-C2-L2. first collection contains SENTINEL-2/2A ARD images, bands resolutions available AWS (see ). example shows access SENTINEL-2-L2A collection.\nFigure 13: Sentinel-2 image area state Rondonia, Brazil\nLANDSAT-C2-L2 collection provides access data Landsat-4, 5, 7, 8, 9 satellites. Images satellites intercalibrated ensure data consistency. compatibility different Landsat sensors, band names BLUE, GREEN, RED, NIR08, SWIR16, SWIR22. images 30m resolution. collection, tile search supported; roi parameter used. example shows retrieve data region interest covering city Brasilia Brazil.\nFigure 14: Landsat-8 image area city Brasilia, Brazil\n","code":"\n# create a data cube covering an area in the Brazilian Amazon\ns2_20LKP_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"20LKP\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2019-07-01\",\n  end_date = \"2019-07-28\"\n)\n# plot a color composite of one date of the cube\nplot(s2_20LKP_cube_MPC,\n  red = \"B11\", blue = \"B02\", green = \"B8A\",\n  date = \"2019-07-18\"\n)\n# Read a shapefile thar covers the city of Brasilia\nshp_file <- system.file(\"extdata/shapefiles/df_bsb/df_bsb.shp\",\n  package = \"sitsdata\"\n)\nsf_bsb <- sf::read_sf(shp_file)\n# select the cube\ns2_L8_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"LANDSAT-C2-L2\",\n  bands = c(\"BLUE\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi = sf_bsb,\n  start_date = \"2019-06-01\",\n  end_date = \"2019-10-01\"\n)\n# Plot the second tile that covers Brasilia\nplot(s2_L8_cube_MPC[2, ],\n  red = \"SWIR16\", green = \"NIR08\", blue = \"BLUE\",\n  date = \"2019-07-30\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-digital-earth-africa","chapter":"Earth observation data cubes","heading":"Assessing Digital Earth Africa","text":"Digital Earth Africa (DEAFRICA) cloud service provides open access Earth Observation data African continent. ARD image collections available sits S2_L2A (Sentinel-2 level 2A) LS8_SR (Landsat-8). Since STAC interface DEAFRICA implement concept tiles, users users need specify area interest using roi parameter. requested roi produces cube contains three MGRS tiles (“35HLD”, “35HKD”, “35HLC”) covering part South Africa.","code":"\ndea_cube <- sits_cube(\n  source = \"DEAFRICA\",\n  collection = \"S2_L2A\",\n  roi = c(\n    lon_min = 24.97, lat_min = -34.30,\n    lon_max = 25.87, lat_max = -32.63\n  ),\n  bands = c(\"B05\", \"B8A\", \"B11\"),\n  start_date = \"2019-09-01\",\n  end_date = \"2019-10-01\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-the-brazil-data-cube","chapter":"Earth observation data cubes","heading":"Assessing the Brazil Data Cube","text":"Brazil Data Cube (BDC) built Brazil’s National Institute Space Research (INPE). BDC uses three hierarchical grids based Albers Equal Area projection SIRGAS 2000 datum. three grids generated taking -54\\(^\\circ\\) longitude central reference defining tiles \\(6\\times4\\), \\(3\\times2\\) \\(1.5\\times1\\) degrees. large grid composed tiles \\(672\\times440\\) km2 used CBERS-4 AWFI collections 64 meter resolution; CBERS-4 AWFI tile contains images \\(10,504\\times6,865\\) pixels. medium grid used Landsat-8 OLI collections 30 meter resolution; tiles extension \\(336\\times220\\) km2 image \\(11,204\\times7,324\\) pixels. small grid covers \\(168\\times110\\) km2 used Sentinel-2 MSI collections 10m resolutions; image \\(16,806\\times10,986\\) pixels. data cubes BDC regularly spaced time cloud-corrected [3].\nFigure 15: Hierarchical BDC tiling system showing overlayed Brazilian Biomes (), illustrating one large tile (b) contains four medium tiles (c) medium tile contains four small tiles. Source: Ferreira et al.(2020). Reproduction fair use doctrine.\ncollections available BDC : LC8_30_16D_STK-1 (Landsat-8 OLI, 30m resolution, 16-day intervals), S2-SEN2COR_10_16D_STK-1 (Sentinel-2 MSI images 10 meter resolution, 16-day intervals), CB4_64_16D_STK-1 (CBERS 4/4A AWFI, 64m resolution, 16 days intervals), CB4_20_1M_STK-1 (CBERS 4/4A MUX, 20m resolution, one month intervals) MOD13Q1-6 (MODIS MOD13SQ1 product, collection 6, 250m resolution, 16-day intervals). details, use sits_list_collections(source = \"BDC\").access Brazil Data Cube, users need provide credentials using environment variables, shown . Obtaining BDC access key free. Users need register BDC site obtain key.example , data cube defined one tile (“022024”) CB4_64_16D_STK-1 collection holds CBERS AWFI images 16 days resolution.\nFigure 16: Plot CBERS-4 image obtained BDC single tile covering area Brazilian Cerrado.\n","code":"Sys.setenv(\n    \"BDC_ACCESS_KEY\" = <your_bdc_access_key>\n)\n# define a tile from the CBERS-4/4A AWFI collection\ncbers_tile <- sits_cube(\n  source = \"BDC\",\n  collection = \"CB4_64_16D_STK-1\",\n  tiles = \"022024\",\n  bands = c(\"B13\", \"B14\", \"B15\", \"B16\", \"CLOUD\"),\n  start_date = \"2018-09-01\",\n  end_date = \"2019-08-28\"\n)\n# plot one time instance\nplot(cbers_tile, red = \"B15\", green = \"B16\", blue = \"B13\", date = \"2018-09-30\")"},{"path":"earth-observation-data-cubes.html","id":"defining-a-data-cube-using-ard-local-files","chapter":"Earth observation data cubes","heading":"Defining a data cube using ARD local files","text":"ARD images downloaded cloud collections local computer associated STAC endpoint describes . need organized named allow sits create data cube . local files directory spatial resolution projection. file contain single image band single date. file name needs include tile, date band information. Users need provide information original data source allow sits retrieve information image attributes band names, missing values, etc. working local cubes, sits_cube() needs following parameters:source: name original data provider; either BDC, AWS, USGS, MSPC DEAFRICA.collection: collection data extracted.data_dir: local directory images.bands: optional parameter describe bands retrieved.parse_info: information parse file names. File names need contain information tile, date band, separated delimiter (usually “_“).delim: separator character descriptors file name (default “_“).example shows define data cube using files sitsdata package. data set containing part tile “20LKP” Sentinel-2 images period 2020-06-04 2021-08-26, bands “B02”, “B8A” “B11”. Data extracted collection “SENTINEL-2-L2A” Microsoft Planetary Computer (“MPC”) Given file name cube_20LKP_B02_2020-06-04.tif, retrieve information images, one needs set parse_info parameter c(\"X1\", \"tile\", \"band\", \"date\").\nFigure 17: CBERS-4 NDVI area Brazil\n","code":"\nlibrary(sits)\n# Create a cube based on a stack of CBERS data\ndata_dir <- system.file(\"extdata/Rondonia-20LKP\", package = \"sitsdata\")\n# list the first file\nlist.files(data_dir)[1]#> [1] \"cube_20LKP_B02_2020-06-04.tif\"\n# create a data cube from local files\ns2_cube_20LKP <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\"X1\", \"tile\", \"band\", \"date\")\n)\n# plot the band B8A in the first time instance\nplot(s2_cube_20LKP, red = \"B11\", green = \"B8A\", blue = \"B02\", dates = \"2021-07-25\")"},{"path":"earth-observation-data-cubes.html","id":"defining-a-data-cube-using-classified-images","chapter":"Earth observation data cubes","heading":"Defining a data cube using classified images","text":"also possible create local cubes based results produced classification post-classification algorithms. case, parameters required parameter parse_info specified differently, follows:source: name original data provider.collection: name collection data extracted.data_dir: local directory classified images.band: Band name associated type result. Use: () probs probability cubes produced sits_classify(); (b) bayes, cubes produced sits_smooth(); (c) entropy, least, ratio margin, according method selected using sits_uncertainty(); (d) class labelled cubes.labels: Labels associated classification results (required cubes produced sits_uncertainty()).version: Version result (default = v1).parse_info: File name parsing information allow sits deduce values tile, start_date, end_date, band version file name. Unlike non-classified image files, cubes produced classification post-classification start_date end_date.following code creates results cube based classification deforestation Brazil. classified cube obtained large data cube Sentinel-2 images, covering state Rondonia, Brazil comprising 40 tiles, 10 spectral bands, covering period 2020-06-01 2021-09-11. Samples four classes trained random forest classifier.\nFigure 18: Classified data cube year 2020/2021 Rondonia, Brazil\n","code":"\n# Create a cube based on a classified image\ndata_dir <- system.file(\"extdata/Rondonia\", package = \"sitsdata\")\n# file is named \"SENTINEL-2_MSI_20LLP_2020-06-04_2021-08-26_class_v1.tif\"\nRondonia_class_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  bands = \"class\",\n  labels = c(\n    \"Burned_Area\", \"Cleared_Area\",\n    \"Highly_Degraded\", \"Forest\"\n  ),\n  data_dir = data_dir,\n  parse_info = c(\n    \"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  )\n)\n# plot the classified cube\nplot(Rondonia_class_cube)"},{"path":"earth-observation-data-cubes.html","id":"regularizing-data-cubes","chapter":"Earth observation data cubes","heading":"Regularizing data cubes","text":"Analysis-ready data (ARD) collections available AWS, MSPC, USGS DEAFRICA regular space time. Bands may different resolutions, images may cover entire tile, time intervals regular. reason, data collection need converted regular data cubes run machine learning methods. done function sits_regularize(), uses gdalcubes package [2].following example, user created irregular data cube Sentinel-2 collection available Microsoft’s Planetary Computer (MSPC) tiles 20LKP 20LLP state Rondonia, Brazil. first build irregular data cube using sits_cube().\nFigure 19: Sentinel-2 tile 20LLP date 2018-07-03\ndifferent acquisition orbits Sentinel-2 Sentinel-2A satellites, two tiles also different timelines. Tile 20LKP 12 instances tile 20LLP 24 instances chosen period. function sits_regularize() builds data cube regular timeline best estimate valid pixel interval. period parameter sets time interval two images. Values period use ISO8601 time period specification, defines time intervals P[n]Y[n]M[n]D, Y stands years, “M” months “D” days. Thus, P1M stands one-month period, P15D fifteen-day period. joining different images get best image period, sits_regularize() uses aggregation method organizes images chosen interval order increasing cloud cover, selects first cloud-free pixel sequence.\nFigure 20: Regularized image tile Sentinel-2 tile 20LLP\nobtaining regular data cube, users can perform data analysis classification operations, shown next chapters.","code":"\n# creating an irregular data cube from MSPC\ns2_cube <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = c(\"20LKP\", \"20LLP\"),\n  bands = c(\"B05\", \"B8A\", \"B12\", \"CLOUD\"),\n  start_date = as.Date(\"2018-07-01\"),\n  end_date = as.Date(\"2018-08-31\")\n)\n# show the different timelines of the cube tiles\nsits_timeline(s2_cube)#> Warning: cube is not regular, returning all timelines#> $`20LKP`\n#>  [1] \"2018-07-03\" \"2018-07-08\" \"2018-07-13\" \"2018-07-18\" \"2018-07-23\" \"2018-07-28\" \"2018-08-02\" \"2018-08-07\"\n#>  [9] \"2018-08-12\" \"2018-08-17\" \"2018-08-22\" \"2018-08-27\"\n#> \n#> $`20LLP`\n#>  [1] \"2018-07-03\" \"2018-07-05\" \"2018-07-08\" \"2018-07-10\" \"2018-07-13\" \"2018-07-15\" \"2018-07-18\" \"2018-07-20\"\n#>  [9] \"2018-07-23\" \"2018-07-25\" \"2018-07-28\" \"2018-07-30\" \"2018-08-02\" \"2018-08-04\" \"2018-08-07\" \"2018-08-09\"\n#> [17] \"2018-08-12\" \"2018-08-14\" \"2018-08-17\" \"2018-08-19\" \"2018-08-22\" \"2018-08-24\" \"2018-08-27\" \"2018-08-29\"\n# plot the first image of the irregular cube\ns2_cube %>%\n  dplyr::filter(tile == \"20LLP\") %>%\n  plot(red = \"B12\", green = \"B8A\", blue = \"B05\", date = \"2018-07-03\")\n# regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n  cube       = s2_cube,\n  output_dir = \"./tempdir/chp4\",\n  res        = 120,\n  period     = \"P15D\",\n  multicores = 4\n)\n# plot the first image of the tile 20LLP of the regularized cube\n# The pixels of the regular data cube cover the full MGRS tile\nreg_cube %>%\n  dplyr::filter(tile == \"20LLP\") %>%\n  plot(red = \"B12\", green = \"B8A\", blue = \"B05\")"},{"path":"operations-on-data-cubes.html","id":"operations-on-data-cubes","chapter":"Operations on Data Cubes","heading":"Operations on Data Cubes","text":"","code":""},{"path":"operations-on-data-cubes.html","id":"pixel-based-and-neighborhood-based-operations","chapter":"Operations on Data Cubes","heading":"Pixel-based and neighborhood-based operations","text":"Pixel-based operations remote sensing images refer image processing techniques operate individual pixels cells image, without taking account spatial relationships neighboring pixels. operations typically applied pixel image independently can used extract information spectral, radiometric, spatial properties image. Pixel-based operations produce spectral indexes combine information multiple bands.Neighborhood-based operations operations applied group pixels image. neighborhood typically defined rectangular circular region centered given pixel. operations can used removing noise images, detecting edges, sharpening, among uses.Using sits_apply() function, users specify desired mathematical operation function bands available cube using valid R expression compute new indices. , sits_apply() computes operation tiles temporal intervals. two types operations sits_apply():Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin().Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin().Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation) w_var() (variance). Users set size window (odd values allowed).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation) w_var() (variance). Users set size window (odd values allowed).following examples show use sits_apply() function.","code":""},{"path":"operations-on-data-cubes.html","id":"computing-ndvi-and-its-variations","chapter":"Operations on Data Cubes","heading":"Computing NDVI and its variations","text":"Using vegetation indexes established practice remote sensing. indexes aim improve discrimination vegetation structure combining two wavebands, one leaf pigments reflect incoming light another leaves absorb incoming radiation. Green leaves natural vegetation forests strong emissivity rate near infrared bands low emissivity rates red bands electromagnetic spectrum. spectral properties used calculate NDVI (Normalized Difference Vegetation Index), widely used index computed normalized difference values infra-red red bands. inclusion red-edge bands Sentinel-2 images broadened scope bands used calculate indices[[4]][5]. follows, show examples vegetation index calculation, using Sentinel-2 data cube.First, define data cube tile Amazon region state Rondonia, Brazil, including bands used compute different vegetation indexes. regularize cube using target resolution 60 meters reduce processing time.many options calculating NDVI-related indexes Sentinel-2 bands. widely used method combines band “B08” (785-899 nm) band “B04” (650-680 nm). Recent works literature propose use red-edge bands “B05” (698-713 nm), “B06” (733-748 nm) “B07” (773-793 nm) capturing subtle variations chlorophyll absorption producing indexes called Normalized Difference Vegetation Red-edge indexes (NDRE) [4]. recent paper, Sun et al.[5] argue vegetation index built using bands “B06” “B07” provide better approximation leaf area index estimates. recent review, Chaves et al.[6] argues red-edge bands important distinguishing leaf structure chlorophyll content different vegetation species. example , show include additional indexes regular data cube Sentinel-2 spectral bands.first calculate NDVI usual way, using bands B08 B04.\nFigure 21: NDVI using bands B08 B04 Sentinel-2\nnow compare traditional NDVI vegetation indexes computed using red-edge bands. first compute NDRE1 using bands “B06” “B05”.\nFigure 22: NDRE1 using bands B06 B05 Sentinel-2\ncan notice contrast forests deforested areas stronger NDRE1 index NDVI. can also compare index red-edge based indexes shown . first calculate NDRE2 using bands “B07” “B05”.\nFigure 23: NDRE2 using bands B07 B05 Sentinel-2\nFinally, can calculate third red-edge based vegetation index using bands “B06” “B07”.\nFigure 24: NDVI using bands B08 B04 Sentinel-2\n","code":"\n# create a directory to store files\nif (!file.exists(\"./tempdir/chp5\")) {\n  dir.create(\"./tempdir/chp5\")\n}\n\n# creating an irregular data cube from MSPC\ns2_cube <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = c(\"20LKP\"),\n  bands = c(\n    \"B02\", \"B03\", \"B04\",\n    \"B05\", \"B06\", \"B07\",\n    \"B08\", \"B8A\", \"B11\",\n    \"B12\", \"CLOUD\"\n  ),\n  start_date = as.Date(\"2018-07-01\"),\n  end_date = as.Date(\"2018-08-31\")\n)\n# regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n  cube       = s2_cube,\n  output_dir = \"./tempdir/chp5\",\n  res        = 60,\n  period     = \"P15D\",\n  multicores = 4\n)\n# calculate new indexes\nreg_cube <- sits_apply(reg_cube,\n  NDVI = (B08 - B04) / (B08 + B04),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)\nplot(reg_cube, band = \"NDVI\", palette = \"RdYlGn\")\n# calculate new indexes\n# NDRE1 using bands B06 and B05\nreg_cube <- sits_apply(reg_cube,\n  NDRE1 = (B06 - B05) / (B06 + B05),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)\n# plot NDRE1 index\nplot(reg_cube, band = \"NDRE1\", palette = \"RdYlGn\")\n# calculate new index\n# NDRE2 using bands B07 and B05\nreg_cube <- sits_apply(reg_cube,\n  NDRE2 = (B07 - B05) / (B07 + B05),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)\n# plot NDRE2 index\nplot(reg_cube, band = \"NDRE2\", palette = \"RdYlGn\")\n# calculate new indexes\n# NDRE3 using bands B07 and B06\nreg_cube <- sits_apply(reg_cube,\n  NDRE3 = (B07 - B06) / (B07 + B06),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)\n# plot NDRE3 index\nplot(reg_cube, band = \"NDRE3\", palette = \"RdYlGn\")"},{"path":"operations-on-data-cubes.html","id":"spectral-indexes-for-identification-of-burned-areas","chapter":"Operations on Data Cubes","heading":"Spectral indexes for identification of burned areas","text":"Another relevant use band combination creation spectral indexes detection degradation fires, important element environmental degradation. Forest fires significant impact emissions impoverish natural ecosystems[7]. Fires open canopy, make microclimate drier increase amount dry fuel[8]. One well-established technique detecting burned areas remote sensing images normalized burn ratio (NBR) difference near infrared short wave infrared band, calculated using B8A B12 bands.\nFigure 25: NBR ratio regular data cube built using Sentinel-2 tiles 20LKP 20LLP\n","code":"\n# calculate the normalized burn ratio\nreg_cube <- sits_apply(reg_cube,\n  NBR = (B12 - B8A) / (B12 + B8A),\n  output_dir = \"./tempdir/chp5\",\n  multicores = 4,\n  memsize = 12\n)\n# plot the NBR for the first date\"\nplot(reg_cube, band = \"NBR\", palette = \"Reds\")"},{"path":"operations-on-data-cubes.html","id":"spectral-mixture-analysis","chapter":"Operations on Data Cubes","heading":"Spectral mixture analysis","text":"One useful tools analysis land remote sensing images use spectral mixture models[11]. rationale mixture models arises due spatial resolution associated pixels medium-resolution images. general, values pixels contain mixture spectral responses different types land cover contained inside resolution element [12]. Assuming set land cover classes (called endmembers) known, goal spectral mixture analysis derive set new bands, containing proportion endmember. used method spectral mixture analysis linear model [12], expressed \\[\nR_i = \\sum_{j=1}^N a_{,j}*x_j + \\epsilon_i, \\{1,...M}, M > N\n\\]\n\\(=1,..M\\) set spectral bands \\(j=1,..N\\) set land cover types. pixel, \\(R_i\\) reflectance -th spectral band, \\(x_j\\) value reflectance due j-th endmember, \\(a_{,j}\\) proportion j-th endmember -th spectral band. model includes error term \\(e_i\\). linear model can interpreted system equations spectral response pixel linear combination spectral response endmembers[12]. solve system equations obtain proportion endmember, sits uses non-negative least squares (NNLS) regression algorithm available R package RStoolbox developed Jakob Schwalb-Willmann, based sequential coordinate-wise algorithm (SCA) proposed Franc et al. [13].run mixture model sits, necessary inform values pixels covered entirely single class. -called “pure” pixels. pixels chosen carefully based expert knowledge area. quality resulting endmember images depends quality pure pixels. Since sits supports multiple endmember spectral mixture analysis[14], users can specify one pure pixel per endmember account natural variability.sits, spectral mixture analysis done sits_mixture_model() function, two mandatory parameters: cube (data cube) endmembers, named table (equivalent) defines defines pure pixels. endmembers table name following named columns: () type, defines class associated endmember; (b) names, names bands. line table contain value endmember bands (see example). improve readability, suggest endmembers parameters defined tribble. tribble tibble easier read row--row layout. example , define three endmmembers classes “forest”, “soil”, “water”. Note values band expressed integers ranging 0 10,000.\nFigure 26: Percentage forest per pixel estimated mixture model\n\nFigure 27: Percentage water per pixel estimated mixture model\n\nFigure 28: Percentage soil per pixel estimated mixture model\nSpectral mixture analysis methods many application remote sensing, including forest degradation[17], wetland surface dynamics [18] urban area characterization [19]. use sits allows unique combination mixture models time series analysis.","code":"\n# define the endmembers for three classes and six bands\nem <- tibble::tribble(\n  ~type,    ~B02, ~B03, ~B04, ~B8A, ~B11, ~B12,\n  \"forest\",  200,  352,  189, 2800, 1340,  546,\n  \"soil\",    400,  650,  700, 3600, 3500, 1800,\n  \"water\",   700, 1100, 1400,  850,   40,   26,\n)\n# Generate the mixture model\nreg_cube <- sits_mixture_model(\n  data = reg_cube,\n  endmembers = em,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp5\"\n)\n# plot the FOREST for the first date using the \"forest\" palette\nplot(reg_cube, band = \"FOREST\", palette = \"Greens\")\n# plot the water endmember for the first date using the water palette\nplot(reg_cube, band = \"WATER\", palette = \"Blues\")\n# plot the SOIL endmember for the first date using the \"soil\" palette\nplot(reg_cube, band = \"SOIL\", palette = \"OrRd\")"},{"path":"working-with-time-series.html","id":"working-with-time-series","chapter":"Working with time series","heading":"Working with time series","text":"","code":""},{"path":"working-with-time-series.html","id":"data-structures-for-satellite-time-series","chapter":"Working with time series","heading":"Data structures for satellite time series","text":"sits package uses sets time series data describing properties spatiotemporal locations interest. land use classification, sets consist samples labelled experts. package can also used type classification, provided timeline bands time series used training match data cubes.package uses tibble data structure organize time series data. tibble generalization data.frame, usual way R organize data tables. Tibbles part tidyverse, collection R packages designed work together data manipulation [20]. following code shows first three lines tibble containing 1,882 labeled samples land cover Mato Grosso state Brazil. samples contain time series extracted MODIS MOD13Q1 product 2000 2016, provided every 16 days 250-meter resolution Sinusoidal projection. Based ground surveys high-resolution imagery, includes samples nine classes: “Forest”, “Cerrado”, “Pasture”, “Soy_Fallow”, “Fallow_Cotton”, “Soy_Cotton”, “Soy_Corn”, “Soy_Millet”, “Soy_Sunflower”.sits tibble contains data metadata. first six columns contain spatial temporal information, label assigned sample, data cube data extracted. first sample labeled “Pasture” location (-58.5631, -13.8844) valid period (2006-09-14, 2007-08-29). Informing dates label valid crucial correct classification. case, researchers involved labeling samples chose use agricultural calendar Brazil. applications countries, relevant dates likely different used example. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band.","code":"\n# samples\ndata(\"samples_matogrosso_mod13q1\")\nsamples_matogrosso_mod13q1[1:4, ]#> # A tibble: 4 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 3     -59.4    -9.31 2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 4     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>"},{"path":"working-with-time-series.html","id":"utilities-for-handling-time-series","chapter":"Working with time series","heading":"Utilities for handling time series","text":"package provides functions data manipulation displaying information sits tibble. example, sits_labels_summary() shows labels sample set frequencies.many cases, helpful relabel data set. example, may situations one wants use smaller set labels, since samples one label original set may distinguishable samples labels. use sits_labels()<- assign new labels). example shows relabelling time series set shown ; samples associated crops grouped single “Croplands” label.Given used tibble data format metadata embedded time series, one can use functions dplyr, tidyr, purrr packages tidyverse [20] process data. example, following code uses sits_select() get subset sample data set two bands (NDVI EVI) uses dplyr::filter() select samples labelled “Cerrado”.","code":"\nsits_labels_summary(samples_matogrosso_mod13q1)#> # A tibble: 9 × 3\n#>   label         count   prop\n#>   <chr>         <int>  <dbl>\n#> 1 Cerrado         379 0.200 \n#> 2 Fallow_Cotton    29 0.0153\n#> 3 Forest          131 0.0692\n#> 4 Pasture         344 0.182 \n#> 5 Soy_Corn        364 0.192 \n#> 6 Soy_Cotton      352 0.186 \n#> 7 Soy_Fallow       87 0.0460\n#> 8 Soy_Millet      180 0.0951\n#> 9 Soy_Sunflower    26 0.0137\n# copy the sample set for Mato Grosso\nsamples_new_labels <- samples_matogrosso_mod13q1\nsits_labels(samples_new_labels) <- c(\n  \"Cerrado\", \"Croplands\",\n  \"Forest\", \"Pasture\",\n  \"Croplands\", \"Croplands\",\n  \"Croplands\", \"Croplands\",\n  \"Croplands\"\n)\nsits_labels_summary(samples_new_labels)#> # A tibble: 4 × 3\n#>   label     count   prop\n#>   <chr>     <int>  <dbl>\n#> 1 Cerrado     379 0.200 \n#> 2 Croplands  1038 0.549 \n#> 3 Forest      131 0.0692\n#> 4 Pasture     344 0.182\n# select NDVI band\nsamples_ndvi <- sits_select(samples_matogrosso_mod13q1,\n  bands = \"NDVI\"\n)\n\n# select only samples with Cerrado label\nsamples_cerrado <- dplyr::filter(\n  samples_ndvi,\n  label == \"Cerrado\"\n)"},{"path":"working-with-time-series.html","id":"time-series-visualisation","chapter":"Working with time series","heading":"Time series visualisation","text":"Given small number samples display, plot() tries group many spatial locations together. following example, first 12 samples “Cerrado” class refer spatial location consecutive time periods. reason, samples plotted together.\nFigure 29: Plot first ‘Cerrado’ sample\nlarge number samples, default visualization combines samples together single temporal interval even belong different years. plot useful show spread values time series band. strong red line plot shows median values, two orange lines first third interquartile ranges. See ?plot details data visualization sits.\nFigure 30: Plot Cerrado samples\n","code":"\n# plot the first 12 samples\nplot(samples_cerrado[1:12, ])\n# plot all cerrado samples together\nplot(samples_cerrado)"},{"path":"working-with-time-series.html","id":"obtaining-time-series-data-from-data-cubes","chapter":"Working with time series","heading":"Obtaining time series data from data cubes","text":"get set time series sits, one first create regular data cube request one time series cube using sits_get_data(). function uses two mandatory parameters: cube samples. cube parameter indicates data cube time series extracted. samples parameter accepts following data types:data.frame information latitude longitude (mandatory), start_date, end_date label sample point.csv file columns latitude longitude, start_date, end_date label.shapefile containing either POINT POLYGON geometries. See details .sf object (sf package) POINT POLYGON geometry information. See details .example , given data cube user provides latitude longitude desired location. Since bands, start date end date time series informed, sits obtains data cube. result tibble one time series can visualized using plot().\n\nFigure 31: NDVI EVI time series fetched local raster cube.\nuseful case set labelled samples available used training data set. case, one usually trusted observations labelled commonly stored plain text files comma-separated values (CSV) using shapefiles (SHP).retrieve training samples time series analysis, users need provide temporal information (start_date end_date). simplest case, samples share dates. strict requirement. Users can specify different dates, long compatible duration. example, data set samples_matogrosso_mod13q1 provided sitsdata package contains samples different years covering duration. samples obtained MOD13Q1 product, contains number images per year. Thus, time series data set samples_matogrosso_mod13q1 number instances.Given suitably built CSV sample file, sits_get_data() requires two parameters: () cube, name R object describes data cube; (b) samples, name CSV file.Users can also specify samples providing shapefiles sf objects containing POINT POLYGON geometries. geographical location inferred geometries associated shapefile sf object. files containing points, geographical location obtained directly. polygon geometries, parameter n_sam_pol (defaults 20) determines number samples extracted polygon. temporal information can provided explicitly user; absent, inferred data cube. label information available shapefile sf object, users include parameter label_attr indicate column contains label associated time series.","code":"\n# Obtain a raster cube with based on local files\ndata_dir <- system.file(\"extdata/sinop\", package = \"sitsdata\")\nraster_cube <- sits_cube(\n  source     = \"BDC\",\n  collection = \"MOD13Q1-6\",\n  data_dir   = data_dir,\n  parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\")\n)\n# obtain a time series from the raster cube from a point\nsample_latlong <- tibble::tibble(\n  longitude = -55.57320,\n  latitude  = -11.50566\n)\nseries <- sits_get_data(\n  cube = raster_cube,\n  samples = sample_latlong\n)\nplot(series)\n# retrieve a list of samples described by a CSV file\nsamples_csv_file <- system.file(\"extdata/samples/samples_sinop_crop.csv\",\n  package = \"sits\"\n)\n# for demonstration, read the CSV file into an R object\nsamples_csv <- read.csv(samples_csv_file)\n# print the first three lines\nsamples_csv[1:3, ]#> # A tibble: 3 × 6\n#>      id longitude latitude start_date end_date   label  \n#>   <int>     <dbl>    <dbl> <chr>      <chr>      <chr>  \n#> 1     1     -55.7    -11.8 2013-09-14 2014-08-29 Pasture\n#> 2     2     -55.6    -11.8 2013-09-14 2014-08-29 Pasture\n#> 3     3     -55.7    -11.8 2013-09-14 2014-08-29 Forest\n# get the points from a data cube in raster brick format\npoints <- sits_get_data(\n  cube = raster_cube,\n  samples = samples_csv_file\n)\n# show the tibble with the first three points\npoints[1:3, ]#> # A tibble: 3 × 7\n#>   longitude latitude start_date end_date   label    cube      time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>    <chr>     <list>           \n#> 1     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 <tibble [23 × 3]>\n#> 2     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 <tibble [23 × 3]>\n#> 3     -55.7    -11.7 2013-09-14 2014-08-29 Soy_Corn MOD13Q1-6 <tibble [23 × 3]>\n# obtain a set of points inside the state of Mato Grosso, Brazil\nshp_file <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n  package = \"sits\"\n)\n# read the shapefile into an \"sf\" object\nsf_shape <- sf::st_read(shp_file)#> Reading layer `mt' from data source \n#>   `/Library/Frameworks/R.framework/Versions/4.2/Resources/library/sits/extdata/shapefiles/mato_grosso/mt.shp' \n#>   using driver `ESRI Shapefile'\n#> Simple feature collection with 1 feature and 3 fields\n#> Geometry type: POLYGON\n#> Dimension:     XY\n#> Bounding box:  xmin: -61.6 ymin: -18 xmax: -50.2 ymax: -7.35\n#> Geodetic CRS:  SIRGAS 2000\n# create a data cube based on MOD13Q1 collection from BDC\nmodis_cube <- sits_cube(\n  source      = \"BDC\",\n  collection  = \"MOD13Q1-6\",\n  bands       = c(\"NDVI\", \"EVI\"),\n  roi         = sf_shape,\n  start_date  = \"2020-06-01\",\n  end_date    = \"2021-08-29\"\n)\n# read the points from the cube and produce a tibble with time series\nsamples_mt <- sits_get_data(\n  cube = modis_cube,\n  samples = shp_file,\n  start_date = \"2020-06-01\", end_date = \"2021-08-29\",\n  n_sam_pol = 20, multicores = 4\n)"},{"path":"working-with-time-series.html","id":"filtering-techniques-for-time-series","chapter":"Working with time series","heading":"Filtering techniques for time series","text":"Satellite image time series generally contaminated atmospheric influence, geolocation error, directional effects [21]. Atmospheric noise, sun angle, interferences observations different equipment specifications, well nature climate-land dynamics can sources variability [22]. Inter-annual climate variability also changes phenological cycles vegetation, resulting time series whose periods intensities match year--year basis. make best use available satellite data archives, methods satellite image time series analysis need deal noisy non-homogeneous data sets. vignette, discuss filtering techniques improve time series data present missing values noise.literature satellite image time series several applications filtering correct smooth vegetation index data. package supports well-known Savitzky–Golay (sits_sgolay()) Whittaker (sits_whittaker()) filters. evaluation MERIS NDVI time series filtering estimating phenological parameters India, [22] found Whittaker filter provides good results. [23] found Savitzky-Golay filter good reconstruction tropical evergreen broadleaf forests.","code":""},{"path":"working-with-time-series.html","id":"savitzkygolay-filter","chapter":"Working with time series","heading":"Savitzky–Golay filter","text":"Savitzky-Golay filter works fitting successive array \\(2n+1\\) adjacent data points \\(d\\)-degree polynomial linear least squares. main parameters filter polynomial degree (\\(d\\)) length window data points (\\(n\\)). general, produces smoother results larger value \\(n\\) /smaller value \\(d\\) [24]. optimal value two parameters can vary case case. SITS, user can set order polynomial using parameter order (default = 3), size temporal window parameter length (default = 5), temporal expansion parameter scaling (default = 1). following example shows effect Savitsky-Golay filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01.\nFigure 32: Savitzky-Golay filter applied multi-year NDVI time series.\nNotice resulting smoothed curve desirable unwanted properties. period 2000 2008, Savitsky-Golay filter removes noise resulting clouds. However, 2010, region converted agriculture, filter removes important part natural variability crop cycle. Therefore, length parameter arguably big results oversmoothing. Users can try reduce parameter analyse results.","code":"\n# Take NDVI band of the first sample data set\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# apply Savitzky Golay filter\npoint_sg <- sits_sgolay(point_ndvi, length = 11)\n# merge the point and plot the series\nsits_merge(point_sg, point_ndvi) %>% plot()"},{"path":"working-with-time-series.html","id":"whittaker-filter","chapter":"Working with time series","heading":"Whittaker filter","text":"Whittaker smoother attempts fit curve represents raw data, penalized subsequent points vary much [25]. Whittaker filter balancing residual original data “smoothness” fitted curve. filter one parameter: \\(\\lambda{}\\) works “smoothing weight” parameter.following example shows effect Whitakker filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01. lambda parameter controls smoothing filter. default, set 0.5, small value. illustrative purposes, show effect larger smoothing parameter.\n\nFigure 33: Whittaker filter applied one-year NDVI time series.\nway observed Savitsky-Golay filter, high values smoothing parameter lambda produce -smoothed time series reduces capacity time series represent natural variations crop growth. reason, low smoothing values recommended using sits_whittaker function.","code":"\n# Take NDVI band of the first sample data set\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# apply Whitakker filter\npoint_whit <- sits_whittaker(point_ndvi, lambda = 8)\n# merge the point and plot the series\nsits_merge(point_whit, point_ndvi) %>% plot()"},{"path":"improving-the-quality-of-training-samples.html","id":"improving-the-quality-of-training-samples","chapter":"Improving the Quality of Training Samples","heading":"Improving the Quality of Training Samples","text":"Selecting good training samples machine learning classification satellite images critical achieving accurate results. Experience machine learning methods demonstrated number quality training samples critical factors obtaining accurate results [26]. Large accurate datasets preferable, regardless algorithm used, noisy training samples can negatively impact classification performance [27]. Thus, beneficial use pre-processing methods improve quality samples eliminate may incorrectly labeled possess low discriminatory power.One needs distinguish wrongly labelled samples differences result natural variability class signatures. training data collected large geographic region, natural variability vegetation phenology leads different patterns assigned label. related issue limitation crisp boundaries describe natural world. Class definitions use idealized descriptions (e.g., “savanna woodland tree cover 50% 90% ranging 8 15 meters height”). practice, boundaries classes fuzzy sometimes overlap, making hard distinguish . help users improve sample quality, sits provides methods evaluate training data","code":""},{"path":"improving-the-quality-of-training-samples.html","id":"geographical-variability-of-training-samples","chapter":"Improving the Quality of Training Samples","heading":"Geographical variability of training samples","text":"working machine learning classification Earth observation data, important evaluate training samples well distributed study area. many cases, training data comes ground surveys made chosen location. working large areas, ideally one needs representative sample captures spatial variability. practice, however, ground surveys means data collection limited selected areas. many case, geographical distribution training data cover study area equally. mismatch can problem achieving good quality classification. stated Meyer Pebesma[28]: “large gaps geographic space always imply large gaps feature space”.Meyer Pebesma[28] propose use spatial distance distribution plot, display two distributions nearest-neighbor distances: sample--sample prediction-location--sample. difference two distributions reflects degree spatial clustering reference data. Ideally, two distributions similar. Cases sample--sample distance distribution match prediction-location--sample distribution indicate possible problems training data collection.sits implements spatial distance distribution plots sits_geo_dist() function. function asks users provide training data samples parameter, study area roi parameter expressed sf object. Additional parameters n (maximum number samples distribution) crs (coordinate reference system samples). default, n 1000, crs “EPSG:4326”. example shows use sits_geo_dist().\nFigure 34: SOM map Cerrado samples\nplot shows mismatch sample--sample sample--prediction distribution. samples closer close locatiom values need predicted. case, many areas samples collected prediction uncertainty higher. similar cases, users invest improving distribution training samples. possible, aware areas insufficient samples lower accuracy, fact reported potential users results.","code":"\n# read a shapefile for the state of Mato Grosso, Brazil\nmt_shp <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n  package = \"sits\"\n)\n# convert to an sf object\nmt_sf <- sf::read_sf(mt_shp)\n\n# calculate sample-to-sample and sample-to-prediction distances\ndistances <- sits_geo_dist(\n  samples = samples_modis_ndvi,\n  roi = mt_sf\n)\n# plot sample-to-sample and sample-to-prediction distances\nplot(distances)"},{"path":"improving-the-quality-of-training-samples.html","id":"hierachical-clustering-for-sample-quality-control","chapter":"Improving the Quality of Training Samples","heading":"Hierachical clustering for sample quality control","text":"package provides two clustering methods assess sample quality: () Agglomerative Hierarchical Clustering (AHC); (b) Self-organizing Maps (SOM). methods different computational complexities. AHC computational complexity \\(\\mathcal{O}(n^2)\\) given number time series \\(n\\), whereas SOM complexity linear respect n. large data, AHC requires substantial amount memory running time; cases, SOM recommended. section, describe run AHC sits. SOM-based technique presented following section.Agglomerative hierarchical clustering (AHC) computes dissimilarity two elements data set. Depending distance functions linkage criteria, algorithm decides two clusters merged iteration. approach useful exploring samples due visualization power ease use [29]. sits, AHC implemented using sits_cluster_dendro().\nFigure 35: Example hierarchical clustering two class set time series\nsits_cluster_dendro() function one mandatory parameter (samples), users provide samples evaluated. Optional parameters include bands, dist_method linkage. dist_method parameter specifies calculate distance two time series. recommend metric uses dynamic time warping (DTW)[30], DTW reliable method measuring differences satellite image time series [31]. options available sits based provided package dtwclust, include dtw_basic, dtw_lb, dtw2. Please check ?dtwclust::tsclust information DTW distances.linkage parameter defines distance metric clusters. recommended linkage criteria : complete ward.D2. Complete linkage prioritizes within-cluster dissimilarities, producing clusters shorter distance samples, results sensitive outliers. alternative, Ward proposes use sum--squares error minimize data variance [32]; method available ward.D2 option linkage parameter. cut dendrogram, sits_cluster_dendro() function computes adjusted rand index (ARI) [33] returns height cut dendrogram maximizes index . example, ARI index indicates six (6) clusters present. result sits_cluster_dendro() time series tibble one additional column, called “cluster”. function sits_cluster_frequency() provides information composition cluster.cluster frequency table shows cluster predominance either “Cerrado” “Pasture” class exception cluster 3 mix samples classes. confusion may resulted incorrect labeling, inadequacy selected bands spatial resolution, even natural confusion due variability land classes. remove cluster 3, use dplyr::filter(). resulting clusters still contained mixed labels, possibly resulting outliers. case, users may want remove outliers leave frequent class using sits_cluster_clean(). cleaning samples, result set samples likely improve classification results.","code":"\n# take a set of patterns for 2 classes\n# create a dendrogram, plot, and get the optimal cluster based on ARI index\nclusters <- sits_cluster_dendro(\n  samples = cerrado_2classes,\n  bands = c(\"NDVI\", \"EVI\"),\n  dist_method = \"dtw_basic\",\n  linkage = \"ward.D2\"\n)\n# show clusters samples frequency\nsits_cluster_frequency(clusters)#>          \n#>             1   2   3   4   5   6 Total\n#>   Cerrado 203  13  23  80   1  80   400\n#>   Pasture   2 176  28   0 140   0   346\n#>   Total   205 189  51  80 141  80   746\n# remove cluster 3 from the samples\nclusters_new <- dplyr::filter(clusters, cluster != 3)\n# clear clusters, leaving only the majority class\nclean <- sits_cluster_clean(clusters_new)\n# show clusters samples frequency\nsits_cluster_frequency(clean)#>          \n#>             1   2   4   5   6 Total\n#>   Cerrado 203   0  80   0  80   363\n#>   Pasture   0 176   0 140   0   316\n#>   Total   203 176  80 140  80   679"},{"path":"improving-the-quality-of-training-samples.html","id":"using-som-for-sample-quality-control","chapter":"Improving the Quality of Training Samples","heading":"Using SOM for sample quality control","text":"alternative hierarchical clustering quality control training samples, SITS provides clustering technique based self-organizing maps (SOM). SOM dimensionality reduction technique [34], high-dimensional data mapped two dimensional map, keeping topological relations data patterns. shown , SOM 2D map composed units called neurons. neuron weight vector, dimension training samples. start, neurons assigned small random value trained competitive learning. algorithm computes distances member training set neurons finds neuron closest input, called best matching unit.\nFigure 36: SOM 2D map creation (source: Santos et al.(2021). Reproduction fair use doctrine.\ninput data quality assessment set training samples, high-dimensional data; example, time series 25 instances 4 spectral bands 100 dimensions. projecting high-dimensional data set 2D SOM map, units map (called neurons) compete sample. time series mapped one neurons. Since number neurons smaller number classes, neuron associated many time series. resulting 2D map set clusters. Given SOM preserves topological structure neighborhoods multiple dimensions, clusters contain training samples given class usually neighbors 2D space. neighbors neuron SOM map provide information intraclass interclass variability used detect noisy samples. methodology using SOM sample quality assessment discussed detail reference paper [35].\nFigure 37: Using SOM class noise reduction (source: Santos et al.(2021). Reproduction fair use doctrine.\nexample, take set time series Cerrado region Brazil, second largest biome South America area 2 million km2. data ranges 2000 2017 includes 50,160 land use cover samples divided 12 classes(“Dense_Woodland”, “Dunes”, “Fallow_Cotton”, “Millet_Cotton”, “Pasture”, “Rocky_Savanna”, “Savanna”, “Savanna_Parkland”, “Silviculture”, “Soy_Corn”, “Soy_Cotton”, “Soy_Fallow”). time series covers 12 months (23 data points) MOD13Q1 product, 4 bands (“EVI”, “NDVI”, “MIR”, “NIR”). use bands “NDVI” “EVI” faster processing.","code":"\n# take only the NDVI and EVI bands\nsamples_cerrado_mod13q1_2bands <- sits_select(\n  data = samples_cerrado_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n# show the summary of the samples\nsits_labels_summary(\n  data = samples_cerrado_mod13q1_2bands\n)#> # A tibble: 12 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    9966 0.199  \n#>  2 Dunes              550 0.0110 \n#>  3 Fallow_Cotton      630 0.0126 \n#>  4 Millet_Cotton      316 0.00630\n#>  5 Pasture           7206 0.144  \n#>  6 Rocky_Savanna     8005 0.160  \n#>  7 Savanna           9172 0.183  \n#>  8 Savanna_Parkland  2699 0.0538 \n#>  9 Silviculture       423 0.00843\n#> 10 Soy_Corn          4971 0.0991 \n#> 11 Soy_Cotton        4124 0.0822 \n#> 12 Soy_Fallow        2098 0.0418"},{"path":"improving-the-quality-of-training-samples.html","id":"creating-the-som-map","chapter":"Improving the Quality of Training Samples","heading":"Creating the SOM map","text":"perform SOM-based quality assessment, first step run sits_som_map() uses kohonen R package [36] compute SOM grid, controlled five parameters. grid size given grid_xdim grid_ydim. starting learning rate alpha, decreases interactions. measure separation samples, use distance (either “sumofsquares” “euclidean”). number iterations set rlen. details, please consult ?kohonen::supersom.\nFigure 38: SOM map Cerrado samples\noutput sits_som_map() list 3 elements: () original set time series two additional columns time series: id_sample (original id sample) id_neuron (id neuron belongs); (b) tibble information neurons. neuron, gives prior posterior probabilities labels occur samples assigned ; (c) SOM grid. plot SOM grid, use plot(). neurons labelled using majority voting.SOM grid shows classes associated neurons close . exceptions. “Pasture” neurons far main cluster, transition areas open savanna pasture always well defined depends climate latitude. Also, neurons associated “Soy_Fallow” dispersed map; indicates possible problems distinguishing class agricultural classes. SOM map can used remove outliers, shown .","code":"\n# clustering time series using SOM\nsom_cluster <- sits_som_map(samples_cerrado_mod13q1_2bands,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  distance = \"euclidean\",\n  rlen = 20\n)\n# plot the som map\nplot(som_cluster)"},{"path":"improving-the-quality-of-training-samples.html","id":"measuring-confusion-between-labels-using-som","chapter":"Improving the Quality of Training Samples","heading":"Measuring confusion between labels using SOM","text":"second step SOM-based quality assessment understanding confusion labels. function sits_som_evaluate_cluster() groups neurons majority label produces tibble. label, tibble show percentage samples different label mapped neuron whose majority label.Many labels associated clusters samples different label. confusion labels arises visual labeling samples subjective can biased. many cases, interpreters use high-resolution data identify samples. However, actual images classified captured satellites lower resolution. case study, MOD13Q1 image pixels 250 x 250 meter resolution correspondence labelled locations high-resolution images mid low-resolution images direct. confusion class can visualized bar plot using plot(), shown . bar plot shows confusion classes associated natural vegetation typical Brazilian Cerrado (“Savanna”, “Savanna_Parkland”, “Rocky_Savanna”). mixture due large variability natural vegetation Cerrado biome, makes difficult draw sharp boundaries label. confusion also visible agricultural classes. “Millet_Cotton” class particularly difficult one, since many samples assigned class confused “Soy_Cotton” “Fallow_Cotton”.\nFigure 39: Confusion classes measured SOM.\n","code":"\n# produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster)\n# show the result\nsom_eval#> # A tibble: 77 × 4\n#>    id_cluster cluster        class          mixture_percentage\n#>         <int> <chr>          <chr>                       <dbl>\n#>  1          1 Dense_Woodland Dense_Woodland           80.9    \n#>  2          1 Dense_Woodland Pasture                   5.26   \n#>  3          1 Dense_Woodland Rocky_Savanna             7.15   \n#>  4          1 Dense_Woodland Savanna                   3.69   \n#>  5          1 Dense_Woodland Silviculture              2.95   \n#>  6          1 Dense_Woodland Soy_Corn                  0.00889\n#>  7          1 Dense_Woodland Soy_Fallow                0.00889\n#>  8          2 Dunes          Dunes                   100      \n#>  9          3 Fallow_Cotton  Fallow_Cotton            64.8    \n#> 10          3 Fallow_Cotton  Millet_Cotton             5.47   \n#> # … with 67 more rows\n# plot the confusion between clusters\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"detecting-noisy-samples-using-som","chapter":"Improving the Quality of Training Samples","heading":"Detecting noisy samples using SOM","text":"third step quality assessment uses discrete probability distribution associated neuron, included labelled_neurons tibble produced sits_som_map(). homogeneous neurons (single class high probability) assumed composed good quality samples. Heterogeneous neurons (two classes significant probability) likely contain noisy samples. algorithm computes two values sample:prior probability: probability label assigned sample correct, considering samples contained neuron. example, neuron 20 samples, 15 labeled “Pasture” 5 “Forest”, samples labeled “Forest” assigned prior probability 25%. indication “Forest” samples neuron may good quality.prior probability: probability label assigned sample correct, considering samples contained neuron. example, neuron 20 samples, 15 labeled “Pasture” 5 “Forest”, samples labeled “Forest” assigned prior probability 25%. indication “Forest” samples neuron may good quality.posterior probability: probability label assigned sample correct, considering neighboring neurons. Take case -mentioned neuron whose samples labeled “Pasture” prior probability 75%. happens neighboring samples “Forest” majority label? answer question, use Bayesian inference estimate samples noisy based neighboring neurons [37]. Bayesian inference method, described Technical Annex, recalculates class probabilities neuron, based neighbors.posterior probability: probability label assigned sample correct, considering neighboring neurons. Take case -mentioned neuron whose samples labeled “Pasture” prior probability 75%. happens neighboring samples “Forest” majority label? answer question, use Bayesian inference estimate samples noisy based neighboring neurons [37]. Bayesian inference method, described Technical Annex, recalculates class probabilities neuron, based neighbors.identify noisy samples, take result sits_som_map() function first argument function sits_som_clean_samples(). function finds samples noisy, clean, need examined user. requires prior_threshold posterior_threshold parameters according following rules:prior probability sample less prior_threshold, sample assumed noisy tagged “remove”;prior probability greater equal prior_threshold posterior probability calculated Bayesian inference greater equal posterior_threshold, sample assumed noisy thus tagged “clean”;prior probability greater equal prior_threshold posterior probability less posterior_threshold, situation sample part majority level assigned neuron, label consistent neighbors. anomalous condition tagged “analyze”. Users encouraged inspect samples find whether fact noisy .default value prior_threshold posterior_threshold 60%. sits_som_clean_samples() additional parameter (keep) indicates samples kept set based prior posterior probabilities. default keep c(\"clean\", \"analyze\"). result cleaning, 900 samples considered noisy thus removed.samples class highest confusion others(“Millet_Cotton”) removed. samples class “Silviculture” (planted forests) also removed, since SOM map confused natural forests woodlands. analysis includes calculating SOM map confusion matrix new set, shown following example.\nFigure 40: Cluster confusion plot samples cleaned SOM\nexpected, new confusion map shows significant improvement previous one. result interpreted carefully, since may due different effects. direct interpretation “Millet_Cotton” “Silviculture” easily separated classes, given current attributes (time series “NDVI” “EVI” indices MODIS images). situations, users consider improving number samples less represented classes, including MODIS bands, working higher resolution satellites. Results SOM method interpreted based users’ understanding ecosystems agricultural practices study region.comparison original clean samples run 5-fold validation original cleaned sample sets using sits_kfold_validate() random forests model. SOM procedure improves validation results 95% original data set 99% cleaned one. improvement interpreted providing better fit final map accuracy. 5-fold validation procedure measures well machine learning model fits samples; accuracy assessment classification results. result indicates resulting training set SOM sample removal procedure internally consistent original one. details accuracy measures, please see chapter “Validation Accuracy Measures”.SOM-based analysis discards samples can confused samples classes. removing noisy samples uncertain classes, data set obtains better validation score since less confusion classes. Users analyse results care. discarded samples low quality ones. Confusion samples different classes can result inconsistent labeling lack capacity satellite data distinguish chosen classes. many samples discarded, current example, advisable revise whole classification schema. aim selecting training data always match reality ground power remote sensing data identify differences. analysis procedure can replace actual user experience knowledge study region.","code":"\nnew_samples <- sits_som_clean_samples(\n  som_map = som_cluster,\n  prior_threshold = 0.6,\n  posterior_threshold = 0.6,\n  keep = c(\"clean\", \"analyze\")\n)\n# print the new sample distribution\nsits_labels_summary(new_samples)#> # A tibble: 10 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    8334 0.206  \n#>  2 Dunes              550 0.0136 \n#>  3 Fallow_Cotton      152 0.00375\n#>  4 Pasture           5743 0.142  \n#>  5 Rocky_Savanna     6603 0.163  \n#>  6 Savanna           7943 0.196  \n#>  7 Savanna_Parkland  2065 0.0510 \n#>  8 Soy_Corn          4227 0.104  \n#>  9 Soy_Cotton        3540 0.0874 \n#> 10 Soy_Fallow        1350 0.0333\n# evaluate the misture in the SOM clusters of new samples\nnew_cluster <- sits_som_map(\n  data = new_samples,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  distance = \"euclidean\",\n)\nnew_cluster_mixture <- sits_som_evaluate_cluster(new_cluster)\n# plot the mixture information.\nplot(new_cluster_mixture)\n# run a k-fold validation\nassess_orig <- sits_kfold_validate(\n  samples = samples_cerrado_mod13q1_2bands,\n  folds = 5,\n  ml_method = sits_rfor()\n)\n# print summary\nsits_accuracy_summary(assess_orig)#> Overall Statistics                          \n#>  Accuracy : 0.945         \n#>    95% CI : (0.943, 0.947)\n#>     Kappa : 0.936\nassess_new <- sits_kfold_validate(\n  samples = new_samples,\n  folds = 5,\n  ml_method = sits_rfor()\n)\n# print summary\nsits_accuracy_summary(assess_new)#> Overall Statistics                          \n#>  Accuracy : 0.99          \n#>    95% CI : (0.989, 0.991)\n#>     Kappa : 0.989"},{"path":"improving-the-quality-of-training-samples.html","id":"reducing-sample-imbalance","chapter":"Improving the Quality of Training Samples","heading":"Reducing sample imbalance","text":"Many training samples Earth observation data analysis imbalanced. situation arises distribution samples associated class uneven. One example Cerrado data set used chapter. three frequent classes (“Dense Woodland”, “Savanna” “Pasture”) include 53% samples, three least frequent classes (“Millet-Cotton”, “Silviculture”, “Dunes”) comprise 2.5% data set. Sample imbalance undesirable property training set. Since machine learning algorithms tend accurate classes many samples. instances belonging minority group misclassified often belonging majority group. Thus, reducing sample imbalance can positive effect classification accuracy[38].function sits_reduce_imbalance() deals class imbalance; oversamples minority classes undersamples majority ones. Oversampling requires generation synthetic samples. package uses SMOTE method estimates new samples considering cluster formed nearest neighbors minority class. SMOTE takes two samples cluster produces new one random interpolation [39].perform undersampling, sits_reduce_imbalance() builds SOM map majority class, based required number samples selected. dimension SOM set ceiling(sqrt(new_number_samples/4)) allow reasonable number neurons group similar samples. calculating SOM map, algorithm extracts four samples per neuron generate reduced set samples approximates variation original one.sits_reduce_imbalance() algorithm two parameters: n_samples_over n_samples_under. first parameter ensures classes samples less value oversampled. second parameter controls undersampling; classes samples value undersampled. following example shows use sits_reduce_imbalance() Cerrado data set used chapter. generate balanced data set classes 1000 1500 samples. use sits_som_evaluate_cluster() estimate confusion classes balanced data set.\nFigure 41: Confusion cluster balanced data set\nshown Figure, balanced data set shows less confusion per class unbalanced one. case, many classes confused original confusion map now better represented. Reducing class imbalance tried alternative reducing number samples classes using SOM. general, users try balance training data better performance.","code":"\n# reducing imbalances in the Cerrado data set\nbalanced_samples <- sits_reduce_imbalance(\n  samples = samples_cerrado_mod13q1_2bands,\n  n_samples_over = 1000,\n  n_samples_under = 1500,\n  multicores = 4\n)\n# print the balanced samples\n# some classes have more than 1500 samples due to the SOM map\n# each class has betwen 10% and 6% of the full set\nsits_labels_summary(balanced_samples)#> # A tibble: 12 × 3\n#>    label            count   prop\n#>    <chr>            <int>  <dbl>\n#>  1 Dense_Woodland    1600 0.0964\n#>  2 Dunes             1000 0.0602\n#>  3 Fallow_Cotton     1000 0.0602\n#>  4 Millet_Cotton     1000 0.0602\n#>  5 Pasture           1592 0.0959\n#>  6 Rocky_Savanna     1524 0.0918\n#>  7 Savanna           1596 0.0961\n#>  8 Savanna_Parkland  1588 0.0956\n#>  9 Silviculture      1000 0.0602\n#> 10 Soy_Corn          1592 0.0959\n#> 11 Soy_Cotton        1596 0.0961\n#> 12 Soy_Fallow        1516 0.0913\n# clustering time series using SOM\nsom_cluster_bal <- sits_som_map(\n  data = balanced_samples,\n  grid_xdim = 10,\n  grid_ydim = 10,\n  alpha = 1.0,\n  distance = \"euclidean\",\n  rlen = 20\n)\n# produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster_bal)\n# show the result\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"conclusion","chapter":"Improving the Quality of Training Samples","heading":"Conclusion","text":"quality training data critical improve accuracy maps resulting machine learning classification methods. address challenge, sits package provides three methods improving training samples. large datasets, recommend using imbalance reducing SOM-based algorithms. SOM-based method identifies potential mislabeled samples outliers require investigation. results demonstrate positive impact overall classification accuracy.Users need take care defining classification schema. complexity diversity planet defies simple class names hard boundaries. Due representational data handling issues, classification systems limited number categories, inevitably fail properly describe nuances planet’s landscapes. representation systems thus limited application-dependent. stated Janowicz [40]: “geographical concepts situated context-dependent can described different, equally valid, points view; thus, ontological commitments arbitrary large extent”.availability big data satellite image time series challenge. principle, image time series can capture subtle changes land classification. practice, experts need conceive classification systems training data collection understanding time series information relate actual land change. Methods quality analysis presented chapter replace user understanding informed choices.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-for-data-cubes","chapter":"Machine Learning for Data Cubes","heading":"Machine Learning for Data Cubes","text":"","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-classification","chapter":"Machine Learning for Data Cubes","heading":"Machine learning classification","text":"Machine learning classification kind supervised learning algorithm trained predict category class input data point belongs . involves teaching computer program recognize patterns data use patterns predict class label new data. goal classification build model can accurately assign class label new data based patterns learned previously labeled data. sits, machine learning used classify individual time series, using time-first approach.goal machine learning models approximate function \\(y = f(x)\\) maps input \\(x\\) category \\(y\\). model defines mapping \\(y = f(x;\\theta)\\) learns value parameters \\(\\theta\\) result best function approximation [41]. difference different algorithms approach take build mapping classifies input data.sits package includes two kinds methods time series classification:Machine learning algorithms explicitly consider temporal stucture time series. treat time series vector high-dimensional feature space. instance time series taken algorithm independent others. include random forest (sits_rfor()), support vector machines (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptrons (sits_mlp()).Machine learning algorithms explicitly consider temporal stucture time series. treat time series vector high-dimensional feature space. instance time series taken algorithm independent others. include random forest (sits_rfor()), support vector machines (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptrons (sits_mlp()).Deep learning methods designed work time series. Temporal relations observed values time series taken account. kind models, sits supports 1D convolution neural networks (sits_tempcnn()), residual 1D networks (sits_resnet()), temporal attention-based encoders (sits_tae() sits_lighttae()). algorithms, order samples time series relevant classifier.Deep learning methods designed work time series. Temporal relations observed values time series taken account. kind models, sits supports 1D convolution neural networks (sits_tempcnn()), residual 1D networks (sits_resnet()), temporal attention-based encoders (sits_tae() sits_lighttae()). algorithms, order samples time series relevant classifier.Based experience sits, random forests, extreme gradient boosting, temporal deep learning models outperform SVM multilayer perceptron models. temporal behavior land use land cover classes varies, certain dates providing information others. instance, monitoring deforestation, dates correspond forest removal actions informative earlier later dates. Similarly, crop mapping, dates may capture large portion variation. Classification methods consider temporal order samples therefore likely capture seasonal behavior image time series. Random forest extreme gradient boosting methods use individual measures nodes decision trees can also capture specific events deforestation.following examples show train machine learning methods apply classify single time series. use set samples_matogrosso_mod13q1, containing time series samples Brazilian Mato Grosso state, obtained MODIS MOD13Q1 product. 1,892 samples 9 classes (Cerrado, Fallow_Cotton, Forest, Pasture, Soy_Corn, Soy_Cotton, Soy_Fallow, Soy_Millet, Soy_Sunflower). time series covers 12 months (23 data points) 6 bands (“NDVI”, “EVI”, “BLUE”, “RED”, “NIR”, “MIR”). samples arranged along agricultural year, starting September ending August. data set used paper “Big Earth observation time series analysis monitoring Brazilian agriculture” [42], available R package sitsdata. Please see “Setup” section instructions obtain package.results taken indication method performs better. important factor achieving good result quality training data [26]. Experience shows classification quality depends training samples well model matches samples. examples ML classifying large areas, please see papers authors [3], [42]–[44].","code":""},{"path":"machine-learning-for-data-cubes.html","id":"visualizing-sample-patterns","chapter":"Machine Learning for Data Cubes","heading":"Visualizing Sample Patterns","text":"One useful way describing understanding samples plotting . direct way using plot function, discussed “Working Time Series” chapter. useful alternative estimate statistical approximation idealized pattern based generalized additive models (GAM). GAM linear model linear predictor depends linearly smooth function predictor variables\\[\ny = \\beta_{} + f(x) + \\epsilon, \\epsilon \\sim N(0, \\sigma^2).\n\\]function sits_patterns() uses GAM predict smooth, idealized approximation time series associated label, bands. function based R package dtwSat[45], implements TWDTW time series matching method described [31]. resulting patterns can viewed using plot.\nFigure 42: Patterns samples Mato Grosso.\nresulting patterns provide insights time series behavior class. response Forest class quite distinctive. also shows possible separate single cropping classes double cropping ones. similarities double-cropping classes (Soy_Corn, Soy_Millet, Soy_Sunflower Soy_Sunflower) Cerrado Pasture classes. subtle differences class signatures provide hints possible ways machine leaning algorithms might distinguish classes. One example difference middle-infrared response dry season (May September) distinguish Cerrado Pasture classes.","code":"\n# Estimate the patterns for each class and plot them\nsamples_matogrosso_mod13q1 %>%\n  sits_patterns() %>%\n  plot()"},{"path":"machine-learning-for-data-cubes.html","id":"common-interface-to-machine-learning-and-deep-learning-models","chapter":"Machine Learning for Data Cubes","heading":"Common interface to machine learning and deep learning models","text":"sits_train() function provides common interface machine learning models. function takes two mandatory parameters: training data (samples) ML algorithm (ml_method). model estimated, can used classify individual time series data cubes sits_classify(). follows, show apply method classification single time series. , “Classification Images Data Cubes” discuss classify data cubes.Since sits aimed remote sensing users machine learning experts, provides set default values classification models. settings chosen based testing authors. Nevertheless, users can control parameters model. Novice users can rely default values, experienced ones can fine-tune model parameters meet needs. Model tuning discussed end chapter.set time series organised tibble taken input classifier, result tibble one additional column (“predicted”), contains information labels assigned interval. results can shown text format using function sits_show_prediction() graphically using plot().","code":""},{"path":"machine-learning-for-data-cubes.html","id":"random-forest","chapter":"Machine Learning for Data Cubes","heading":"Random forest","text":"Random forest machine learning algorithm uses ensemble learning method classification tasks. algorithm consists multiple decision trees, decision tree trained different subset training data different subset features. make prediction, decision tree forest independently classifies input data, final prediction made based majority vote decision trees. randomness algorithm comes random subsets data features used train decision tree, helps reduce overfitting improve accuracy model. classifier measures importance feature classification task, can useful feature selection data visualization. Pelletier et al[46] discuss robustness random forest method satellite image time series classification.\nFigure 43: Random forests algorithm (source: Venkata Jagannath Wikipedia - licenced CC--SA 4.0.)\nSITS provides sits_rfor(), uses R randomForest package [47]; main parameter num_trees, number trees grow default value 100. model can visualized using plot().\nFigure 44: important variables random forests model.\nimportant explanatory variables NIR (near infrared) band date 17 (2007-05-25) MIR (middle infrared) band date 22 (2007-08-13). NIR value end May captures growth second crop double cropping classes. Values MIR band end period (late July late August) capture bare soil signatures distinguish agricultural classes natural ones. corresponds summer time ground drier crops harvested.\nFigure 45: Classification time series using random forests.\nresult shows area started forest 2000, deforested 2004 2005, used pasture 2006 2007, double-cropping agriculture 2009 onwards. consistent expert evaluation process land use change region Amazonia.Random forests robust outliers able deal irrelevant inputs [48]. method tends overemphasize variables performance tends stabilize part trees grown [48]. cases abrupt change takes place, deforestation mapping, random forests (properly trained) emphasize temporal instances bands capture quick change.","code":"\n# Train the Mato Grosso samples with Random Forests model.\nrfor_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_rfor(num_trees = 100)\n)\n# plot the most important variables of the model\nplot(rfor_model)\n# retrieve a point to be classified\npoint_mt_4bands <- sits_select(\n  data = point_mt_6bands,\n  bands = c(\"NDVI\", \"EVI\", \"NIR\", \"MIR\")\n)\n# Classify using Random Forest model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_4bands,\n  ml_model  = rfor_model\n)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"support-vector-machines","chapter":"Machine Learning for Data Cubes","heading":"Support Vector Machines","text":"support vector machine (SVM) classifier generalization linear classifier finds optimal separation hyperplane minimizes misclassification [49]. Since set samples \\(n\\) features defines n-dimensional feature space, hyperplanes linear \\({(n-1)}\\)-dimensional boundaries define linear partitions space. classes linearly separable feature space, optimal solution defined maximal margin hyperplane, separating hyperplane farthest training observations[50]. maximal margin computed smallest distance observations hyperplane. solution hyperplane coefficients depends samples define maximum margin criteria, -called support vectors.\nFigure 46: Maximum-margin hyperplane margins SVM trained samples two classes. Samples margin called support vectors. (source: Larhmam Wikipedia - licensed CC--SA-4.0 ).\ndata linearly separable, SVM includes kernel functions map original feature space higher dimensional space, providing nonlinear boundaries original feature space. new classification model, despite linear boundary enlarged feature space, generally translates hyperplane nonlinear boundary original attribute space. Kernels efficient computational strategy produce nonlinear boundaries input attribute space; thus, improve training-class separation. SVM one widely used algorithms machine learning applications applied classify remote sensing data [51].sits, SVM implemented wrapper e1071 R package uses LIBSVM implementation [52], sits package adopts one--one method multiclass classification. \\(q\\) class problem, method creates \\({q(q-1)/2}\\) SVM binary models, one class pair combination tests unknown input vectors throughout models. overall result computed voting scheme.example shows apply SVM method classification time series using default values. main parameters SVM kernel controls whether use non-linear transformation (default radial), cost measures punishment wrongly-classified samples (default 10), cross sets value k-fold cross validation (default 10).\nFigure 47: Classification time series using SVM.\nSVM classifier less stable less robust outliers random forests method. example, tends misclassify data. 2008, likely land cover still “Pasture” rather “Soy_Millet” produced algorithm, “Soy_Cotton” class 2012 also inconsistent previous latter classification “Soy_Corn”.","code":"\n# Train a SVM model\nsvm_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_svm()\n)\n# Classify using SVM model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_4bands,\n  ml_model = svm_model\n)\n# plot the result\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"extreme-gradient-boosting","chapter":"Machine Learning for Data Cubes","heading":"Extreme Gradient Boosting","text":"boosting method based idea starting weak predictor improving performance sequentially fitting better model iteration. starts fitting simple classifier training data, using residuals fit build predictor. Typically, base classifier regression tree. Although random forests boosting use trees classification, important differences. performance random forests generally increases number trees becomes stable. Boosting trees improve previous result applying finer divisions improve performance [48]. However, number trees grown boosting techniques limited risk overfitting.Gradient boosting variant boosting methods cost function minimized gradient descent. Extreme gradient boosting [53], called XGBoost, efficient approximation gradient loss function. recent papers show outperforms random forests remote sensing image classification[54]. However, result generalizable, since actual performance controlled quality training data set.SITS, XGBoost method implemented sits_xbgoost() function, based XGBoost R package five hyperparameters require tuning. sits_xbgoost() function takes user choices input cross validation determine suitable values predictor.learning rate eta varies 0.0 1.0 kept small (default 0.3) avoid overfitting. minimum loss value gamma specifies minimum reduction required make split. default 0; increasing makes algorithm conservative. max_depth value controls maximum depth trees. Increasing value make model complex likely overfit (default 6). subsample parameter controls percentage samples supplied tree. default 1 (maximum). Setting lower values means xgboost randomly collects part data instances grow trees, thus preventing overfitting. nrounds parameter controls maximum number boosting interactions; default 100, proven enough cases. order follow convergence algorithm, users can turn verbose parameter . general, results using extreme gradient boosting algorithm similar random forests method.\nFigure 48: Classification time series using XGBoost.\n","code":"\n# Train using  XGBoost\nxgb_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_xgboost(verbose = 0)\n)\n# Classify using SVM model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_4bands,\n  ml_model = xgb_model\n)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"deep-learning-using-multilayer-perceptrons","chapter":"Machine Learning for Data Cubes","heading":"Deep learning using multilayer perceptrons","text":"support deep learning methods, sits uses torch R package, takes Facebook torch C++ library back-end. Machine learning algorithms use R torch package similar developed using PyTorch. Converting image time series algorithms developed PyTorch using sits straightforward. Please see chapter “Extensibility” guidance include new deep learning algorithms sits.simplest deep learning method multilayer perceptrons (MLPs), feedforward artificial neural networks. MLP consists three kinds nodes: input layer, set hidden layers output layer. input layer dimension number features data set. hidden layers attempt approximate best classification function. output layer makes decision class assigned input.sits, users build MLP models using sits_mlp(). Since established model generic classification satellite image time series, designing MLP models requires parameter customization. important decisions number layers model number neurons per layer. values set layers parameters, list integer values. size list number layers element list indicates number nodes per layer.choice number layers depends inherent separability data set classified. data sets classes different signatures, shallow model (3 layers) may provide appropriate responses. complex situations require models deeper hierarchy. user aware models many hidden layers may take long time train may able converge. suggestion start 3 layers test different options number neurons per layer, increasing number layers.MLP models also need include activation function. activation function node defines output node given input set inputs. Following standard practices [41], use relu activation function.Users can also define optimization method (optimizer), defines gradient descent algorithm used. methods aim maximize objective function updating parameters opposite direction gradient objective function [55]. Based experience image time series, recommend users start using default method provided sits, optimizer_adamw method package torchopt. Please refer torchopt package additional information.Another relevant parameter list dropout rates (dropout). Dropout technique randomly dropping units neural network training [56]. randomly discarding neurons, dropout reduces overfitting. Since purpose cascade neural nets improve learning data acquired, discarding neurons may seem waste resources. practice, dropout prevents early convergence local minimum [41]. suggest users experiment different dropout rates, starting small values (10-30%) increasing required.following example shows use sits_mlp(). default parameters chosen based modified verion [57], proposes use multilayer perceptrons baseline time series classification. parameters : () Three layers 512 neurons , specified parameter layers; (b) Using “relu” activation function; (c) dropout rates 40%, 30%, 20% layers; (d) “optimizer_adamw” optimizer (default value); (e) number training steps (epochs) 100; (f) batch_size 64, indicates many time series used input given steps; (g) validation percentage 20%, means 20% samples randomly set side validation.experience, training data good quality, using 3 5 layers reasonable compromise. increase number layers improve model. simplify output generation, verbose option turned . default value “”. model generated, plot training history.\nFigure 49: Evolution training accuracy MLP model.\n, classify 16-year time series using multilayer perceptron model.\nFigure 50: Classification time series using MLP.\ntheory, multilayer perceptron model able capture subtle changes random forests XGBoost models. specific case, result similar . Although model mixes “Soy_Corn” “Soy_Millet” classes, distinction temporal signatures quite subtle. Also case, suggests need improve number samples. examples, MLP model shows increase sensitivity compared previous models. recommend users compare different configurations, since MLP model sensitive changes parameters.","code":"\n# train using an MLP model\n# this is an example of how to set parameters\n# first-time users should test default options first\nmlp_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_mlp(\n    layers           = c(512, 512, 512),\n    dropout_rates    = c(0.40, 0.30, 0.20),\n    epochs           = 100,\n    batch_size       = 64,\n    verbose          = FALSE,\n    validation_split = 0.2\n  )\n)\n# show training evolution\nplot(mlp_model)\n# Classify using DL model and plot the result\npoint_mt_6bands %>%\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NIR\", \"MIR\")) %>%\n  sits_classify(mlp_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"temporal-convolutional-neural-network-tempcnn","chapter":"Machine Learning for Data Cubes","heading":"Temporal Convolutional Neural Network (TempCNN)","text":"Convolutional neural networks (CNN) class deep learning methods apply convolution filters (sliding window) input data sequentially. Temporal Convolutional Neural Network (TempCNN) neural network architecture specifically designed processing sequential data time series. case time series, 1D CNN applies moving temporal window time series produces another time series result convolution.TempCNN applies one-dimensional convolutions input sequence capture temporal dependencies, allowing network learn long-term dependencies input sequence. layer model captures temporal dependencies different scale. Due multi-scale approach, TempCNN capable capturing complex temporal patterns data producing accurate predictions.TempCNN architecture satellite image time series classification proposed Pelletier et al [58]. three 1D convolutional layers, final softmax layer classification (see figure). authors use combination different methods avoid overfitting reduce vanishing gradient effect, including dropout, regularization, batch normalisation. TempCNN reference paper [58], authors compare favorably model Recurrent Neural Network proposed Russwurm Körner [59] land use classification. figure shows architecture TempCNN model.\nFigure 51: Structure tempCNN architecture (source: Pelletier et al.(2019))\nfunction sits_tempcnn() implements model. parameter cnn_layers controls number 1D-CNN layers size filters applied layer; default values three CNNs 128 units. parameter cnn_kernels indicates size convolution kernels; default kernels size 7. Activation 1D-CNN layers uses “relu” function. dropout rates 1D-CNN layer controlled individually parameter cnn_dropout_rates. validation_split controls size test set, relative full data set. recommend set aside least 20% samples validation.\nFigure 52: Training evolution TempCNN model.\n, classify 16-year time series using TempCNN model.\nFigure 53: Classification time series using TempCNN.\nresult important differences previous ones. TempCNN model indicates “Soy_Cotton” class likely one 2004. result likely wrong, shows time series year 2004 different “Forest” “Pasture” classes. One possible explanation forest degradation 2004, leading signature mix forest bare soil. case, users consider improving training data including samples represent forest degradation. experience, TempCNN models reliable way classifying image time series [60]. Recent work compares different models also provides evidence TempCNN models satisfactory behavior, especially case crop classes [61].","code":"\nlibrary(torchopt)\n# train using tempCNN\ntempcnn_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_tempcnn(\n    optimizer            = torchopt::optim_adamw,\n    cnn_layers           = c(128, 128, 128),\n    cnn_kernels          = c(7, 7, 7),\n    cnn_dropout_rates    = c(0.2, 0.2, 0.2),\n    epochs               = 100,\n    batch_size           = 64,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n\n# show training evolution\nplot(tempcnn_model)\n# Classify using TempCNN model and plot the result\nclass <- point_mt_6bands %>%\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NIR\", \"MIR\")) %>%\n  sits_classify(tempcnn_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"residual-1d-cnn-networks-resnet","chapter":"Machine Learning for Data Cubes","heading":"Residual 1D CNN Networks (ResNet)","text":"residual 1D CNN network, also known ResNet, extension standard 1D CNN architecture, addition residual connections layers. Residual connections allow network learn residual mappings, difference input output layer. adding residual connections, network can learn bypass certain layers still capture important features data.Residual Network (ResNet) time series classification proposed Wang et al. [57], based idea deep residual networks 2D image recognition [62]. ResNet architecture composed 11 layers, three blocks three 1D CNN layers (see figure ). block corresponds 1D CNN architecture. output block combined shortcut links output input, called “skip connection”. purpose combining input layer block output layer (convolutions) avoid -called “vanishing gradient problem”. issue occurs deep networks neural network’s weights updated based partial derivative error function. gradient small, weights updated, stopping training[63]. Skip connections aim avoid vanishing gradients occurring, allowing deep networks trained.\nFigure 54: Structure ResNet architecture (source: Wang et al.(2017)).\nsits, Residual Network implemented using sits_resnet() function. default parameters proposed Wang et al. [57], implemented Fawaz et al.[64]. first parameter blocks, controls number blocks size filters block. default, model implements three blocks, first 64 filters others 128 filters. Users can control number blocks filter size changing parameter. parameter kernels controls size kernels three layers inside block. found useful experiment bit kernel sizes case satellite image time series. default activation “relu”, recommended literature reduce problem vanishing gradients. default optimizer optim_adamw, available package torchopt.\nFigure 55: Training evolution ResNet model.\n, classify 16-year time series using ResNet model. behaviour ResNet model similar TempCNN, variability.\nFigure 56: Classification time series using ResNet.\n","code":"\n# train using ResNet\nresnet_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_resnet(\n    blocks               = c(64, 128, 128),\n    kernels              = c(7, 5, 3),\n    epochs               = 100,\n    batch_size           = 64,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# show training evolution\nplot(resnet_model)\n# Classify using DL model and plot the result\nclass <- point_mt_6bands %>%\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NIR\", \"MIR\")) %>%\n  sits_classify(tempcnn_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"attention-based-models","chapter":"Machine Learning for Data Cubes","heading":"Attention-based models","text":"Attention-based deep learning models class models use mechanism inspired human attention focus specific parts input processing. models shown effective various tasks machine translation, image captioning, speech recognition.basic idea behind attention-based models allow model selectively focus different parts input different times. can done introducing mechanism assigns weights element input, indicating relative importance element current processing step. model can use compute weighted sum input. results capture model’s attention specific parts input.Attention-based models become one used deep learning architectures problems involve sequential data inputs, e.g., text recognition automatic translation. general idea applications language translation inputs alike. Consider English sentence “Look lonely people”. good translation system needs relate words “look” “people” key parts sentence ensure link captured translation. specific type attention models, called transformers, enables recognition complex relationships input output sequences [65].basic structure transformers neural network algorithms. encoder transforms input textual values numerical vectors, decoder processes vectors provides suitable answers. difference values handled internally. multilayer perceptrons (MLP), inputs treated equally first; based iterative matching training test data, backpropagation technique feeds information back initial layers identify relevant combination inputs produces best output. convolutional nets (CNN), input values close time (1D) space (2D) combined produce higher-level information helps distinguish different components input data. text recognition, initial choice deep learning studies use recurrent neural networks (RNN) handle input sequences sequentially. However, neither MLPs, CNNs RNNs able capture structure complex inputs natural language. success transformer-based solutions accounts substantial improvements natural language processing.two main differences transformer models algorithms use positional encoding self-attention. Positional encoding assigns index input value ensures relative locations inputs maintained throughout learning processing phases. Self-attention works comparing every word sentence every word sentence, including . way, learns contextual information relation words. conception validated large language models BERT [66] GPT-3 [67].application attention-based models satellite image time series analysis proposed Garnot et [68] Russwurm Körner [61]. self-attention network can learn focus specific time steps image features relevant distinguishing different classes. algorithm tries identify combination individual temporal observations relevant identify class. example, crop identification use observations capture onset growing season, date maximum growth, end growing season. case deforestation, algorithm tries identify dates forest cut. Attention-based models means indentify events characterize land use land cover class.first model proposed Garnot co-authors full transformer-based model [68]. Considering image time series classification easier task natural language processing, Garnot et al [69] also propose simplified version full transformer model. simpler model uses reduced way compute attention matrix, reducing time training classification without loss quality result.sits, full transformer-based model proposed Garnot co-authors [68] implemented using sits_tae() function. default parameters proposed authors. default optimizer optim_adamw, available package torchopt.\nFigure 57: Training evolution Temporal Self-Attention model.\n, classify 16-year time series using TAE model.\nFigure 58: Classification time series using TAE.\nGarnot co-authors [68] also proposed Lightweight Temporal Self-Attention Encoder. lightweight self-attention encoder model can achieve high classification accuracy fewer parameters compared neural network models. makes good choice applications computational resources limited. sits_lighttae() function implements algorithm. default optimizer optim_adamw, available package torchopt. important parameter set learning rate lr. Values ranging 0.001 0.005 produce reasonable results. See also section model tuning.\nFigure 59: Training evolution Lightweight Temporal Self-Attention model.\n, classify 16-year time series using LightTAE model.\nFigure 60: Classification time series using LightTAE.\nbehaviour sits_tae() sits_lighttae() similar sits_tempcnn(). points possible need classes training data better represent transition period 2004 2010. One possibility training data associated Pasture class consistent time series years 2005 2008. However, transition Forest Pasture 2004 Pasture Agriculture 2009-2010 subject uncertainty, since classifiers agree resulting classes. general, deep learning temporal-aware models sensitive class variability random forests extreme gradient boosters.","code":"\n# train a machine learning model using TAE\ntae_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_tae(\n    epochs               = 150,\n    batch_size           = 64,\n    optimizer            = torchopt::optim_adamw,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# show training evolution\nplot(tae_model)\n# Classify using DL model and plot the result\nclass <- point_mt_6bands %>%\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NIR\", \"MIR\")) %>%\n  sits_classify(tae_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))\n# train a machine learning model using TAE\nltae_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_lighttae(\n    epochs = 150,\n    batch_size = 64,\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(lr = 0.001),\n    validation_split = 0.2\n  )\n)\n# show training evolution\nplot(ltae_model)\n# Classify using DL model and plot the result\nclass <- point_mt_6bands %>%\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NIR\", \"MIR\")) %>%\n  sits_classify(ltae_model) %>%\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"model-tuning","chapter":"Machine Learning for Data Cubes","heading":"Model tuning","text":"Deep learning model tuning process selecting best set hyperparameters specific application. Model tuning enables better fit algorithm training data. Hyperparameters parameters model learned training, instead set prior training affect behavior model training. Examples include learning rate, batch size, number epochs, number hidden layers, number neurons layer, activation functions, regularization parameters, optimization algorithms.Deep learning model tuning involves selecting best combination hyperparameters results optimal performance model given task. done training evaluating model different sets hyperparameters selecting set gives best performance.Deep learning algorithms try find optimal point represents best value prediction function , given input \\(X\\) data points, predicts result \\(Y\\). case, \\(X\\) multidimensional time series \\(Y\\) vector probabilities possible output classes. complex situations, best prediction function time consuming estimate. reason, deep learning methods rely gradient descent methods speed predictions converge faster exhaustive search [70]. gradient descent methods use optimization algorithm adjusted hyperparameters learning rate regularization rate [71]. learning rate controls numerical step gradient descent function regularization rate controls model overfitting. Adjusting values optimal setting requires use model tuning methods.reduce learning curve, sits provides default values machine learning deep learning methods, ensure reasonable baseline performance. experienced users may want refine model hyperparameters, especially complex models sits_lighttae() sits_tempcnn(). end, package provides sits_tuning() function.simplest approach model tuning run grid search; involves defining range hyperparameter testing possible combinations. approach leads combinational explosion thus recommended. Instead, Bergstra Bengio [72] propose use randomly chosen trials. paper, authors show random trials efficient grid search trials, allowing selection adequate hyperparameters fraction computational cost. sits_tuning() function follows Bergstra Bengio [72] uses random search chosen hyperparameters.Since gradient descent plays key role deep learning model fitting, developing optimizers important topic research [73]. large number optimizers proposed literature, recent results reviewed Schmidt et al. [71]. general deep learning applications, Adam optimizer [74] provides good baseline reliable performance. reason, Adam default optimizer R torch package. Experiments image time series show optimizers may better performance specific problem land use classification. reason, authors developed torchopt R package includes number recently proposed optimizers, including Adamw [75], Madgrad [76] Yogi [77]. Based experiments, selected Adamw default optimizer deep learning methods. Using sits_tuning() function allows testing optimizers available torch torch_opt packages.sits_tuning() function takes following parameters:samples - Training data set used model.samples_validation (optional) - available, data set contains time series used validation. missing, next parameter used.validation_split - samples_validation used, parameter defines proportion time series training data set used validation (default 20%).ml_method() - Deep learning method (either sits_mlp(), sits_tempcnn(), sits_resnet(), sits_tae() sits_lighttae())params - defines optimizer hyperparameters calling sits_tuning_hparams() function, shown example .trials - number trials run random search.multicores - number cores used procedure.progress - show progress bar?sits_tuning_hparams() function inside sits_tuning() allows users define optimizers hyperparameters including lr (learning rate), eps (controls numerical stability) weight_decay (controls overfitting). default values eps weight_decay sits deep learning functions 1.0e-08 1.0e-06, respectively. default lr sits_lighttae() sits_tempcnn() 0.005, sits_tae() sits_resnet() 0.001. Users different ways randomize hyperparameters, including: choice() (list options), uniform (uniform distribution), randint (random integers uniform distribution), normal(mean, sd) (normal distribution), beta(shape1, shape2)(beta distribution). options allow extensive combination hyperparameters.example, sits_tuning() function finds good hyperparameters train sits_lighttae() method Mato Grosso data set. tests 100 combinations learning rate weight decay Adamw optimizer. randomize learning rate, uses beta distribution parameters 0.35 10, allows variation 0.2 1.0e-00; weight decay, beta distribution parameters 0.1 2 generates values roughly 1 1.0e-24.result tibble different values accuracy, kappa, decision matrix, hyperparameters. 10 best results obtain accuracy values 0.976 0.958, shown . best result obtained learning rate 0.0011 weight decay 2.14e-05,large data sets, tuning process time consuming. Despite cost, recommended achieving best performance. general, tuning hyperparameters models sits_tempcnn() sits_lighttae() result slight performance improvement default parameters overall accuracy. performance gain stronger less well represented classes, significant gains producer’s user’s accuracies possible. cases one wants detect change less frequent classes, tuning can make difference results.","code":"\ntuned <- sits_tuning(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_lighttae(),\n  params = sits_tuning_hparams(\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(\n      lr = beta(0.35, 10),\n      weight_decay = beta(0.1, 2)\n    )\n  ),\n  trials = 100,\n  multicores = 6,\n  progress = FALSE\n)\n# obtain accuracy, kappa, lr and weight decay for the 10 best results\n# hyperparameters are organized as a list\nhparams_10 <- tuned[1:10, ]$opt_hparams\n# extract learning rate and weight decay from the list\nlr_10 <- purrr::map_dbl(hparams_10, function(h) h$lr)\nwd_10 <- purrr::map_dbl(hparams_10, function(h) h$weight_decay)\n\n# create a tibble to display the results\nbest_10 <- tibble::tibble(\n  accuracy = tuned[1:10, ]$accuracy,\n  kappa = tuned[1:10, ]$kappa,\n  lr = lr_10,\n  weight_decay = wd_10\n)\n# print the best combination of hyperparameters\nbest_10#> # A tibble: 10 × 4\n#>    accuracy kappa       lr weight_decay\n#>       <dbl> <dbl>    <dbl>        <dbl>\n#>  1    0.976 0.972 0.00117      2.14e- 5\n#>  2    0.971 0.965 0.00125      2.07e- 4\n#>  3    0.968 0.962 0.000281     2.70e- 2\n#>  4    0.966 0.959 0.000418     1.54e- 2\n#>  5    0.963 0.956 0.000432     1.76e- 6\n#>  6    0.960 0.953 0.000263     2.35e- 4\n#>  7    0.960 0.953 0.000254     3.13e- 3\n#>  8    0.958 0.950 0.000973     1.35e- 2\n#>  9    0.958 0.949 0.000694     8.95e-15\n#> 10    0.958 0.950 0.000428     1.09e- 1"},{"path":"machine-learning-for-data-cubes.html","id":"considerations-on-model-choice","chapter":"Machine Learning for Data Cubes","heading":"Considerations on model choice","text":"development machine learning methods classification satellite image time series ongoing task. lot recent work using methods convolutional neural networks [78] temporal self-attention [68]. Given rapid evolution field new methods still developed, references offer comparison different machine learning methods. works literature [64] compare methods generic time series classification. insights directly applicable satellite image time series data, different properties time series using applications economics health.specific case satellite image time series, Russwurm et al. [61] present comparative study seven deep neural networks classification agricultural crops, using random forests (RF) baseline. data composed Sentinel-2 images Britanny, France. results indicate slight difference best model (attention-based transformer model) TempCNN, ResNet RF. Attention-based models obtain accuracy ranging 80-81%, TempCNN get 78-80%, RF gets 78%. Based result also authors’ experience, make following recommendations:Random forests provide good baseline image time series classification included users’ assessments.Random forests provide good baseline image time series classification included users’ assessments.XGBoost worthy alternative Random forests. principle, XGBoost sensitive data variations cost possible overfitting.XGBoost worthy alternative Random forests. principle, XGBoost sensitive data variations cost possible overfitting.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.Attention-based models (TAE LightTAE) can achieve best overall performance, case well designed balanced training sets hyperparameter tuning.Attention-based models (TAE LightTAE) can achieve best overall performance, case well designed balanced training sets hyperparameter tuning.best means improving classification performance provide accurate reliable training data set. class enough samples account spatial temporal variability.best means improving classification performance provide accurate reliable training data set. class enough samples account spatial temporal variability.","code":""},{"path":"image-classification-in-data-cubes.html","id":"image-classification-in-data-cubes","chapter":"Image Classification in Data Cubes","heading":"Image Classification in Data Cubes","text":"chapter, discuss classify data cubes providing step--step example. study area state Rondonia, Brazil, underwent substantial deforestation last decades. objective case study detect deforested areas.","code":""},{"path":"image-classification-in-data-cubes.html","id":"training-the-classification-model","chapter":"Image Classification in Data Cubes","heading":"Training the classification model","text":"case study uses training data set samples_prodes_4bands, available package sitsdata. data set consists 480 samples collected Sentinel-2 images covering state Rondonia. samples intended detect deforestation events, include four classes: “Forest”, “Burned_Area”, “Cleared_Area”, “Highly_Degraded”. time series cover set 29 dates period 16 days, ranging “2020-06-04” “2021-08-26”. data 12 attributes, including original bands (“B02”, “B03”, “B04”, “B05”, “B08”, “B8A”, “B11”, “B12”) indices (“NDVI”, “EVI” “NBR”).better understand training set, useful plot basic patterns associated samples. function sits_patterns() uses generalized additive model (GAM) predict smooth, idealized approximation time series associated label, bands. Since data cube used classification three bands (“B02”, “B8A”, “B11”), filter samples bands showing patterns.\nFigure 61: Patterns associated training samples\npatterns show different temporal responses selected classes. match typical behavior deforestation Amazon. First, forest cut start dry season (June/July). end dry season, clear-cut areas burned clean remains; action reflected steep fall response “B8A” values burned area samples July. areas cleared burned, response middle infra-red band “B11” increases significantly end dry season, “B8A” values remain high. sign mixed pixels combine forest remains bare soil. Forest areas show constant spectral response year. Degraded areas show increase values middle infra-red band “B11” compared native forests, showing mixed response vegetation soil.","code":"\nlibrary(sitsdata)\n# obtain the samples\ndata(\"samples_prodes_4classes\")\n# show the contents of the samples\nsits_labels_summary(samples_prodes_4classes)#> # A tibble: 4 × 3\n#>   label           count  prop\n#>   <chr>           <int> <dbl>\n#> 1 Burned_Area        96 0.244\n#> 2 Cleared_Area      115 0.293\n#> 3 Forest            107 0.272\n#> 4 Highly_Degraded    75 0.191\nsamples_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n)\nplot(sits_patterns(samples_3bands))"},{"path":"image-classification-in-data-cubes.html","id":"building-a-data-cube","chapter":"Image Classification in Data Cubes","heading":"Building a data cube","text":"now build data cube Sentinel-2 images available package sitsdata. images downloaded SENTINEL-2-L2A collection Microsoft Planetary Computer (MPC). chosen bands “BO2”, “B8A” “B11” images small area 1000 x 1000 pixels state Rondonia. explained “Earth observation data cubes” chapter, need inform sits parse file names obtain tile, date band information. Image files named according convention “cube_tile_band_date” (e.g., cube_20LKP_BO2_2020_06_04.tif).\nFigure 62: Color composite image cube date 2021-07-25\n","code":"\n# files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LKP/\", package = \"sitsdata\")\n# read data cube\nro_cube_20LKP <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\"X1\", \"tile\", \"band\", \"date\")\n)\n\n# plot the cube\nplot(ro_cube_20LKP, dates = \"2021-07-25\", red = \"B11\", green = \"B8A\", blue = \"B02\")"},{"path":"image-classification-in-data-cubes.html","id":"training-a-deep-learning-model","chapter":"Image Classification in Data Cubes","heading":"Training a deep learning model","text":"next step train Lightweigth Temporal Attentiona Enconder model model, using adamw optimizer learning rate 0.001. Since data cube classified bands BO2, B8A B11, select bands training data.\nFigure 63: Training evolution LightTAE model.\n","code":"\n# use only the bands available in the cube\nsamples_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = sits_bands(ro_cube_20LKP)\n)\n\n# train model using LightTAE algorithm\nltae_model <- sits_train(\n  samples = samples_3bands,\n  ml_method = sits_lighttae(\n    opt_hparams = list(lr = 0.001)\n  )\n)\n# plot the evolution of the model\nplot(ltae_model)"},{"path":"image-classification-in-data-cubes.html","id":"classification-using-parallel-processing","chapter":"Image Classification in Data Cubes","heading":"Classification using parallel processing","text":"classify data cubes sets time series, use function sits_classify(), uses parallel processing speed performance, described end Chapter. relevant parameters : () data, either data cube set time series; (b) ml_model, trained model using one machine learning methods provided; (c) multicores, number CPU cores used processing; (d) memsize, memory available classification; (e) output_dir, directory results stored; (f) version, version control. users want follow processing steps, turn parameters verbose print information progress get progress bar. result classification data cube set probability layers, one output class. probability layer contains model’s assessment likely pixel belong related class. probability cube can visualized plot().\nFigure 64: Probability maps produced LightTAE model.\nprobability cube useful tool data analysis. used post-processing smoothing, described Chapter, also uncertainty estimates active learning, described “Uncertainty Active Learning” Chapter.\nFigure 65: Final classification map.\nlabelled map generated pixel-based time series classification method exhibits number misclassified pixels, depicted small patches appear surrounded different class. occurrence outliers common issue arises due inherent nature classification approach. Mixed pixels prevalent images, regardless resolution, class exhibits considerable degree data variability. result, factors can lead outliers higher probability misclassified. overcome limitation, sits employs post-processing smoothing techniques leverage spatial context probability cubes refine results.","code":"\n# classify data cube\nro_cube_20LKP_probs <- sits_classify(\n  data = ro_cube_20LKP,\n  ml_model = ltae_model,\n  output_dir = \"./tempdir/chp9\",\n  version = \"ltae\",\n  multicores = 4,\n  memsize = 12\n)\nplot(ro_cube_20LKP_probs, palette = \"YlGn\")\n# generate thematic map\ndefor_map <- sits_label_classification(\n  cube = ro_cube_20LKP_probs,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp9\",\n  version = \"no_smooth\"\n)\nplot(defor_map)"},{"path":"image-classification-in-data-cubes.html","id":"bayesian-smoothing","chapter":"Image Classification in Data Cubes","heading":"Bayesian smoothing","text":"sits package uses time-first, space-later approach. Since machine learning classifiers sits mostly pixel-based, necessary complement smooth labeling methods. methods improve accuracy land-cover classification incorporating spatial contextual information classification process. Smoothing methods use neighborhood information remove outliers enhance consistency resulting product. smoothing method available sits uses Bayesian inference.Bayesian inference can thought way coherently updating uncertainty light new evidence. allows inclusion expert knowledge derivation probabilities. Bayesian smoothing works considering combination two elements: () prior belief class probabilities; (b) estimated probabilities given pixel. estimate prior distribution class probabilities pixel, use values neighbors. assumption , local level, class probabilities similar provide baseline comparison pixel values produced classifier. Based two elements, Bayesian smoothing adjusts probabilities pixel based prior beliefs.intuition Bayesian smoothing homogeneous neighborhoods class. situations occur high average probability single class, associated low variance. case, local effects dominate. Pixels assigned different class updated one dominates neighborhood. cases, prior probability said informative. contrast, neighborhoods average probability frequent class high high variance values, likely pixel misclassified. Bayesian smoothing improves classification results removing pixels classifier low confidence.One expected consequence Bayesian smoothing improve borders objects created classification. pixel-based classification, mixed pixels limits areas different classes pose problem classification. pixels contain signatures two classes. account cases, Bayesian smoothing sits uses special definition neighborhood. pixel probability map class associated neighborhood half size local window. pixels neighborhood highest probability belonging class.run Bayesian smoothing, parameter sits_smooth() : () cube, probability cube produced sits_classify(); (b) type bayes (default); (c) window_size, local window compute neighborhood probabilities; (d) neigh_fraction, fraction local neighbors used calculate local statistics; (e) smoothness, estimate local variance (see Technical Annex details); (f) multicores, number CPU cores used processing; (g) memsize, memory available classification; (h) output_dir, directory results stored; () version, version control. resulting cube can visualized plot(). bigger one sets window_size smoothness parameters, stronger adjustments . follows, compare two situations smoothing effects, varying window_size smoothness parameters.explained , window_size parameter controls size neighborhood. However, pixels inside window included Bayesian estimator. reliable, local class statistics include pixels likely belong class. Windows centered border pixels contain pixels belonging class central pixel; others belongs different class. Consider window size 9 x 9 around pixel probability map class “Forest”. contain central pixel 80 neighbors. Instead using neighbors compute local statistics, sits uses . number neighbors used calculate local statistics set taking highest probability belonging class “Forest”. percentage pixel per window used calculate local class statistics set neigh_fraction parameter.Together, parameters window_size neigh_fraction control many pixels neighborhood used calculate local statistics used Bayesian estimator. Since estimator based Gaussian distributions, needs least 30 samples produce statistical significant values. example, setting window size 9 neigh_fraction 0.5 (defaults) ensures least 40 samples used estimate local statistics.\nFigure 66: Probability maps bayesian smoothing.\nBayesian smoothing removed local variability associated misclassified pixels different neighbors. impact smoothing best appreciated comparing labelled map produced without smoothing one follows procedure, shown .\nFigure 67: Final classification map Bayesian smoothing 5 x 5 window smoothness = 30.\nproduce even stronger smoothing effect, example uses bigger values window_size smoothness.\nFigure 68: Probability maps bayesian smoothing 9 x 9 window smoothness = 80.\n\nFigure 69: Final classification map Bayesian smoothing 9 x 9 size.\nComparing two maps, apparent smoothing procedure reduced lot noise original classification produced homogeneous result. Although pleasing eye, map may accurate previous one, since much spatial details lost. general, Bayesian smoothing improves quality final labelled maps thus applied situations.","code":"\n# compute Bayesian smoothing\ncube_smooth_w9_s20 <- sits_smooth(\n  cube = ro_cube_20LKP_probs,\n  type = \"bayes\",\n  window_size = 9,\n  neigh_fraction = 0.50,\n  smoothness = 20,\n  multicores = 4,\n  memsize = 12,\n  version = \"bayes_w9_s20\",\n  output_dir = \"./tempdir/chp9\"\n)\n# plot the result\nplot(cube_smooth_w9_s20, palette = \"YlGn\")\n# generate thematic map\ndefor_map_smooth_w9_20 <- sits_label_classification(\n  cube = cube_smooth_w9_s20,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp8\",\n  version = \"bayes_w9_s20\"\n)\nplot(defor_map_smooth_w9_20)\n# compute Bayesian smoothing\ncube_smooth_w13_s80 <- sits_smooth(\n  cube = ro_cube_20LKP_probs,\n  type = \"bayes\",\n  window_size = 13,\n  smoothness = 80,\n  multicores = 4,\n  memsize = 12,\n  version = \"bayes_w13_s80\",\n  output_dir = \"./tempdir/chp8\"\n)\n# plot the result\nplot(cube_smooth_w13_s80, palette = \"YlGn\")\n# generate thematic map\ndefor_map_smooth_w13_s80 <- sits_label_classification(\n  cube = cube_smooth_w13_s80,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp8\",\n  version = \"bayes_w13_s80\"\n)\nplot(defor_map_smooth_w13_s80, palette = \"YlGn\")"},{"path":"image-classification-in-data-cubes.html","id":"map-reclassification","chapter":"Image Classification in Data Cubes","heading":"Map Reclassification","text":"Reclassification remote sensing map refers process changing classes assigned different pixels image. purpose reclassification modify information contained image better suit specific use case. sits, reclassification involves assigning new class labels pixels based additional information provided reference map. Based labels classification reference map, users defines rules based desired outcome. rules applied classified map. result new map updated labels.illustrate reclassification operation sits, take classified data cube, stored sitsdata package. discussed “Earth observation data cubes” chapter, sits can create data cube classified image file. Users need provide original data source collection, directory data stored (data_dir), information retrieve data cube parameters file names (parse_info), labels associated classified image.\nFigure 70: original classification map.\nmap shows total extent deforestation clear cuts estimated sits random forest algorithm area Rondonia, Brasil, based time series Sentinel-2 images period 2020-06-04 2021-08-26. Suppose want estimate deforestation ocurred period June 2020 August 2021. need reference map contains information forest cuts prior 2020.example, PRODES deforestation map Amazonia created Brazil’s National Institute Space Research (INPE) refence. map produced visual interpretation. PRODES measures deforestation yearly basis, starting August one year July following year. contains classes represent natural world (“Forest”, “Water”, “NonForest”, “NonForest2”) classes capture yearly deforestation increments. classes labelled “dYYYY” “rYYYY”; first label refers deforestation given year (e.g., “d2008” deforestation August 2007 July 2008); second places satellite data sufficient determine land cover (e.g, “r2010” 2010). map available package “sitsdata”, shown .Since labels deforestation map specialized part default sits color table, define legend better visualisation different deforestation classes. Using new legend, can plot PRODES deforestation map.\nFigure 71: Deforestation map produced PRODES.\nTaking PRODES map refence, can include new labels classified map produced sits using sits_reclassify(). new label “Defor_2020” applied pixels PRODES considers deforested prior July 2020. also include new label “Non_Forest” include pixels PRODES takes covered native vegetation, wetlands rocky areas. PRODES classes used mask sits deforestation map.sits_reclassify() operation requires parameters: () cube, classified data cube whose pixels reclassified; (b) mask, reference data cube used mask; (c) rules, named list. names rules list new labels classified cube. new label associated mask vector includes labels reference map joined. sits_reclassify() compares original reference map pixel pixel. pixel reference map whose labels one rules, algorithm relabels original map. result reclassified map original labels plus new labels masked using reference map.\nFigure 72: Deforestation map sits masked PRODES map.\nreclassified map split deforestation prior mid-2020 (using PRODES map) areas classified sits taken deforested period mid-2020 mid-2021. allows experts measure much deforestation occurred period according sits compare result PRODES visual interpretation map.sits_reclassify() operation restricted comparison deforestation maps. can used case requires masking result based reference map.","code":"\n# Open classification map\ndata_dir <- system.file(\"extdata/Rondonia-Class\", package = \"sitsdata\")\nro_class <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\n    \"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  ),\n  bands = \"class\",\n  labels = c(\n    \"Water\", \"ClearCut_Burn\", \"ClearCut_Soil\",\n    \"ClearCut_Veg\", \"Forest\", \"Bare_Soil\", \"Wetland\"\n  )\n)\nplot(ro_class)\ndata_dir <- system.file(\"extdata/PRODES\", package = \"sitsdata\")\nprodes2021 <- sits_cube(\n  source = \"USGS\",\n  collection = \"LANDSAT-C2L2-SR\",\n  data_dir = data_dir,\n  parse_info = c(\n    \"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  ),\n  bands = \"class\",\n  version = \"v20220606\",\n  labels = c(\n    \"Forest\", \"Water\", \"NonForest\",\n    \"NonForest2\", \"NoClass\", \"d2007\", \"d2008\",\n    \"d2009\", \"d2010\", \"d2011\", \"d2012\",\n    \"d2013\", \"d2014\", \"d2015\", \"d2016\",\n    \"d2017\", \"d2018\", \"r2010\", \"r2011\",\n    \"r2012\", \"r2013\", \"r2014\", \"r2015\",\n    \"r2016\", \"r2017\", \"r2018\", \"d2019\",\n    \"r2019\", \"d2020\", \"NoClass\", \"r2020\",\n    \"Clouds2021\", \"d2021\", \"r2021\"\n  )\n)\n# use the RColorBrewer pallete \"YlOrBr\" for the deforestation years\ncolors <- grDevices::hcl.colors(n = 15, palette = \"YlOrBr\")\n# define the legend for the deforestation map\ndef_legend <- c(\n  \"Forest\" = \"forestgreen\", \"Water\" = \"dodgerblue3\",\n  \"NonForest\" = \"bisque2\", \"NonForest2\" = \"bisque2\",\n  \"d2007\" = colors[1], \"d2008\" = colors[2],\n  \"d2009\" = colors[3], \"d2010\" = colors[4],\n  \"d2011\" = colors[5], \"d2012\" = colors[6],\n  \"d2013\" = colors[7], \"d2014\" = colors[8],\n  \"d2015\" = colors[9], \"d2016\" = colors[10],\n  \"d2017\" = colors[11], \"d2018\" = colors[12],\n  \"d2019\" = colors[13], \"d2020\" = colors[14],\n  \"d2021\" = colors[15], \"r2010\" = \"azure2\",\n  \"r2011\" = \"azure2\", \"r2012\" = \"azure2\",\n  \"r2013\" = \"azure2\", \"r2014\" = \"azure2\",\n  \"r2015\" = \"azure2\", \"r2016\" = \"azure2\",\n  \"r2017\" = \"azure2\", \"r2018\" = \"azure2\",\n  \"r2019\" = \"azure2\", \"r2020\" = \"azure2\",\n  \"r2021\" = \"azure2\", \"NoClass\" = \"grey90\",\n  \"Clouds2021\" = \"grey90\"\n)\nplot(prodes2021, legend = def_legend)\n# Reclassify cube\nro_def_202021 <- sits_reclassify(\n  cube = ro_class,\n  mask = prodes2021,\n  rules = list(\n    \"Deforestation_Mask\" = mask %in% c(\n      \"d2007\", \"d2008\", \"d2009\",\n      \"d2010\", \"d2011\", \"d2012\",\n      \"d2013\", \"d2014\", \"d2015\",\n      \"d2016\", \"d2017\", \"d2018\",\n      \"d2019\", \"d2020\",\n      \"r2010\", \"r2011\", \"r2012\",\n      \"r2013\", \"r2014\", \"r2015\",\n      \"r2016\", \"r2017\", \"r2018\",\n      \"r2019\", \"r2020\", \"r2021\"\n    ),\n    \"Water\" = mask == \"Water\",\n    \"Non_Forest\" = mask %in% c(\"NonForest\", \"NonForest2\")\n  ),\n  memsize = 8,\n  multicores = 2,\n  output_dir = \"./tempdir/chp9\",\n  version = \"defor-reclass\"\n)\n# plot the reclassified map\nplot(ro_def_2021)#> Warning: palette colors names missing for 8, 9. Therefore, palette color names will be ignored"},{"path":"image-classification-in-data-cubes.html","id":"how-parallel-processing-works","chapter":"Image Classification in Data Cubes","heading":"How parallel processing works","text":"section provides overview functions sits_classify(), sits_smooth() sits_label_classification() process images parallel. achieve efficiency, sits implements fault tolerant multitasking procedure big EO data classification. Users burdened need learn multiprocessing. Thus, learning curve shortened. Image classification sits done cluster independent workers linked virtual machine. avoid communication overhead, large payloads read stored independently; direct interaction main process workers kept minimum.classification procedure benefits fact images available cloud collections stored COGs (cloud-optimized Geotiff). COGs regular GeoTIFF files organized regular square blocks improve visualization access large data sets. Thus, data requests can optimized access portions images. cloud services supported sits use COG files. classification algorithm sits uses COGs ensure optimal data access, reducing /O demand much possible.approach parallel processing sits, depicted figure , following steps:Based block size individual COG files, calculate size chunk loaded memory, considering number bands length timeline. Chunk access optimized efficient transfer data blocks.Divide total memory available chunk size find many processes can run parallel.core processes chunk produces subset result.Repeat process chunks cube processed.Check subimages produced correctly. problem one subimages, run failure recovery procedure ensure data processed.subimages generated, join obtain result.\nFigure 73: Parallel processing sits (source: Simoes et al.,2021).\napproach many advantages. works virtual machine supports R dependencies proprietary software. Processing done concurrent independent way, communication workers. Failure one worker cause failure big data processing. software prepared resume classification processing last processed chunk, preventing failures memory exhaustion, power supply interruption, network breakdown.reduce processing time, necessary adjust sits_classify(), sits_smooth(), sits_label_classification() according capabilities host environment. memsize parameter controls size main memory (GBytes) used classification. practical approach set memsize maximum memory available virtual machine classification chose multicores largest number cores available. Based memory available size blocks COG files, sits access images optimized way. way, sits tries ensure best possible use available resources.","code":""},{"path":"validation-and-accuracy-measurements.html","id":"validation-and-accuracy-measurements","chapter":"Validation and accuracy measurements","heading":"Validation and accuracy measurements","text":"","code":""},{"path":"validation-and-accuracy-measurements.html","id":"case-study","chapter":"Validation and accuracy measurements","heading":"Case study","text":"show validation accuracy assessment insits, show example land classification Cerrado biome, second largest biome Brazil 1.9 million km\\(^2\\). Brazilian Cerrado tropical savanna ecoregion rich ecosystem ranging grasslands woodlands. home 7000 species plants high levels endemism [79]. includes three major types natural vegetation: Open Cerrado, typically composed grasses small shrubs sporadic presence small tree vegetation; Cerrado, typical savanna formation, presence low, irregularly branched, thin-trunked trees; Cerradão, areas medium-sized trees (10–12 m)[80]. natural areas converted agriculture fast pace, one world’s fast moving agricultural frontiers [81]. main agricultural land uses include cattle ranching, crop farms, planted forests. classification follows work Simoes et al.[60].data composed 67 Landsat-8 tiles Brazil Data Cube, 23 time steps covering period 2017-08-29 2018-08-29. Since data avaliable Brazil Data Cube, users first obtain access BDC, obtaining access key. obtaining access key, include credentials using environment variables, shown . Obtaining BDC access key free. Users need register BDC site obtain key.obtaining BDC access key, now can create data cube Cerrado biome.\nFigure 74: Color composite image first date cube\nclassify Cerrado, use training data set produced Simoes et al.[60]. authors carried systematic sampling using grid 5 x 5 km throughout Cerrado biome, collecting 85,026 samples. training data labels extracted three sources: 2018 pastureland map Parente et al. [82], MapBiomas Collection 5 2018 [83], ~Brazil’s National Mapping Agency IBGE land maps 2016–2018. 85,026 samples, authors selected disagreement labels assigned three sources. final training set consists 48,850 points authors extracted time series using Landsat-8 data cube available BDC. classes training set : Annual Crop, Cerradao, Cerrado, Open Cerrado, Nat_NonVeg (Dunes), Pasture, Perennial_Crop, Silviculture (Planted Forests), Sugarcane, Water. data set available package sitsdata samples_cerrado_lc8.","code":"Sys.setenv(\n    \"BDC_ACCESS_KEY\" = <your_bdc_access_key>\n)\n# files are available in the Brazil Data Cube\n#\n# obtain the region of interest covering the Cerrado biome\nroi_cerrado_shp <- system.file(\n  \"extdata/shapefiles/cerrado_border/cerrado_border.shp\",\n  package = \"sitsdata\"\n)\n# read the shapefile as an object of the \"sf\" package\nroi_cerrado <- sf::st_read(roi_cerrado_shp, quiet = TRUE)\n\n# create a data cube for the entire cerrado biome\ncerrado_cube <- sits_cube(\n  source = \"BDC\",\n  collection = \"LC8_30_16D_STK-1\",\n  roi = roi_cerrado,\n  start_date = \"2017-08-29\",\n  end_date = \"2018-08-29\",\n  multicores = 3\n)\n# plot the first date with NDVI and EVI bands\nplot(cerrado_cube,\n  tile = \"044049\",\n  red = \"B7\",\n  green = \"B5\",\n  blue = \"B4\"\n)\nlibrary(sitsdata)\ndata(\"samples_cerrado_lc8\")\n# show the class distribution in the new training set\nsits_labels_summary(samples_cerrado_lc8)#> # A tibble: 10 × 3\n#>    label          count     prop\n#>    <chr>          <int>    <dbl>\n#>  1 Annual_Crop     6887 0.141   \n#>  2 Cerradao        4211 0.0862  \n#>  3 Cerrado        16251 0.333   \n#>  4 Nat_NonVeg        38 0.000778\n#>  5 Open_Cerrado    5658 0.116   \n#>  6 Pasture        12894 0.264   \n#>  7 Perennial_Crop    68 0.00139 \n#>  8 Silviculture     805 0.0165  \n#>  9 Sugarcane       1775 0.0363  \n#> 10 Water            263 0.00538"},{"path":"validation-and-accuracy-measurements.html","id":"cross-validation-of-training-set","chapter":"Validation and accuracy measurements","heading":"Cross validation of training set","text":"Cross-validation technique estimate inherent prediction error model [48]. Since cross-validation uses training samples, results accuracy measures, unless samples carefully collected represent diversity possible occurrences classes study area [84]. practice, working large areas, hard obtain random stratified samples cover different variations land cover associated ecosystems study area. Thus, cross-validation taken measure model performance training data estimate overall map accuracy.Cross-validation uses part available samples fit classification model, different part test . k-fold validation method splits data \\(k\\) partitions approximately size proceed fitting model testing \\(k\\) times. step, take one distinct partition test remaining \\({k-1}\\) training model, calculate prediction error classifying test partition. simple average gives us estimation expected prediction error. recommended choices \\(k\\) \\(5\\) \\(10\\) [48].sits_kfold_validate() supports k-fold validation sits. result confusion matrix accuracy statistics (overall class). examples , use multiprocessing speed results.Since data set big highly imbalanced, use function sits_reduce_imbalance() reduce size produce smaller balanced sample data set validation examples.following code five-fold validation using random forests.One useful function SITS capacity compare different validation methods store XLS file analysis. following example shows , using Cerrado data set. take models: random forests(sits_rfor()), extreme gradient boosting (sits_xgboost()), temporal CNN (sits_tempcnn()), lightweight temporal attention encoder (sits_lighttae()). computing confusion matrix statistics model, also store result list. calculation finished, function sits_to_xlsx() writes results Excel-compatible spreadsheet.resulting Excel file can opened R using spreadsheet programs. figure shows printout read Excel. shown , sheet corresponds output one model. simplicity, show result TempCNN, overall accuracy 90%.\nFigure 75: Result 5-fold cross validation Mato Grosso data using LightTAE\nscores overall accuracy similar models. However, significant differences models, shown comparing F1 scores, shown .table shows F1-scores classes model, produced k-fold validation. F1-scores obtained harmonic mean user’s accuracy precision accuracy class. results show although deep learning models TempCNN LightTAE similar overall accuracies Random Forests XGBoost, F1-scores per class cases better.cross validation results interpreted carefully. Cross validation measure well model fits training data. Using results measure classification accuracy valid training data good sample entire data set. practice, training data subject various sources bias. cases land classification, classes much frequent others training data set imbalanced. large areas, regional differences soil climate condition lead classes different spectral responses. collecting samples large areas, field analysts may restricted areas access (e.g, along roads). additional problem mixed pixels. Expert interpreters tend select samples standout field work reference images. Border pixels unlikely chosen part training data. reasons, cross validation results considered indicative accuracy measurement entire data set.","code":"\n# reduce imbalance in the data set\n# maximum number of samples per class will be 1000\n# minimum number of samples per class will be 500\nsamples_cerrado_bal <- sits_reduce_imbalance(\n  samples = samples_cerrado_lc8,\n  n_samples_over = 500,\n  n_samples_under = 1000,\n  multicores = 4\n)\n# show new sample distribution\nsits_labels_summary(samples_cerrado_bal)#> # A tibble: 10 × 3\n#>    label          count   prop\n#>    <chr>          <int>  <dbl>\n#>  1 Annual_Crop     1000 0.124 \n#>  2 Cerradao         900 0.111 \n#>  3 Cerrado          992 0.123 \n#>  4 Nat_NonVeg       500 0.0618\n#>  5 Open_Cerrado     984 0.122 \n#>  6 Pasture          956 0.118 \n#>  7 Perennial_Crop   500 0.0618\n#>  8 Silviculture     805 0.0994\n#>  9 Sugarcane        960 0.119 \n#> 10 Water            500 0.0618\n# perform a five fold validation for the cerrado data set\n# random forests machine learning method using default parameters\nval_rfor <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  folds = 5,\n  ml_method = sits_rfor(),\n  multicores = 5\n)\n# print the validation statistics\nsits_accuracy_summary(val_rfor)#> Overall Statistics                          \n#>  Accuracy : 0.877         \n#>    95% CI : (0.869, 0.884)\n#>     Kappa : 0.862\n# Compare different models for the Cerrado data set\n# create a list to store the results\nresults <- list()\n# Give a name to the results of the random forest model (see above)\nval_rfor$name <- \"rfor\"\n# store the rfor results in a list\nresults[[length(results) + 1]] <- val_rfor\n\n## Extreme Gradient Boosting\nval_xgb <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  ml_method = sits_xgboost(),\n  folds = 5,\n  multicores = 5\n)\n\n# Give a name to the SVM model\nval_xgb$name <- \"xgboost\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_xgb\n\n# Temporal CNN\nval_tcnn <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  ml_method = sits_tempcnn(\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(lr = 0.001)\n  ),\n  folds = 5,\n  multicores = 5\n)\n\n# Give a name to the result\nval_tcnn$name <- \"TempCNN\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_tcnn\n\n# Light TAE\nval_ltae <- sits_kfold_validate(\n  samples = samples_cerrado_bal,\n  ml_method = sits_lighttae(\n    optimizer = torchopt::optim_adamw,\n    opt_hparams = list(lr = 0.001)\n  ),\n  folds = 5,\n  multicores = 5\n)\n\n# Give a name to the result\nval_ltae$name <- \"LightTAE\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_ltae\n\n# Save to an XLS file\nxlsx_file <- \"./model_comparison.xlsx\"\n\nsits_to_xlsx(results, file = xlsx_file)\nmodel_acc <- tibble::tibble(\n  \"Random Forest\" = val_rfor$overall[[\"Accuracy\"]],\n  \"XGBoost\"       = val_xgb$overall[[\"Accuracy\"]],\n  \"TempCNN\"       = val_tcnn$overall[[\"Accuracy\"]],\n  \"LightTAE\"      = val_ltae$overall[[\"Accuracy\"]]\n)\noptions(digits = 3)\nmodel_acc#> # A tibble: 1 × 4\n#>   `Random Forest` XGBoost TempCNN LightTAE\n#>             <dbl>   <dbl>   <dbl>    <dbl>\n#> 1           0.879   0.889   0.897    0.894\nf1_score_rfor <- unname(val_rfor$byClass[, \"F1\"])\nf1_score_xgb <- unname(val_xgb$byClass[, \"F1\"])\nf1_score_tcnn <- unname(val_tcnn$byClass[, \"F1\"])\nf1_score_ltae <- unname(val_ltae$byClass[, \"F1\"])\n\nf1_scores <- tibble::tibble(\n  \"Classes\"  = sits_labels(samples_cerrado_bal),\n  \"RandFor\"  = f1_score_rfor,\n  \"XGBoost\"  = f1_score_xgb,\n  \"TempCNN\"  = f1_score_tcnn,\n  \"LightTAE\" = f1_score_ltae\n)\nf1_scores#> # A tibble: 10 × 5\n#>    Classes        RandFor XGBoost TempCNN LightTAE\n#>    <chr>            <dbl>   <dbl>   <dbl>    <dbl>\n#>  1 Annual_Crop      0.909   0.903   0.924    0.912\n#>  2 Cerradao         0.878   0.889   0.877    0.882\n#>  3 Cerrado          0.746   0.759   0.755    0.748\n#>  4 Nat_NonVeg       0.823   0.835   0.838    0.833\n#>  5 Open_Cerrado     0.824   0.847   0.854    0.859\n#>  6 Pasture          0.917   0.933   0.947    0.931\n#>  7 Perennial_Crop   0.999   0.999   0.998    1    \n#>  8 Silviculture     0.977   0.976   0.990    0.995\n#>  9 Sugarcane        0.998   0.998   1        0.998\n#> 10 Water            0.890   0.911   0.945    0.936"},{"path":"validation-and-accuracy-measurements.html","id":"accuracy-assessment-of-classified-images","chapter":"Validation and accuracy measurements","heading":"Accuracy assessment of classified images","text":"measure accuracy classified images, sits_accuracy() function uses area-weighted technique, following best practices proposed Olofsson et al. [85]. need area-weighted estimates arises fact land use land cover classes evenly distributed space. applications (e.g., deforestation) interest lies assessing much image changed, area mapped deforested likely small fraction total area. users disregard relative importance small areas change taking place, overall accuracy estimate inflated unrealistic. reason, Olofsson et al [85] argue “mapped areas adjusted eliminate bias attributable map classification error error-adjusted area estimates accompanied confidence intervals quantify sampling variability estimated area”.motivation, measuring accuracy classified images, function sits_accuracy() follows procedure set Olofsson et al. [85]. Given classified image validation file, first step calculate confusion matrix traditional way, .e., identifying commission omission errors. calculate unbiased estimator proportion area cell \\(,j\\) error matrix\\[\n\\hat{p_{,j}} = W_i\\frac{n_{,j}}{n_i}\n\\]\ntotal area map \\(A_{tot}\\), mapping area class \\(\\) \\(A_{m,}\\) proportion area mapped class \\(\\) \\(W_i = {A_{m,}}/{A_{tot}}\\). Adjusting area size allows producing unbiased estimation total area class \\(j\\), defined stratified estimator\n\\[\n\\hat{A_j} = A_{tot}\\sum_{=1}^KW_i\\frac{n_{,j}}{n_i}\n\\]\nunbiased area estimator includes effect false negatives (omission error) considering effect false positives (commission error). area estimates also allow producing unbiased estimate user’s producer’s accuracy class. Following [85], provide 95% confidence interval \\(\\hat{A_j}\\).use sits_accuracy() function produce adjusted area estimates, users provide classified image together csv file containing set well selected labeled points. csv file format one used obtain samples, discussed earlier. labelled points based random stratified sample. areas associated class contribute test data used accuracy assessment.biases inherent cross validation training data, users provide independent validation data set measure classification accuracy. case study, Simoes et al.[60] systematic sampling Cerrado biome using 20 x 20 km grid total 5402 points. samples independent training set used classification. interpreted five specialists using high resolution images period classification. resulted 5286 evaluation samples thus distributed: “Annual Crop” (553), “Cerrado” (3155), “Natural Non Vegetated” (44), “Pasture” (1246), “Perennial Crop” (38), “Silviculture” (94), “Sugarcane” (77), “Water” (79). data set available package sitsdata, described . validation file, samples belonging classes “Cerrado”, “Open Cerrado” “Cerradao” (Woody Savanna) grouped together single class.first step obtain classification map. code full classification Cerrado biome, using TempCNN algorithm, shown . large data size, code executed. accuracy assessment, use labelled classification map available Dropbox folder.Since code included information , use labelled cube stored Dropbox folder perform accuracy assessment. First, retrieve metadata cube.\nFigure 76: Classification tile 044048 Landsat data cube Brazilian Cerrado 2017/2018.\nnext step provide CSV file validation points, described .example shows important correct area estimates land classification, reduce bias effect misclassification take account different producer’s accuracies associated class. also shows actual overall accuracy general lower result cross-validation.","code":"\n# This code shows the classification of the Cerrado biome\n# It is include for information purposes\n# It takes a long time to run\ntcnn_model <- sits_train(\n  samples = samples_cerrado_lc8,\n  ml_method = sits_tempcnn()\n)\n# using the tempCNN model to classify the Cerrado\n# this example should be run on a large virtual machine\ncerrado_probs_cube <- sits_classify(\n  cube = cerrado_cube,\n  ml_model = tcnn_model,\n  memsize = 128,\n  multicores = 64,\n  output_dir = \"./cerrado_probs\"\n)\ncerrado_bayes_cube <- sits_smooth(\n  cube = cerrado_probs_cube,\n  type = \"bayes\",\n  memsize = 128,\n  multicores = 64,\n  output_dir = \"./cerrado_bayes\"\n)\ncerrado_classif <- sits_label_classification(\n  cube = cerrado_bayes_cube,\n  memsize = 128,\n  multicores = 64,\n  output_dir = \"./cerrado_label\"\n)\n# retrieve the metadata for the classified cube\n# the files are stored as Dropbox links\ncerrado_classif_rds <- system.file(\"extdata/Cerrado/cerrado_classif_dropbox.rds\",\n  package = \"sitsdata\"\n)\n# read the cube metadata\ncerrado_classif <- readRDS(cerrado_classif_rds)\n# plot one tile of the classification\nplot(cerrado_classif, tiles = \"044048\")\n# get ground truth points\nvalid_csv <- system.file(\"extdata/csv/cerrado_lc8_validation.csv\",\n  package = \"sitsdata\"\n)\n# calculate accuracy according to Olofsson's method\narea_acc <- sits_accuracy(cerrado_classif,\n  validation_csv = valid_csv\n)\n# print the area estimated accuracy\narea_acc#> $error_matrix\n#>                 \n#>                  Annual_Crop Cerrado Nat_NonVeg Pasture Perennial_Crop Silviculture Sugarcane Water\n#>   Annual_Crop            469      13          0      47              0            0         2     0\n#>   Cerrado                  4    2813          0     191              3           12         2     4\n#>   Nat_NonVeg               0       2         43       0              0            0         0     2\n#>   Pasture                 67     287          0     999              5            3         2     4\n#>   Perennial_Crop           0      23          0       2             26            2         0     0\n#>   Silviculture             0      16          0       2              4           77         0     0\n#>   Sugarcane               13       0          0       5              0            0        71     0\n#>   Water                    0       1          1       0              0            0         0    69\n#> \n#> $area_pixels\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>       3.12e+07       2.02e+08       9.97e+05       1.09e+08       1.62e+06       6.96e+06       1.06e+07 \n#>          Water \n#>       1.42e+07 \n#> \n#> $error_ajusted_area\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>       3.47e+07       2.14e+08       1.11e+06       9.58e+07       1.67e+06       6.51e+06       8.84e+06 \n#>          Water \n#>       1.44e+07 \n#> \n#> $stderr_prop\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>       0.002328       0.004194       0.000542       0.004386       0.000735       0.001060       0.001282 \n#>          Water \n#>       0.000931 \n#> \n#> $stderr_area\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>         876650        1579665         204161        1651840         276851         399372         483007 \n#>          Water \n#>         350471 \n#> \n#> $conf_interval\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>        1718233        3096142         400156        3237606         542628         782769         946693 \n#>          Water \n#>         686924 \n#> \n#> $accuracy\n#> $accuracy$user\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>          0.883          0.929          0.915          0.731          0.491          0.778          0.798 \n#>          Water \n#>          0.972 \n#> \n#> $accuracy$producer\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture      Sugarcane \n#>          0.794          0.880          0.820          0.830          0.474          0.831          0.954 \n#>          Water \n#>          0.956 \n#> \n#> $accuracy$overall\n#> [1] 0.861\n#> \n#> \n#> attr(,\"class\")\n#> [1] \"sits_area_assessment\" \"list\""},{"path":"uncertainty-and-active-learning.html","id":"uncertainty-and-active-learning","chapter":"Uncertainty and active learning","heading":"Uncertainty and active learning","text":"Land use land cover classification tasks unique characteristics differ machine learning domains image recognition natural language processing. main challenge land classification able describe diversity planet’s landscapes handful labels. However, diversity world’s ecosystem makes classification systems biased approximations reality. stated Murphy : “gradation properties world means smallish number categories never map perfectly onto objects” [86]. reason, sits provides tools users improve classifications iterative means, using process called “active learning”.Active learning remote sensing data classification iterative process sample selection, labeling, model retraining. following steps provide general overview use active learning remote sensing data classification:Collect initial training samples: Start collecting small set representative training samples cover range land cover classes interest.Train machine learning model: Use initial training samples train machine learning model classify remote sensing data.Classify data cube using model.Identify areas uncertainty.Select samples re-labeling: select set unlabeled samples model uncertain , .e., model least confident classifying.Label selected samples: user labels selected samples, adding training set.Retrain model: model retrained using newly labeled samples, process repeats , starting step 2.Stop classification accuracy satisfactory: iterative process continues classification accuracy reaches satisfactory level.traditional classification methods, experts provide set training samples use machine learning algorithm produce map. contrast, active learning approach puts human loop[87]. iteration, unlabeled set samples presented user, assigns classes includes training set [88]. process repeated expert satisfied result, shown Figure .\nFigure 77: Active learning approach (source: Crawford et al., 2013)\nActive learning aims reduce bias errors sample selection improve accuracy result. interaction, experts asked review pixels ML classifier indicates high value uncertainty. Source classification uncertainty include missing classes mislabeled samples. sits, active learning supported combination three functions: sits_uncertainty(), sits_uncertainty_sampling() sits_confidence_sampling().","code":""},{"path":"uncertainty-and-active-learning.html","id":"measuring-uncertainty","chapter":"Uncertainty and active learning","heading":"Measuring uncertainty","text":"Uncertainty land use land cover classification refers degree doubt ambiguity accuracy classification results. process classifying land use land cover involves interpreting remotely sensed images geospatial data assign specific land use land cover categories various regions ground. Several sources uncertainty can arise process, including:Classification errors: can occur classification algorithm misinterprets spectral spatial characteristics input data, leading misclassification land use land cover categories.Ambiguity definition land use/land cover categories: definition land use land cover categories can ambiguous subjective, leading inconsistencies classification results.Variability landscape: Natural human-induced variations landscape can make difficult accurately classify land use land cover regions.Limitations data: quality quantity input data can influence accuracy classification results.Quantifying uncertainty land use land cover classification important ensuring classification results reliable useful decision-making. Various methods, confusion matrices error matrices, can used estimate visualize level uncertainty classification results. Additionally, incorporating uncertainty estimates decision-making processes can help identify regions investigation data collection needed.function sits_uncertainty() calculates uncertainty cube based probabilities produced classifier. takes probability cube input. uncertainty measure relevant context active leaning, helps increase quantity quality training samples providing information confidence model. supported types uncertainty ‘entropy’, ‘least’, ‘margin’ ‘ratio’.Least confidence sampling computed difference uncertainty (100% confidence) probability likely class, normalized number classes. Let \\(P_1()\\) higher class probability pixel \\(\\). least confidence sampling expressed \\[\n\\theta_{LC} = (1 - P_1()) * \\frac{n}{n-1}\n\\]Margin confidence sampling difference two confident predictions, expressed range 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_1()\\) two higher class probability pixel \\(\\). , margin confidence expressed \\[\n\\theta_{MC} = (1 - P_1() - P_2())\n\\]\nRatio confidence measure ratio two confident predictions, expressed range 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_1()\\) two higher class probability pixel \\(\\). , ratio confidence expressed \n\\[\n\\theta_{RC} = \\frac{P_2()}{P_1()}\n\\]Entropy measure uncertainty used Claude Shannon classic work “Mathematical Theory Communication”. related amount variability probabilities associated pixel. lower variability, lower entropy. Let \\(P_k()\\) probability associated class \\(k\\) pixel \\(\\). entropy calculated \n\\[\n\\theta_{E} = \\frac{-\\sum_{k=1}^K P_k() * log_2(P_k())}{log_2{n}}\n\\]parameters sits_uncertainty() : cube, probability data cube; type, uncertainty measure (default least). case entropy, also requires parameters window_size, size neighborhood calculate entropy (default 5) window_fn, function applied entropy calculation (default median). processing functions, users can specify multicores number cores run function memsize, maximum overall memory (GB) run function. Optional parameters include output_dir (output directory image files) version (version result).","code":""},{"path":"uncertainty-and-active-learning.html","id":"using-uncertainty-measures-for-active-learning","chapter":"Uncertainty and active learning","heading":"Using uncertainty measures for active learning","text":"following case study shows uncertainty measures can used context active learning. study area subset one Sentinel-2 tile state Rondonia, Brazil. aim work detect deforestation Brazilian Amazonia.study area located close Samuel Hydroelectric Dam, located Madeira River Brazilian state Rondônia. Building dam led loss 56,000 hectares native forest. construction dam caused displacement several indigenous communities traditional populations, leading social cultural disruption. Additionally, flooding large areas forest resulted loss habitats biodiversity, including several endangered species. dam altered natural flow Madeira River, leading changes water quality temperature, affecting aquatic life depends river. changes river flow also impacted navigation transportation activities local communities.first step produce regular data cube chosen area rom period 2020-06-01 2021-09-01. reduce processing time storage, use three bands (“B02”, “B8A”, “B11”) plus cloud band, take small area inside tile. obtaining regular cube, plot study area dates temporal interval data cube. first image taken beginning dry season “2020-07-04”, inundation area dam covered shallow water.\nFigure 78: Area Rondonia near Samuel dam (source: authors)\nsecond image “2020-11-09” shows inundation area dries dry season. early November 2020, end dry season, inundation area dry response similar bare soil burned areas. Madeira river can seen running dried inundation area.\nFigure 79: Area Rondonia near Samuel dam November 2021 (source: authors)\nthird image “2021-08-08”. early August 2021, wet season, inundation area covered shallow water layer. number burned clear cut areas can also seen August 2021 image compared July 2020 one. Given contrast wet dry seasons, correct land cover classification area hard.\nFigure 80: Area Rondonia near Samuel dam August 2021 (source: authors)\nnext step classify study area using training set 480 times series collected state Rondonia (Brasil) detecting deforestation. training set uses 4 classes (“Burned_Area”, “Forest”, “Highly_Degraded” “Cleared_Area”). cube classified using LightTAE model, post-processed Bayesian smoothing, labelled.\nFigure 81: Classified map area Rondonia near Samuel dam (source: authors)\nresulting map correctly identifies forest area deforestation. However, wrongly classifies area covered Samuel hydroelectric dam. reason lack samples classes related surface water wetlands. improve classification, need improve samples. , first step calculate uncertainty classification.\nFigure 82: Uncertainty map classification Rondonia near Samuel dam (source: authors)\nexpected, places highest uncertainty covered surface water associated wetlands. places likely misclassified. reason, sits provides function sits_uncertainty_sampling() takes uncertainty cube input produces tibble locations WGS84 high uncertainty. function three parameters: n, number uncertain points included; min_uncert, minimum value uncertainty pixels included list; sampling_window, improve spatial distribution new samples avoiding points neighborhood included. running function, can use sits_view() visualize location samples.\nFigure 83: Location uncertain pixel classification Rondonia near Samuel dam (source: authors)\nvisualization shows samples located areas covered Samuel data. first approximation, one can use label “Wetlands” designate samples. detailed evaluation, recommended practices, requires analysing samples exploration software QGIS individually labelling sample. case, take direct approach illustration purposes.\nFigure 84: New land classification Rondonia near Samuel dam (source: authors)\nresults shows significant quality gain earlier classification. still confusion areas exposed soils inside inundation area, classified burned areas. useful also show uncertainty map associated second model.\nFigure 85: Uncertainty map classification Rondonia near Samuel dam - improved model (source: authors)\nnew uncertainty map shows, significant improvement quality classification. remaining areas high uncertainty places affected contrast wet dry season close inundation area. areas low-laying places sometimes covered water sometimes bare soil areas throughout year, depending intensity rainy season. improve quality classification, obtain new samples uncertain areas, label add samples. general, section shows, combining uncertainty measurements active learning recommended practice improving classification results.","code":"\n# create a directory to store files\nif (!file.exists(\"./tempdir/chp11\")) {\n  dir.create(\"./tempdir/chp11\")\n}\n# select a S2 tile\ns2_cube_ro <- sits_cube(\n  source = \"MPC\",\n  collection = \"sentinel-2-l2a\",\n  tiles = \"20LMR\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"SCL\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2021-09-01\")\n)\n# select a small area inside the tile\n\nroi <- c(\n  lon_max = -63.25790, lon_min = -63.6078,\n  lat_max = -8.72290, lat_min = -8.95630\n)\n\n# regularize the small area cube\n\ns2_reg_cube_ro <- sits_regularize(\n  cube = s2_cube_ro,\n  output_dir = \"./tempdir/chp11/\",\n  res = 20,\n  roi = roi,\n  period = \"P16D\",\n  multicores = 4\n)\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-07-04\"\n)\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-11-09\"\n)\nplot(s2_reg_cube_ro, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2021-08-08\")\nlibrary(sitsdata)\n# load the training set\ndata(\"samples_prodes_4classes\")\n# select the same three bands used in the data cube\nsamples_4classes_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n)\n# Train a lightTAE model\nltae_model <- sits_train(\n  samples = samples_4classes_3bands,\n  ml_method = sits_lighttae()\n)\n# classify the small area cube\ns2_cube_probs <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = ltae_model,\n  output_dir = \"./tempdir/chp11/\",\n  memsize = 15,\n  multicores = 5\n)\n# post-process the probability cube\ns2_cube_bayes <- sits_smooth(\n  cube = s2_cube_probs,\n  output_dir = \"./tempdir/chp11/\",\n  memsize = 16,\n  multicores = 4\n)\n# label the post-processed  probability cube\ns2_cube_label <- sits_label_classification(\n  cube = s2_cube_bayes,\n  output_dir = \"./tempdir/chp11/\",\n  memsize = 16,\n  multicores = 4\n)\nplot(s2_cube_label)\n# calculate the uncertainty cube\ns2_cube_uncert <- sits_uncertainty(\n  cube = s2_cube_bayes,\n  type = \"entropy\",\n  output_dir = \"./tempdir/chp11/\",\n  memsize = 16,\n  multicores = 4\n)\nplot(s2_cube_uncert)\n# calculate the uncertainty cube\nnew_samples <- sits_uncertainty_sampling(\n  uncert_cube = s2_cube_uncert,\n  n = 20,\n  min_uncert = 0.5,\n  sampling_window = 10\n)\n# view the location of the samples\nsits_view(new_samples)\n# label the new samples\nnew_samples$label <- \"Wetland\"\n# obtain the time series from the regularized cube\nnew_samples_ts <- sits_get_data(\n  cube = s2_reg_cube_ro,\n  samples = new_samples\n)\n# join the new samples with the original ones with 4 classes\nsamples_4classes_3bands_round_2 <- dplyr::bind_rows(\n  samples_4classes_3bands,\n  new_samples_ts\n)\n# train a lightTAE model with the new sample set\nltae_model_v2 <- sits_train(\n  samples = samples_4classes_3bands_round_2,\n  ml_method = sits_lighttae()\n)\n# classify the small area cube\ns2_cube_probs_v2 <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = ltae_model_v2,\n  output_dir = \"./tempdir/chp11/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n# post-process the probability cube\ns2_cube_bayes_v2 <- sits_smooth(\n  cube = s2_cube_probs_v2,\n  output_dir = \"./tempdir/chp11/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n# label the post-processed  probability cube\ns2_cube_label_v2 <- sits_label_classification(\n  cube = s2_cube_bayes_v2,\n  output_dir = \"./tempdir/chp11/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n# plot the second version of the classified cube\nplot(s2_cube_label_v2)\n# calculate the uncertainty cube\ns2_cube_uncert_v2 <- sits_uncertainty(\n  cube = s2_cube_bayes_v2,\n  type = \"entropy\",\n  output_dir = \"./tempdir/chp11/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\nplot(s2_cube_uncert_v2)"},{"path":"ensemble-prediction-from-multiple-models.html","id":"ensemble-prediction-from-multiple-models","chapter":"Ensemble Prediction from Multiple Models","heading":"Ensemble Prediction from Multiple Models","text":"Ensemble prediction powerful technique combining predictions multiple models produce accurate robust predictions. general, ensemble predictions produce better predictions using single model. errors individual models can cancel reduced combined predictions models. result, ensemble predictions can lead better overall accuracy reduce risk overfitting.Ensemble predictions robust changes data model. single model sensitive certain types data errors, ensemble predictions can help reduce impact issues combining predictions multiple models. Ensemble predictions can help choose best model models given task. comparing predictions different models, can identify models perform best different types data tasks. can especially useful working complex uncertain data. combining predictions multiple models, users can identify features factors important making accurate predictions. using ensemble methods, ’s important choose models diverse different sources error. can help ensure ensemble predictions accurate robust.Overall, ensemble predictions powerful tool improving accuracy robustness machine learning models. combining predictions multiple models, users can reduce errors uncertainty, gain new insights underlying patterns data.sits package provides function sits_combine_predictions() estimate ensemble predictions using probability cubes produced sits_classify() optionally post-processed sits_smooth(). two ways ensemble predictions multiple models sits:Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely ones valid.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely ones valid.follows, use data used “Image Classification Data Cubes” chapter section illustrate produce ensemble prediction. simplicity, repeat steps taken classify image chapter: create data cube, train model using lightweight temporal attention encoder algorithm (sits_lighttae()), classify, post-process label data cube. starting point, plot two instances data cube, start end time series.\nFigure 86: Color composite image date 2020-07-06.\nimage 2020-07-06 shows many areas deforestation, especially large one located top center image. useful compare image one year later, shows number burned areas resulting forest removal followed fire.\nFigure 87: Color composite image date 2021-08-10.\nsamples used classification used “Image Classification Data Cubes” chapter. Please refer chapter detailed description temporal response samples. first reproduce result obtained chapter using sits_lighttae() algorithm.\nFigure 88: Image Classification using LightTAE model.\ndeforestation map produced sits_lighttae() algorithm spatial consistency; arguably, underestimates burned areas right-hand corner image. method tries modelling temporal behavior reflectances. reason, sometimes fails detect changes occur last dates time series, occurs areas burned August.build two-member ensemble, now classify image using random forests algorithm.\nFigure 89: Land classification Rondonia using random forests algorithm.\nComparing two results, land areas classified equally, places disagreement concerning places classified “Burned_Area” “Highly Degraded”. Since random forests model sensitive response images end period, tends better distinguish burned areas. However, tends reduce forest areas, classifying highly degraded. misclassification happens random forests algorithm disregards temporal correlation input data. Values single date used distinguish natural degraded forest areas.Given differences complementarities two predicted outcomes, useful combine using sits_combine_predictions(). first option ensemble prediction take average probability maps reduce noise.\nFigure 90: Land classification Rondonia near Samuel dam using average probabilities produced lightTAE tempCNN algorithms.\nCompared initial map, result increased number pixels classified burned areas highly degraded. areas classified degraded forest random forests method included final map. places random forests algorithm high confidence included. general, average map results better classification individual results.","code":"\n# files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LKP/\", package = \"sitsdata\")\n# read data cube\nro_cube_20LKP <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\"X1\", \"tile\", \"band\", \"date\")\n)\nplot(ro_cube_20LKP,\n  date = \"2020-07-06\",\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\"\n)\nplot(ro_cube_20LKP,\n  date = \"2021-08-10\",\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\"\n)\n# get the samples from library \"sitsdata\"\nlibrary(sitsdata)\ndata(samples_prodes_4classes)\n# use only the bands available in the cube\nsamples_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = sits_bands(ro_cube_20LKP)\n)\n# train model using LightTAE algorithm\nltae_model <- sits_train(\n  samples = samples_3bands,\n  ml_method = sits_lighttae(\n    opt_hparams = list(lr = 0.001)\n  )\n)\n# classify data cube\nro_cube_probs_ltae <- sits_classify(\n  data = ro_cube_20LKP,\n  ml_model = ltae_model,\n  output_dir = \"./tempdir/chp12\",\n  version = \"ltae\",\n  multicores = 4,\n  memsize = 12\n)\n# smooth data cube\nro_cube_bayes_ltae <- sits_smooth(\n  cube = ro_cube_probs_ltae,\n  output_dir = \"./tempdir/chp12\",\n  version = \"ltae\",\n  multicores = 4,\n  memsize = 12\n)\n# generate thematic map\ndefor_map <- sits_label_classification(\n  cube = ro_cube_bayes_ltae,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp12\",\n  version = \"ltae\"\n)\nplot(defor_map)\n# train model using random forests algorithm\nrfor_model <- sits_train(\n  samples = samples_3bands,\n  ml_method = sits_rfor()\n)\n\n# classify the data cube using the tempCNN model\nro_cube_probs_rfor <- sits_classify(\n  data = ro_cube_20LKP,\n  ml_model = rfor_model,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n# post-process the probability cube\nro_cube_bayes_rfor <- sits_smooth(\n  cube = ro_cube_probs_rfor,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n# label the post-processed  probability cube\nro_cube_label_rfor <- sits_label_classification(\n  cube = ro_cube_bayes_rfor,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n# plot the random forests version of the classified cube\nplot(ro_cube_label_rfor)\n# combine the two predictions by taking the average of the probabilities for each class\ns2_cube_average_probs <- sits_combine_predictions(\n  cubes = list(ro_cube_bayes_ltae, ro_cube_bayes_rfor),\n  type = \"average\",\n  output_dir = \"./tempdir/chp11/\",\n  version = \"average\",\n  memsize = 16,\n  multicores = 1\n)\n# label the average probability cube\ns2_cube_average_class <- sits_label_classification(\n  cube = s2_cube_average_probs,\n  output_dir = \"./tempdir/chp11/\",\n  version = \"average\",\n  memsize = 16,\n  multicores = 4\n)\n# plot the second version of the classified cube\nplot(s2_cube_average_class)"},{"path":"visualising-and-exporting-data.html","id":"visualising-and-exporting-data","chapter":"Visualising and Exporting data","heading":"Visualising and Exporting data","text":"section intended programmers experts like extend capabilities sits, either including new data sources, ML algorithms, exporting data used Python QGIS, including new display colors.","code":""},{"path":"visualising-and-exporting-data.html","id":"how-colors-work-in-sits","chapter":"Visualising and Exporting data","heading":"How colors work in sits","text":"examples provided book, color legend taken predefined color table provided sits. default color table displayed using command sits_colors_show. color definition file assigns colors 99 class names, including IPCC IGBP land use classes.\nFigure 91: Default colors used sits package\ncolor table can extended adjusted accessing modifying default color table, using commands sits_colors() retrieve table sits_colors_set() update table according user choices, shown example .example user-defined color table, consider definition covers level 1 Anderson Classification System used US National Land Cover Data, obtained defining new color table, shown . colors can defined HEX values names accepted R color codes.\nFigure 92: Example Anderson Land Classification Scheme use sits\nalternative, users may define legends pass parameters plot function. Please see example provided Section “Map Reclassification” Chapter “Image Classification Data Cubes”.","code":"\n# retrieve the color table\ncolor_tb <- sits_colors()\n# show the color table\ncolor_tb#> # A tibble: 99 × 3\n#>    name                       color   group          \n#>    <chr>                      <chr>   <chr>          \n#>  1 Evergreen_Broadleaf_Forest #1E8449 Tropical_Forest\n#>  2 Forest                     #1E8449 Tropical_Forest\n#>  3 Closed_Forest              #1E8449 Tropical_Forest\n#>  4 Woodland                   #27AE60 Tropical_Forest\n#>  5 Dense_Woodland             #27AE60 Tropical_Forest\n#>  6 Woody_Savanna              #27AE60 Tropical_Forest\n#>  7 Open_Forest                #27AE60 Tropical_Forest\n#>  8 Cerradao                   #27AE60 Tropical_Forest\n#>  9 Mixed_Forest               #27AE60 Tropical_Forest\n#> 10 Sparse_Forest              #27AE60 Tropical_Forest\n#> # … with 89 more rows\n# define a color table based on the Anderson Land Classification System\nus_nlcd <- tibble::tibble(name = character(), color = character())\nus_nlcd <- us_nlcd %>%\n  tibble::add_row(name = \"Urban Built Up\", color = \"#85929E\") %>%\n  tibble::add_row(name = \"Agricultural Land\", color = \"#F0B27A\") %>%\n  tibble::add_row(name = \"Rangeland\", color = \"#F1C40F\") %>%\n  tibble::add_row(name = \"Forest Land\", color = \"#27AE60\") %>%\n  tibble::add_row(name = \"Water\", color = \"#2980B9\") %>%\n  tibble::add_row(name = \"Wetland\", color = \"#D4E6F1\") %>%\n  tibble::add_row(name = \"Barren Land\", color = \"#FDEBD0\") %>%\n  tibble::add_row(name = \"Tundra\", color = \"#EBDEF0\") %>%\n  tibble::add_row(name = \"Snow and Ice\", color = \"#F7F9F9\")\n# load the color table into `sits`\nsits_colors_set(us_nlcd)\n# show the new color table used by sits\nsits_colors_show()"},{"path":"visualising-and-exporting-data.html","id":"exporting-data-to-json","chapter":"Visualising and Exporting data","heading":"Exporting data to JSON","text":"data cube time series tibble can exported exchange formats JSON.","code":"\nlibrary(jsonlite)\n# export the data cube to JSON\njsonlite::write_json(\n  x = s2_20LKP_cube_MPC,\n  path = \"./data_cube.json\",\n  pretty = TRUE\n)\n# export the time series to JSON\njsonlite::write_json(\n  x = samples_prodes_4classes,\n  path = \"./time_series.json\",\n  pretty = TRUE\n)"},{"path":"technical-annex.html","id":"technical-annex","chapter":"Technical Annex","heading":"Technical Annex","text":"chapter contains technical details algorithms available sits. intended support want understand package works also want contribute development.","code":""},{"path":"technical-annex.html","id":"bayesian-smoothing-1","chapter":"Technical Annex","heading":"Bayesian smoothing","text":"post-processing using Bayesian smoothing SITS straightforward. result sits_classify function applied data cube set probability images, one per class. next step apply sits_smooth function. default, function selects likely class pixel considering probabilities class pixel. continuous probability distributions, Bayesian inference expressed rule:\\[\n\\pi(\\theta|x) \\propto \\pi(x|\\theta)\\pi(\\theta)\n\\]Bayesian inference involves estimation unknown parameter \\(\\theta\\), random variable describe trying measure. case smoothing image classification, \\(\\theta\\) class probability given pixel, conditioned probability values pixel. model initial belief value probability distribution, \\(\\pi(\\theta)\\), called distribution. represents know \\(\\theta\\) observing data. distribution \\(\\pi(x|\\theta)\\), called , estimated based observed data. represents added information provided observations. distribution \\(\\pi(\\theta|x)\\) improved belief \\(\\theta\\) seeing data. Bayes’s rule states probability proportional product probability.","code":""},{"path":"technical-annex.html","id":"derivation-of-bayesian-parameters-for-spatiotemporal-smoothing","chapter":"Technical Annex","heading":"Derivation of bayesian parameters for spatiotemporal smoothing","text":"post-classification smoothing model, consider output machine learning algorithm provides probabilities pixel image belong target classes. formally, consider set \\(K\\) classes candidates labelling pixel. Let \\(p_{,t,k}\\) probability pixel \\(\\) belonging class \\(k\\), \\(k = 1, \\dots, K\\). \n\\[\n\\sum_{k=1}^K p_{,k} = 1, p_{,k} > 0\n\\]\nlabel pixel \\(p_i\\) class \\(k\\) \n\\[\n    p_{, k} > p_{,m}, \\forall m = 1, \\dots, K, m \\neq k\n\\]pixel \\(\\), take odds classification class \\(k\\), expressed \n\\[\n    O_{,k} = p_{,k} / (1-p_{,k})\n\\]\n\\(p_{, k}\\) probability class \\(k\\). confidence pixels higher odds since class assignment stronger. situations, border pixels mixed ones, odds different classes similar magnitude. take cases low confidence classification result. assess correct cases, Bayesian smoothing methods borrow strength neighbors reduces variance estimated class pixel.make transformation\n\\[\n    x_{,k} = \\log [O_{,k}]\n\\]\nmeasures logit (log odds) associated classifying pixel \\(\\) class \\(k\\). support \\(x_{, k}\\) \\(\\mathbb{R}\\). can express pixel data \\(K\\)-dimensional multivariate logit vector\\[\n\\mathbf{x}_{}=(x_{,k_{0}},x_{,k_{1}},\\dots{},x_{,k_{K}})\n\\]pixel, random variable describes class probability \\(k\\) denoted \\(\\theta_{,k}\\). formulation allows uses use class covariance matrix formulations. can express Bayes’ rule combinations pixel classes time interval \\[\n\\pi(\\boldsymbol\\theta_{}|\\mathbf{x}_{}) \\propto \\pi(\\mathbf{x}_{}|\\boldsymbol\\theta_{})\\pi(\\boldsymbol\\theta_{}).  \n\\]assume conditional distribution \\(\\mathbf{x}_{}|\\boldsymbol\\theta_{}\\) follows multivariate normal distribution\\[\n    [\\mathbf{x}_{}|\\boldsymbol\\theta_{}]\\sim\\mathcal{N}_{K}(\\boldsymbol\\theta_{},\\boldsymbol\\Sigma_{}),\n\\]\\(\\boldsymbol\\theta_{}\\) mean parameter vector pixel \\(\\), \\(\\boldsymbol\\Sigma_{}\\) known \\(k\\times{}k\\) covariance matrix use parameter control level smoothness effect. discuss later estimate \\(\\boldsymbol\\Sigma_{}\\). model uncertainty parameter \\(\\boldsymbol\\theta_{}\\), assume also follows multivariate normal distribution hyper-parameters \\(\\mathbf{m}_{}\\) mean vector, \\(\\mathbf{S}_{}\\) covariance matrix.\\[\n    [\\boldsymbol\\theta_{}]\\sim\\mathcal{N}_{K}(\\mathbf{m}_{}, \\mathbf{S}_{}).\n\\]equation defines prior distribution. hyper-parameters \\(\\mathbf{m}_{}\\) \\(\\mathbf{S}_{}\\) obtained using neighboring pixels pixel \\(\\). neighborhood can defined graph scheme (e.g. given Chebyshev distance time-space lattice) can include referencing pixel \\(\\) neighbor. formally, let\\[\n    \\mathbf{V}_{}=\\{\\mathbf{x}_{i_{j}}\\}_{j=1}^{N},\n\\]\ndenote \\(N\\) logit vectors spatiotemporal neighborhood \\(N\\) pixel \\(\\). prior mean calculated \\[\n    \\mathbf{m}_{}=\\operatorname{E}[\\mathbf{V}_{}],\n\\]prior covariance matrix \\[\n    \\mathbf{S}_{}=\\operatorname{E}\\left[\n      \\left(\\mathbf{V}_{}-\\mathbf{m}_{}\\right)\n      \\left(\\mathbf{V}_{}-\\mathbf{m}_{}\\right)^\\intercal\n    \\right].\n\\]\n\\(\\boldsymbol\\theta_{}\\) parameter model initial belief pixel vector using neighborhood information prior distribution. represents know probable value \\(\\mathbf{x}_{}\\) (hence, class probabilities logit function monotonically increasing function) observing . function \\(P[\\mathbf{x}_{,t}|\\boldsymbol\\theta_{,t}]\\) represents added information provided observation \\(\\mathbf{x}_{,t}\\). probability density function \\(P[\\boldsymbol\\theta_{,t}|\\mathbf{x}_{,t}]\\) improved belief pixel vector seeing \\(\\mathbf{x}_{,t}\\).Since likelihood prior multivariate normal distributions, posterior also multivariate normal distribution, whose updated parameters can derived applying density functions associated equations. posterior distribution given \\[\n    [\\boldsymbol\\theta_{}|\\mathbf{x}_{}]\\sim\\mathcal{N}_{K}\\left(\n    (\\mathbf{S}_{}^{-1} + \\boldsymbol\\Sigma^{-1})^{-1}( \\mathbf{S}_{}^{-1}\\mathbf{m}_{} + \\boldsymbol\\Sigma^{-1} \\mathbf{x}_{}),\n    (\\mathbf{S}_{}^{-1} + \\boldsymbol\\Sigma^{-1})^{-1}\n    \\right).\n\\]\npoint, able infer estimator \\(\\hat{\\boldsymbol\\theta}_{}\\) \\(\\boldsymbol\\theta_{}|\\mathbf{x}_{}\\) parameter. multivariate normal distribution, posterior mean minimizes quadratic loss absolute zero-one loss functions. can taken updated mean parameter posterior distribution , algebra, can expressed \\[\n    \\hat{\\boldsymbol{\\theta}}_{}=\\operatorname{E}[\\boldsymbol\\theta_{}|\\mathbf{x}_{}]=\\boldsymbol\\Sigma_{}\\left(\\boldsymbol\\Sigma_{}+\\mathbf{S}_{}\\right)^{-1}\\mathbf{m}_{} +\n    \\mathbf{S}_{}\\left(\\boldsymbol\\Sigma_{}+\\mathbf{S}_{}\\right)^{-1}\\mathbf{x}_{}.\n\\]estimator value logit vector \\(\\hat{\\boldsymbol\\theta}_{}\\) weighted average original logit vector \\(\\mathbf{x}_{}\\) neighborhood mean vector \\(\\mathbf{m}_{}\\). weights given covariance matrix \\(\\mathbf{S}_{}\\) prior distribution covariance matrix conditional distribution. matrix \\(\\mathbf{S}_{}\\) calculated considering neighbors matrix \\(\\boldsymbol\\Sigma_{}\\) smoothing factor provided prior belief user.values local class covariance \\(\\mathbf{S}_{}\\) higher conditional covariance \\(\\boldsymbol\\Sigma_{}\\), confidence influence neighbors low, smoothing algorithm gives weight original pixel value \\(x_{,k}\\). local class covariance \\(\\mathbf{S}_{}\\) decreases relative smoothness factor \\(\\boldsymbol\\Sigma_{}\\), confidence influence neighborhood increases. smoothing procedure relevant situations original classification odds ratio low, showing low level separability classes. cases, updated values classes influenced local class variances.practice, \\(\\boldsymbol\\Sigma_{}\\) user-controlled covariance matrix parameter set users based knowledge region classified. simplest case, users can associate conditional covariance \\(\\boldsymbol\\Sigma_{}\\) diagonal matrix, using one hyperparameter \\(\\sigma^2_k\\) set level smoothness. Higher values \\(\\sigma^2_k\\) cause assignment local mean pixel updated probability. case, classification tests, decided use \\(\\sigma^2_k=20\\) default \\(k\\).version implemented sits includes following parameterssmoothness: user-controlled parameter controls influence neighborhood values probabibility value class pixel. Can defined unique value classes, matrix whose size size \\(num_classes * num_classes\\). default value 20, users encouraged define smoothness diagonal matrix whose values reflect relative importance class output product.window_size: size \\(n*n\\) window used define neighborhood.neigh_fraction: percentage pixels per window used calculate local class statistics. aim use pixels window likely part class central pixel. example, window_size size 9 neigh_fraction 0.5, half pixels 9 x 9 window (higher class probabibility) used estimate local class statistics \\(\\mathbf{m}_{,t}\\) \\(\\mathbf{S}_{,t}\\) represent mean standard deviation classes associated prox","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
