[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Satellite images provide key information Earth’s environment impacts caused human actions. Petabytes Earth observation data now open free, making full extent image archives available. Using image time series, analysts make best use full extent big Earth observation data collections, capturing subtle changes ecosystem health condition improving distinction different land classes.book introduces sits, open-source R package land use land cover classification big Earth observation data using satellite image time series. Users build regular data cubes cloud services Amazon Web Services, Microsoft Planetary Computer, Brazil Data Cube, Digital Earth Africa. sits API includes assessment training sample quality, machine learning deep learning classification algorithms, Bayesian post-processing methods smoothing uncertainty assessment. evaluate results, sits supports best practice accuracy assessments.","code":""},{"path":"index.html","id":"who-this-book-is-for","chapter":"Preface","heading":"Who this book is for","text":"target audience sits community remote sensing experts Earth Sciences background want use state---art data analysis methods minimal investment programming skills. package provides clear direct set functions, easy learn master. Users minimal background R programming can start using sits right away. yet familiar R need learn introductory concepts.R user like quickly master needed run sits, please read Parts 1 2 Garrett Golemund’s book, Hands-Programming R. already R user like update skills latest trends, please read book Hadley Wickham Gareth Golemund, R Data Science. Important concepts spatial analysis presented Edzer Pebesma Roger Bivand book Spatial Data Science.","code":""},{"path":"index.html","id":"software-version-described-in-this-book","chapter":"Preface","heading":"Software version described in this book","text":"version sits package described book 1.4.0.","code":""},{"path":"index.html","id":"main-reference-for-sits","chapter":"Preface","heading":"Main reference for sits","text":"use sits work, please cite following paper:Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, Karine Ferreira. “Satellite Image Time Series Analysis Big Earth Observation Data”. Remote Sensing, 13, p. 2428, 2021. https://doi.org/10.3390/rs13132428.","code":""},{"path":"index.html","id":"intellectual-property-rights","chapter":"Preface","heading":"Intellectual property rights","text":"book licensed Attribution-NonCommercial-ShareAlike 4.0 International (CC -NC-SA 4.0) Creative Commons. sits package licensed GNU General Public License, version 3.0.","code":""},{"path":"setup.html","id":"setup","chapter":"Setup","heading":"Setup","text":"sits package relies sf terra R packages, require GDAL PROJ libraries. Please follow instructions installing sf terra together GDAL, provided Edzer Pebesma.","code":""},{"path":"setup.html","id":"support-for-gdal-and-proj","chapter":"Setup","heading":"Support for GDAL and PROJ","text":"","code":""},{"path":"setup.html","id":"windows-and-macos","chapter":"Setup","heading":"Windows and MacOS","text":"Windows MacOS users strongly encouraged install sf terra binary packages CRAN. install sits source, please install package Rtools access compiling environment.","code":""},{"path":"setup.html","id":"ubuntu","chapter":"Setup","heading":"Ubuntu","text":"recommend using latest version GDAL, GEOS, PROJ4 libraries binaries. , use repository ubuntugis-unstable, done follows:Getting error adding PPA repository due absence package software-properties-common. GDAL running docker containers, please add security flag --security-opt seccomp=unconfined start.installing GDAL, GEOS, PROJ4, please install packages sf terra, order.","code":"sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install libudunits2-dev libgdal-dev libgeos-dev libproj-dev \nsudo apt-get install gdal-bin\nsudo apt-get install proj-bin\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")"},{"path":"setup.html","id":"debian","chapter":"Setup","heading":"Debian","text":"install Debian, use rocker geospatial dockerfiles.","code":""},{"path":"setup.html","id":"fedora","chapter":"Setup","heading":"Fedora","text":"following command installs required dependencies:","code":"sudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel"},{"path":"setup.html","id":"support-for-deep-learning-with-torch","chapter":"Setup","heading":"Support for deep learning with torch","text":"deep learning models sits use torch package, R version pyTorch. installing sits, please also install packages torch luz, initialize torch.","code":"\ninstall.packages(\"torch\")\ninstall.packages(\"luz\")\ntorch::install_torch()"},{"path":"setup.html","id":"installing-the-sits-package","chapter":"Setup","heading":"Installing the sits package","text":"installing sf, terra, torch, luz, please proceed install sits, available CRAN installed regular R package.source code repository GitHub. install development version sits, contains latest updates might unstable, users install devtools, already available, install sits follows:run examples book, please also install sitsdata package.","code":"\ninstall.packages(\"sits\", dependencies = TRUE)\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sits@dev\", dependencies = TRUE)\noptions(download.file.method = \"wget\")\ndevtools::install_github(\"e-sensing/sitsdata\")"},{"path":"setup.html","id":"using-gpus-with-sits","chapter":"Setup","heading":"Using GPUs with sits","text":"torch package automatically recognizes GPU available machine uses training classification. significant performance gain GPUs used instead CPUs deep learning models. need specific adjustments torch scripts. use GPUs, torch requires version 11.6 CUDA library, available Ubuntu 18.04 20.04.","code":""},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"","code":""},{"path":"acknowledgements.html","id":"funding-sources","chapter":"Acknowledgements","heading":"Funding Sources","text":"authors acknowledge funders supported development sits:Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology, Space Applications (FUNCATE), establishment Brazil Data Cube.Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology, Space Applications (FUNCATE), establishment Brazil Data Cube.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD, post-doc scholarships, equipment, travel support.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD, post-doc scholarships, equipment, travel support.International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084- Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084- Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.","code":""},{"path":"acknowledgements.html","id":"community-contributions","chapter":"Acknowledgements","heading":"Community Contributions","text":"authors thank R-spatial community foundational work, including Marius Appel, Tim Appelhans, Robert Hijmans, Edzer Pebesma, Martijn Tennekes R packages gdalcubes, leafem, terra, sf/stars, tmap. grateful work Dirk Eddelbuettel Rcpp RcppArmadillo Ron Wehrens package kohonen. much indebted Hadley Wickham tidyverse, Daniel Falbel torch luz packages, RStudio team package leaflet. multiple authors machine learning packages randomForest, e1071, xgboost provided robust algorithms. like thank Python developers shared deep learning algorithms image time series classification: Vivien Sainte Fare Garnot, Zhiguang Wang, Maja Schneider, Marc Rußwurm. first author also thanks Roger Bivand benign influence things related R.","code":""},{"path":"acknowledgements.html","id":"reproducible-papers-used-in-building-sits","chapter":"Acknowledgements","heading":"Reproducible papers used in building sits","text":"thank authors following papers making code available.Edzer Pebesma, “Simple Features R: Standardized Support Spatial Vector Data”. R Journal, 10(1):2018.Edzer Pebesma, “Simple Features R: Standardized Support Spatial Vector Data”. R Journal, 10(1):2018.Ron Wehrens Johannes Kruisselbrink, “Flexible Self-Organising Maps kohonen 3.0”. Journal Statistical Software, 87, 7 (2018). https://doi.org/10.18637/jss.v087.i07.Ron Wehrens Johannes Kruisselbrink, “Flexible Self-Organising Maps kohonen 3.0”. Journal Statistical Software, 87, 7 (2018). https://doi.org/10.18637/jss.v087.i07.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, “Deep learning time series classification: review”. Data Mining Knowledge Discovery, 33(4): 917–963, 2019. https://doi.org/10.1007/s10618-019-00619-1.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, “Deep learning time series classification: review”. Data Mining Knowledge Discovery, 33(4): 917–963, 2019. https://doi.org/10.1007/s10618-019-00619-1.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. “Temporal Convolutional Neural Network Classification Satellite Image Time Series”. Remote Sensing 11 (5), 2019. https://doi.org/10.3390/rs11050523.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. “Temporal Convolutional Neural Network Classification Satellite Image Time Series”. Remote Sensing 11 (5), 2019. https://doi.org/10.3390/rs11050523.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, “Breizhcrops: Time Series Dataset Crop Type Mapping”. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, “Breizhcrops: Time Series Dataset Crop Type Mapping”. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marius Appel Edzer Pebesma, “-Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library.” Data 4 (3): 1–16, 2020. https://doi.org/10.3390/data4030092.Marius Appel Edzer Pebesma, “-Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library.” Data 4 (3): 1–16, 2020. https://doi.org/10.3390/data4030092.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, “Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention”, Conference Computer Vision Pattern Recognition, 2020. https://doi.org/10.1109/CVPR42600.2020.01234.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, “Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention”, Conference Computer Vision Pattern Recognition, 2020. https://doi.org/10.1109/CVPR42600.2020.01234.Vivien Garnot, Loic Landrieu, “Lightweight Temporal Self-Attention Classifying Satellite Images Time Series”, 2020. <arXiv:2007.00586>.Vivien Garnot, Loic Landrieu, “Lightweight Temporal Self-Attention Classifying Satellite Images Time Series”, 2020. <arXiv:2007.00586>.Maja Schneider, Marco Körner, “[Re] Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention.” ReScience C 7 (2), 2021. doi:10.5281/zenodo.4835356.Maja Schneider, Marco Körner, “[Re] Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention.” ReScience C 7 (2), 2021. doi:10.5281/zenodo.4835356.","code":""},{"path":"acknowledgements.html","id":"publications-using-sits","chapter":"Acknowledgements","heading":"Publications using sits","text":"section gathers publications used sits generate results.2023Bruno Adorno, Thales Körting, Silvana Amaral, “Contribution time-series data cubes classify urban vegetation types remote sensing”, Urban Forest & Urban Greening, vol. 79, 127817, January 2023. https://doi.org/10.1016/j.ufug.2022.127817.2021Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, “Quality control class noise reduction satellite image time series”. ISPRS Journal Photogrammetry Remote Sensing, vol. 177, pp 75-88, 2021. https://doi.org/10.1016/j.isprsjprs.2021.04.014.Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, “Quality control class noise reduction satellite image time series”. ISPRS Journal Photogrammetry Remote Sensing, vol. 177, pp 75-88, 2021. https://doi.org/10.1016/j.isprsjprs.2021.04.014.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, “Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series”. Remote Sensing, 2021, 13(5), 974; https://doi.org/10.3390/rs13050974.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, “Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series”. Remote Sensing, 2021, 13(5), 974; https://doi.org/10.3390/rs13050974.2020Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira & Alexandre Carvalho. “Land use cover maps Mato Grosso State Brazil 2001 2017”. Nature Scientific Data 7, article 34 (2020). DOI: https://doi.org/10.1038/s41597-020-0371-4.Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira & Alexandre Carvalho. “Land use cover maps Mato Grosso State Brazil 2001 2017”. Nature Scientific Data 7, article 34 (2020). DOI: https://doi.org/10.1038/s41597-020-0371-4.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, “Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017”. Land, 9(1), 2020. https://doi.org/10.3390/land9010020.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, “Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017”. Land, 9(1), 2020. https://doi.org/10.3390/land9010020.Karine Ferreira, Gilberto Queiroz et al., “Earth Observation Data Cubes Brazil: Requirements, Methodology Products”. Remote Sensing, 12, 4033, 2020. https://doi.org/10.3390/rs12244033.Karine Ferreira, Gilberto Queiroz et al., “Earth Observation Data Cubes Brazil: Requirements, Methodology Products”. Remote Sensing, 12, 4033, 2020. https://doi.org/10.3390/rs12244033.Adeline Maciel, Lubia Vinhas, Michelle Picoli Gilberto Camara, “Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier”. Land, 9, 506, 2020. DOI: https://doi.org/10.3390/land9120506.Adeline Maciel, Lubia Vinhas, Michelle Picoli Gilberto Camara, “Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier”. Land, 9, 506, 2020. DOI: https://doi.org/10.3390/land9120506.2018Michelle Picoli, Gilberto Camara, et al., “Big Earth Observation Time Series Analysis Monitoring Brazilian Agriculture”. ISPRS Journal Photogrammetry Remote Sensing, 2018.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction.html","id":"why-work-with-satellite-image-time-series","chapter":"Introduction","heading":"Why work with satellite image time series?","text":"Satellite images comprehensive source data environment. Covering large area Earth’s surface, images allow researchers study regional global changes. Sensors capture data multiple spectral bands measure physical, chemical, biological properties Earth’s surface. observing location multiple times, satellites provide data changes environment survey areas difficult observe ground. Given unique features, images offer essential information many applications, including deforestation, crop production, food security, urban footprints, water scarcity, land degradation.time series set data points collected regular intervals time. Time series data used analyze trends, patterns, changes. Satellite image time series refer time series obtained collection images captured satellite period time, typically months years. Using time series, experts improve understanding ecological patterns processes. Instead selecting individual images specific dates comparing , researchers track change continuously [1].","code":""},{"path":"introduction.html","id":"time-first-space-later","chapter":"Introduction","heading":"Time-first, space-later","text":"“Time-first, space-later” concept satellite image classification takes time series analysis first step analyzing remote sensing data, spatial information considered time series classified. time-first part brings better understanding changes landscapes. Detecting tracking seasonal long-term trends becomes feasible, well identifying anomalous events patterns data, wildfires, floods, droughts. pixel data cube treated time series, using information available temporal instances case. Time series classification pixel-based, producing set labelled pixels. result used input space-later part method. phase, Bayesian smoothing algorithm considers spatial neighbourhood pixel improves results pixel-based classification.","code":""},{"path":"introduction.html","id":"how-sits-works","chapter":"Introduction","heading":"How sits works","text":"sits package uses satellite image time series land classification, using time-first, space-later approach. data preparation part, collections big Earth observation images organized data cubes. spatial location data cube associated time series. Locations known labels train machine learning algorithm, classifies time series data cube, shown Figure 1.\nFigure 1: Using time series land classification (Source: Authors).\npackage provides tools analysis, visualization, classification satellite image time series. Users follow typical workflow:Select analysis-ready data image collection cloud providers AWS, Microsoft Planetary Computer, Digital Earth Africa, Brazil Data Cube.Build regular data cube using chosen image collection.Obtain new bands indices operations data cubes.Extract time series samples data cube used training data.Perform quality control filtering time series samples.Train machine learning model using time series samples.Classify data cube using model get class probabilities pixel.Post-process probability cube remove outliers.Produce labeled map post-processed probability cube.Evaluate accuracy classification using best practices.workflow step corresponds function sits API, shown Table Figure 2. functions convenient default parameters behaviors. single function builds machine learning (ML) models. classification function processes big data cubes efficient parallel processing. Since sits API simple learn, users can achieve good results without -depth knowledge machine learning parallel processing.\nTable 1: sits API workflow land classification\n\nFigure 2: Main functions sits API (Source: Authors).\n","code":""},{"path":"introduction.html","id":"land-use-and-land-cover","chapter":"Introduction","heading":"Land use and land cover","text":"Since main aim sits support land use land cover classification, section presents short discussion use terms. UN Food Agriculture Organization defines land cover “observed biophysical cover Earth’s surface” [2]. Land cover can observed mapped directly remote sensing images. FAO’s guidelines reports, land use described “human activities purposes land managed exploited”. FAO’s land use classifications include classes cropland pasture. One advantages using image time series land classification capacity measuring changes landscape related agricultural practices. example, time series vegetation index area used crop production show pattern minima (planting sowing stages) maxima (flowering stage). Thus, classification schemas based image time series data can richer detailed associated land cover. book uses term “land classification” refer image classification represents land cover land use classes.","code":""},{"path":"introduction.html","id":"classes-and-labels","chapter":"Introduction","heading":"Classes and labels","text":"book, distinguish concepts “class” “label”. class denotes group spatial objects share similar land cover land use, urban areas, forests, water bodies, agricultural fields. Classes defined based specific application study conducted, help analyse vast amount data obtained remote sensing imagery. label assignment identification given specific feature object within image. Labels markers indicate class particular pixel, segment, object belongs. Labels essential supervised classification methods, training dataset known labels used train machine learning algorithm recognize classify new, unlabelled data. Thus, “class” represents overall category group features, “label” refers specific assignment class particular feature object within image.","code":""},{"path":"introduction.html","id":"creating-a-data-cube","chapter":"Introduction","heading":"Creating a Data Cube","text":"two kinds data cubes sits: () irregular data cubes generated selecting image collections cloud providers AWS Planetary Computer; (b) regular data cubes images fully covering chosen area, image spectral bands spatial resolution, images follow set adjacent regular time intervals. Machine learning applications need regular data cubes. Please refer Chapter Earth observation data cubes details.first steps using sits : () select analysis-ready data image collection available cloud provider stored locally using sits_cube(); (b) collection regular, use sits_regularize() build regular data cube.section shows build data cube local images already organized regular data cube. data cube composed MODIS MOD13Q1 images Sinop region Mato Grosso, Brazil. images indexes NDVI EVI covering one-year period 2013-09-14 2014-08-29 (use “year-month-day” dates). 23 time instances, covering 16-day period. data available R package sitsdata.build data cube local files, users must provide information original source data obtained. case, sits_cube() needs parameters:source, cloud provider data obtained (case, Brazil Data Cube “BDC”);collection, collection cloud provider images extracted. case, data comes MOD13Q1 collection 6;data_dir, local directory image files stored;parse_info, vector strings stating file names store information “tile”, “band”, “date”. case, local images stored files like TERRA_MODIS_012010_EVI_2014-07-28.tif. file represents tile 012010, band EVI, date 2014-07-28.\nFigure 3: Color composite image MODIS cube NDVI band 2013-09-14 (Source: Authors).\naim parse_info parameter extract tile, band date information file name. Given large variation image file names generated different produces, includes designators X1 X2; place holders parts file name relevant sits_cube().R object returned sits_cube() contains metadata describing contents data cube. includes data source collection, satellite, sensor, tile collection, bounding box, projection, list files. file refers one band image one temporal instances cube.","code":"\n# Create a data cube object based on the information about the files\nsinop <- sits_cube(\n  source = \"BDC\", \n  collection  = \"MOD13Q1-6\",\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),  \n  parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\")\n)\n# Plot the NDVI for the first date (2013-09-14)\nplot(sinop, \n     band = \"NDVI\", \n     dates = \"2013-09-14\",\n     palette = \"RdYlGn\")\n# Show the R object that describes the data cube\nsinop#> # A tibble: 1 × 11\n#>   source collection satellite sensor tile        xmin      xmax    ymin    ymax crs  \n#>   <chr>  <chr>      <chr>     <chr>  <chr>      <dbl>     <dbl>   <dbl>   <dbl> <chr>\n#> 1 BDC    MOD13Q1-6  TERRA     MODIS  012010 -6181982. -5963298. -1.35e6 -1.23e6 \"PRO…\n#> # ℹ 1 more variable: file_info <list>"},{"path":"introduction.html","id":"the-time-series-tibble","chapter":"Introduction","heading":"The time series tibble","text":"handle time series information, sits uses tibble. Tibbles extensions data.frame tabular data structures provided tidyverse set packages. example shows time series tibble 1,218 time series obtained MODIS MOD13Q1 images. series four attributes: two bands (NIR MIR) two indexes (NDVI EVI). data set available package sitsdata.time series tibble contains data metadata. first six columns contain metadata: spatial temporal information, label assigned sample, data cube data extracted. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band. details handling time series data, please see Chapter Working time series.helpful plot dispersion time series. follows, brevity, filter one label (“Forest”) select one index (NDVI). Note filtering label use function dplyr package, selecting index use sits_select(). resulting plot shows time series associated label “Forest” index NDVI, highlighting median first third quartiles.\nFigure 4: Joint plot samples band NDVI label Forest (Source: Authors).\n","code":"\n# Load the MODIS samples for Mato Grosso from the \"sitsdata\" package\nlibrary(tibble)\nlibrary(sitsdata)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\nsamples_matogrosso_mod13q1[1:2,]#> # A tibble: 2 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\nsamples_forest <- dplyr::filter(\n    samples_matogrosso_mod13q1, \n    label == \"Forest\"\n)\nsamples_forest_ndvi <- sits_select(\n    samples_forest, \n    band = \"NDVI\"\n)\nplot(samples_forest_ndvi)"},{"path":"introduction.html","id":"training-a-machine-learning-model","chapter":"Introduction","heading":"Training a machine learning model","text":"next step train machine learning (ML) model using sits_train(). takes two inputs, samples (time series table) ml_method (function implements machine learning algorithm). result model used classification. ML algorithm requires specific parameters user-controllable. novice users, sits provides default parameters produce good results. Please see Chapter Machine learning data cubes details.Since time series data four attributes (EVI, NDVI, NIR, MIR) data cube images two, select NDVI EVI values use resulting data training. build classification model, use random forest model called sits_rfor().\nFigure 5: relevant variables trained random forest model (Source: Authors).\n","code":"\n# Select the bands NDVI and EVI\nsamples_2bands <- sits_select(\n    data = samples_matogrosso_mod13q1, \n    bands = c(\"NDVI\", \"EVI\")\n)\n# Train a random forest model\nrf_model <- sits_train(\n    samples = samples_2bands, \n    ml_method = sits_rfor()\n)\n# Plot the most important variables of the model\nplot(rf_model)"},{"path":"introduction.html","id":"data-cube-classification","chapter":"Introduction","heading":"Data cube classification","text":"training machine learning model, next step classify data cube using sits_classify(). function produces set raster probability maps, one class. maps, value pixel proportional probability belongs class. function two mandatory parameters: data, data cube time series tibble classified; ml_model, trained ML model. Optional parameters include: () multicores, number cores used; (b) memsize, RAM used classification; (c) output_dir, directory classified raster files written. Details classification process available “Image classification data cubes”.\nFigure 6: Probability map class Forest (Source: Authors).\ncompleting classification, plot probability maps class “Forest”. Probability maps helpful visualize degree confidence classifier assigns labels pixel. can used produce uncertainty information support active learning, described Chapter Image classification data cubes.","code":"\n# Classify the raster image\nsinop_probs <- sits_classify(\n    data = sinop, \n    ml_model = rf_model,\n    multicores = 2,\n    memsize = 8,\n    output_dir = \"./tempdir/chp3\"\n)\n# Plot the probability cube for class Forest\nplot(sinop_probs, labels = \"Forest\", palette = \"BuGn\")"},{"path":"introduction.html","id":"spatial-smoothing","chapter":"Introduction","heading":"Spatial smoothing","text":"working big Earth observation data, much variability class. result, pixels misclassified. errors likely occur transition areas classes. address problems, sits_smooth() takes probability cube input uses class probabilities pixel’s neighborhood reduce labeling uncertainty. Plotting smoothed probability map class “Forest” shows outliers removed.\nFigure 7: Smoothed probability map class Forest (Source: Authors).\n","code":"\n# Perform spatial smoothing\nsinop_bayes <- sits_smooth(\n    cube = sinop_probs,\n    multicores = 2,\n    memsize = 8,\n    output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_bayes, labels = \"Forest\", palette = \"Blues\")"},{"path":"introduction.html","id":"labeling-a-probability-data-cube","chapter":"Introduction","heading":"Labeling a probability data cube","text":"removing outliers using local smoothing, final classification map can obtained using sits_label_classification(). function assigns pixel class highest probability.\n\nFigure 8: Classification map Sinop (Source: Authors).\nresulting classification files can read QGIS. Links associated files available sinop_map object nested table file_info.shown Introduction, sits provides end--end API land classification.\nfollows, Chapter provides detailed description training, modeling, classification workflow.","code":"\n# Label the probability file \nsinop_map <- sits_label_classification(\n    cube = sinop_bayes, \n    output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_map, title = \"Sinop Classification Map\")\n# Show the location of the classification file\nsinop_map$file_info[[1]]#> # A tibble: 1 × 12\n#>   band  start_date end_date   ncols nrows  xres  yres    xmin    xmax    ymin    ymax\n#>   <chr> <date>     <date>     <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 class 2013-09-14 2014-08-29   944   551  232.  232. -6.18e6 -5.96e6 -1.35e6 -1.23e6\n#> # ℹ 1 more variable: path <chr>"},{"path":"earth-observation-data-cubes.html","id":"earth-observation-data-cubes","chapter":"Earth observation data cubes","heading":"Earth observation data cubes","text":"","code":""},{"path":"earth-observation-data-cubes.html","id":"analysis-ready-data-image-collections","chapter":"Earth observation data cubes","heading":"Analysis-ready data image collections","text":"Analysis-ready data (ARD) images ready analysis without need preprocessing transformation. simplify accelerate analysis Earth observation data providing consistent high-quality data standardized across different sensors platforms. ARD data typically provided collection files, pixel contains single value spectral band given date.ARD collections available cloud services Amazon Web Service, Brazil Data Cube, Digital Earth Africa, Swiss Data Cube, Microsoft’s Planetary Computer. collections processed improve multidate comparability. Radiance measures top atmosphere converted ground reflectance measures. general, timelines images ARD collection different. Images still contain cloudy missing pixels; bands images collection may different resolutions. Figure 9 shows example Landsat ARD image collection.\nFigure 9: ARD image collection (Source: USGS. Reproduction based fair use doctrine).\nARD image collections organized spatial partitions. Sentinel-2/2A images follow Military Grid Reference System (MGRS) tiling system, divides world 60 UTM zones 8 degrees longitude. zone blocks 6 degrees latitude. Blocks split tiles \\(110 \\times 110\\) km\\(^2\\) 10 km overlap. Figure 10 shows MGRS tiling system part Northeastern coast Brazil, contained UTM zone 24, block M.\nFigure 10: MGRS tiling system used Sentinel-2 images (Source: GISSurfer 2.0. Reproduction based fair use doctrine).\nLandsat-4/5/7/8/9 satellites use Worldwide Reference System (WRS-2), breaks coverage Landsat satellites images identified path row (see Figure 11). path descending orbit satellite; WRS-2 system 233 paths per orbit, path 119 rows, row refers latitudinal center line frame imagery. Images WRS-2 geometrically corrected UTM projection.\nFigure 11: WRS-2 tiling system used Landsat-5/7/8/9 images (Source: INPE ESRI. Reproduction based fair use doctrine).\n","code":""},{"path":"earth-observation-data-cubes.html","id":"ard-image-collections-handled-by-sits","chapter":"Earth observation data cubes","heading":"ARD image collections handled by sits","text":"Package sits supports access following ARD image collections:Amazon Web Services (AWS): Open data Sentinel-2/2A level 2A collections Earth’s land surface.Brazil Data Cube (BDC): Open data collections Sentinel-2/2A, Landsat-8, CBERS-4/4A, MODIS images Brazil. collections organized regular data cubes.Digital Earth Africa (DEAFRICA): Open data collections Sentinel-2/2A Landsat-8 Africa.Microsoft Planetary Computer (MPC): Open data collections Sentinel-2/2A Landsat-4/5/7/8/9 Earth’s land areas.USGS: Landsat-4/5/7/8/9 collections available AWS, require access payment.Swiss Data Cube (SDC): Open data collection Sentinel-2/2A Landsat-8 images Switzerland.","code":""},{"path":"earth-observation-data-cubes.html","id":"regular-image-data-cubes","chapter":"Earth observation data cubes","heading":"Regular image data cubes","text":"Machine learning deep learning (ML/DL) classification algorithms require input data consistent. dimensionality data used training model data classified. gaps missing values. Thus, use ML/DL algorithms remote sensing data, ARD image collections converted regular data cubes. Following Appel Pebesma [3], regular data cube following definition properties:regular data cube four-dimensional structure dimensions x (longitude easting), y (latitude northing), time, bands.spatial dimensions refer single spatial reference system (SRS). Cells data cube constant spatial size respect cube’s SRS.temporal dimension set continuous equally-spaced intervals.every combination dimensions, cell single value.cells data cube spatiotemporal extent. spatial resolution cell X Y dimensions. temporal intervals . cell contains valid set measures. position space, data cube provide set valid time series. time interval, regular data cube provide valid 2D image (see Figure 12.\nFigure 12: Conceptual view data cubes (Source: Authors).\nCurrently, cloud service provides regular data cubes default Brazil Data Cube (BDC). ARD collections available AWS, MSPC, USGS, DEAFRICA regular space time. Bands may different resolutions, images may cover entire time, time intervals may irregular. reason, subsets collections need converted regular data cubes processing. produce data cubes machine-learning data analysis, users first create irregular data cube ARD collection use sits_regularize(), described .","code":""},{"path":"earth-observation-data-cubes.html","id":"creating-data-cubes","chapter":"Earth observation data cubes","heading":"Creating data cubes","text":"obtain information ARD image collection cloud providers, sits uses SpatioTemporal Asset Catalogue (STAC) protocol, specification geospatial information many large image collection providers adopted. ‘spatiotemporal asset’ file represents information Earth captured specific space time. access STAC endpoints, sits uses rstac R package.function sits_cube() supports access image collections cloud services; following parameters:source: Name provider.collection: collection available provider supported sits. find collections supported sits, see sits_list_collections().platform: Optional parameter specifying platform collections multiple satellites.tiles: Set tiles image collection reference system. Either tiles roi specified.roi: region interest. Either: () named vector (lon_min, lon_max, lat_min, lat_max) WGS 84 coordinates; (b) sf object. images intersecting convex hull roi selected.bands: Optional parameter bands used. missing, bands collection used.start_date: initial date temporal interval containing time series images.end_date: final date temporal interval containing time series images.result sits_cube() tibble description selected images required processing. contain actual data, pointers images. attributes individual image files can assessed listing file_info column tibble.","code":""},{"path":"earth-observation-data-cubes.html","id":"assessing-amazon-web-services","chapter":"Earth observation data cubes","heading":"Assessing Amazon Web Services","text":"Amazon Web Services (AWS) holds two kinds collections: open-data requester-pays. Open data collections can accessed without cost. Requester-pays collections require payment AWS account. Currently, sits supports collections SENTINEL-S2-L2A (requester-pays) SENTINEL-S2-L2A-COGS (open-data). collections include Sentinel-2/2A bands. bands 10m resolution B02, B03, B04, B08. 20m bands B05, B06, B07, B8A, B11, B12. Bands B01 B09 available 60m resolution. CLOUD band also available. example shows access one tile open data SENTINEL-S2-L2A-COGS collection. tiles parameter allows selecting desired area according MGRS reference system.\nFigure 13: Sentinel-2 image area Northeastern coast Brazil (Source: Authors).\n","code":"\n# Create a data cube covering an area in Brazil\ns2_23MMU_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"23MMU\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2018-07-12\",\n  end_date = \"2019-07-28\"\n)\nplot(s2_23MMU_cube,\n  red = \"B11\",\n  blue = \"B02\", green = \"B8A\", date = \"2018-10-05\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-microsofts-planetary-computer","chapter":"Earth observation data cubes","heading":"Assessing Microsoft’s Planetary Computer","text":"Microsoft’s Planetary Computer (MPC) hosts two open data collections: SENTINEL-2-L2A LANDSAT-C2-L2. first collection contains SENTINEL-2/2A ARD images, bands resolutions available AWS (see ). example shows access SENTINEL-2-L2A collection.\nFigure 14: Sentinel-2 image area state Rondonia, Brazil (Source: Authors).\nLANDSAT-C2-L2 collection provides access data Landsat-4/5/7/8/9 satellites. Images satellites intercalibrated ensure data consistency. compatibility different Landsat sensors, band names BLUE, GREEN, RED, NIR08, SWIR16, SWIR22. images 30m resolution. collection, tile search supported; roi parameter used. example shows retrieve data region interest covering city Brasilia Brazil.\nFigure 15: Landsat-8 image area city Brasilia, Brazil (Source: Authors).\n","code":"\n# Create a data cube covering an area in the Brazilian Amazon\ns2_20LKP_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"20LKP\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2019-07-01\",\n  end_date = \"2019-07-28\"\n)\n# Plot a color composite of one date of the cube\nplot(s2_20LKP_cube_MPC,\n  red = \"B11\", blue = \"B02\", green = \"B8A\",\n  date = \"2019-07-18\"\n)\n# Read a shapefile that covers the city of Brasilia\nshp_file <- system.file(\"extdata/shapefiles/df_bsb/df_bsb.shp\",\n  package = \"sitsdata\"\n)\nsf_bsb <- sf::read_sf(shp_file)\n# Select the cube\ns2_L8_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"LANDSAT-C2-L2\",\n  bands = c(\"BLUE\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi = sf_bsb,\n  start_date = \"2019-06-01\",\n  end_date = \"2019-10-01\"\n)\n# Plot the second tile that covers Brasilia\nplot(s2_L8_cube_MPC[2, ],\n  red = \"SWIR16\", green = \"NIR08\", blue = \"BLUE\",\n  date = \"2019-07-30\"\n)"},{"path":"earth-observation-data-cubes.html","id":"assessing-digital-earth-africa","chapter":"Earth observation data cubes","heading":"Assessing Digital Earth Africa","text":"Digital Earth Africa (DEAFRICA) cloud service provides open-access Earth observation data African continent. ARD image collections sits S2_L2A (Sentinel-2 level 2A) LS8_SR (Landsat-8). Since STAC interface DEAFRICA implement concept tiles, users need specify area interest using roi parameter. requested roi produces cube contains three MGRS tiles (“35HLD”, “35HKD”, “35HLC”) covering part South Africa.\nFigure 16: Sentinel-2 image area South Africa (Source: Authors).\n","code":"\ndea_cube <- sits_cube(\n    source = \"DEAFRICA\",\n    collection = \"S2_L2A\",\n    roi = c(lon_min = 24.97, lat_min = -34.30,\n            lon_max = 25.87, lat_max = -32.63),\n    bands = c(\"B05\", \"B8A\", \"B11\"),\n    start_date = \"2019-09-01\",\n    end_date = \"2019-10-01\")\nplot(dea_cube, red = \"B11\", blue = \"B05\", green = \"B8A\")"},{"path":"earth-observation-data-cubes.html","id":"assessing-the-brazil-data-cube","chapter":"Earth observation data cubes","heading":"Assessing the Brazil Data Cube","text":"Brazil Data Cube (BDC) built Brazil’s National Institute Space Research (INPE). BDC uses three hierarchical grids based Albers Equal Area projection SIRGAS 2000 datum. three grids generated taking -54\\(^\\circ\\) longitude central reference defining tiles \\(6\\times4\\), \\(3\\times2\\), \\(1.5\\times1\\) degrees. large grid tiles \\(672\\times440\\) km2 used CBERS-4 AWFI collections 64 meter resolution; CBERS-4 AWFI tile contains images \\(10,504\\times6,865\\) pixels. medium grid used Landsat-8 OLI collections 30 meter resolution; tiles extension \\(336\\times220\\) km2, image \\(11,204\\times7,324\\) pixels. small grid covers \\(168\\times110\\) km2 used Sentinel-2 MSI collections 10m resolutions; image \\(16,806\\times10,986\\) pixels. data cubes BDC regularly spaced time cloud-corrected [4].\nFigure 17: Hierarchical BDC tiling system showing () overlayed Brazilian biomes, (b) illustrating one large tile, (c) four medium tiles, (d) sixteen small tiles (Source: Ferreira et al. (2020). Reproduction fair use doctrine).\ncollections available BDC : LC8_30_16D_STK-1 (Landsat-8 OLI, 30m resolution, 16-day intervals), S2-SEN2COR_10_16D_STK-1 (Sentinel-2 MSI images 10 meter resolution, 16-day intervals), CB4_64_16D_STK-1 (CBERS 4/4A AWFI, 64m resolution, 16 days intervals), CB4_20_1M_STK-1 (CBERS 4/4A MUX, 20m resolution, one month intervals), MOD13Q1-6 (MODIS MOD13SQ1 product, collection 6, 250m resolution, 16-day intervals). details, use sits_list_collections(source = \"BDC\").access BDC, users must provide credentials using environment variables, shown . Obtaining BDC access key free. Users must register BDC site obtain key.example , data cube defined one tile (“022024”) CB4_64_16D_STK-1 collection, holds CBERS AWFI images 16 days resolution.\nFigure 18: Plot CBERS-4 image obtained BDC single tile covering area Brazilian Cerrado (Source: Authors).\n","code":"Sys.setenv(\"BDC_ACCESS_KEY\" = <your_bdc_access_key>)\n# Define a tile from the CBERS-4/4A AWFI collection\ncbers_tile <- sits_cube(\n    source = \"BDC\",\n    collection = \"CB4_64_16D_STK-1\",\n    tiles = \"022024\",\n    bands = c(\"B13\", \"B14\", \"B15\", \"B16\", \"CLOUD\"),\n    start_date = \"2018-09-01\",\n    end_date = \"2019-08-28\")\n# Plot one time instance\nplot(cbers_tile, red = \"B15\", green = \"B16\", blue = \"B13\", date = \"2018-09-30\")"},{"path":"earth-observation-data-cubes.html","id":"defining-a-data-cube-using-ard-local-files","chapter":"Earth observation data cubes","heading":"Defining a data cube using ARD local files","text":"ARD images downloaded cloud collections local computer associated STAC endpoint describes . must organized named allow sits create data cube . local files directory spatial resolution projection. file must contain single image band single date. file name needs include tile, date, band information. Users must provide information original data source allow sits retrieve information image attributes band names, missing values, etc. working local cubes, sits_cube() needs following parameters:source: Name original data provider; either BDC, AWS, USGS, MSPC, DEAFRICA.collection: Collection data extracted.data_dir: Local directory images.bands: Optional parameter describe bands retrieved.parse_info: Information parse file names. File names need contain information tile, date, band, separated delimiter (usually “_“).delim: Separator character descriptors file name (default “_“).example shows define data cube using files sitsdata package. data set contains part tile “20LKP” Sentinel-2 images period 2020-06-04 2021-08-26, bands “B02”, “B8A”, “B11”. Data extracted collection “SENTINEL-2-L2A” Microsoft Planetary Computer (“MPC”). Given file name cube_20LKP_B02_2020-06-04.tif, parameter parse_info must set c(\"X1\", \"tile\", \"band\", \"date\") retrieving information images.\nFigure 19: CBERS-4 NDVI area Brazil (Source: Authors).\n","code":"\nlibrary(sits)\n# Create a cube based on a stack of CBERS data\ndata_dir <- system.file(\"extdata/Rondonia-20LKP\", package = \"sitsdata\")\n# List the first file\nlist.files(data_dir)[1]#> [1] \"cube_20LKP_B02_2020-06-04.tif\"\n# Create a data cube from local files\ns2_cube_20LKP <- sits_cube(\n    source = \"MPC\",\n    collection = \"SENTINEL-2-L2A\",\n    data_dir = data_dir,\n    parse_info = c(\"X1\", \"tile\", \"band\", \"date\"))\n\n# Plot the band B8A in the first time instance\nplot(s2_cube_20LKP, red = \"B11\", green = \"B8A\", blue = \"B02\", \n     dates = \"2021-07-25\")"},{"path":"earth-observation-data-cubes.html","id":"defining-a-data-cube-using-classified-images","chapter":"Earth observation data cubes","heading":"Defining a data cube using classified images","text":"also possible create local cubes based results produced classification post-classification algorithms. case, parameters required, parameter parse_info specified differently, follows:source: Name original data provider.collection: Name collection data extracted.data_dir: Local directory classified images.band: Band name associated type result. Use: () probs probability cubes produced sits_classify(); (b) bayes, cubes produced sits_smooth(); (c) entropy, least, ratio margin, according method selected using sits_uncertainty(); (d) class classified cubes.labels: Labels associated names classes (required cubes produced sits_uncertainty()).version: Version result (default = v1).parse_info: File name parsing information allow sits deduce values tile, start_date, end_date, band, version file name. Unlike non-classified image files, cubes produced classification post-classification start_date end_date.following code creates results cube based classification deforestation Brazil. classified cube obtained large data cube Sentinel-2 images, covering state Rondonia, Brazil comprising 40 tiles, 10 spectral bands, covering period 2020-06-01 2021-09-11. Samples four classes trained random forest classifier.\nFigure 20: Classified data cube year 2020/2021 Rondonia, Brazil (Source: Authors).\n","code":"\n# Create a cube based on a classified image \ndata_dir <- system.file(\"extdata/Rondonia-20LLP\", \n                        package = \"sitsdata\")\n# File name  \"SENTINEL-2_MSI_20LLP_2020-06-04_2021-08-26_class_v1.tif\" \nRondonia_class_cube <- sits_cube(\n    source = \"AWS\",\n    collection = \"SENTINEL-S2-L2A-COGS\",\n    bands = \"class\",\n    labels = c(\"Burned_Area\", \"Cleared_Area\", \n               \"Highly_Degraded\", \"Forest\"),\n    data_dir = data_dir,\n    parse_info = c(\"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\", \n                   \"band\", \"version\"))\n# Plot the classified cube\nplot(Rondonia_class_cube)"},{"path":"earth-observation-data-cubes.html","id":"regularizing-data-cubes","chapter":"Earth observation data cubes","heading":"Regularizing data cubes","text":"ARD collections available AWS, MSPC, USGS, DEAFRICA regular space time. Bands may different resolutions, images may cover entire tile, time intervals irregular. reason, data collections need converted regular data cubes calling sits_regularize(), uses gdalcubes package [3].following example, user created irregular data cube Sentinel-2 collection available Microsoft’s Planetary Computer (MSPC) tiles 20LKP 20LLP state Rondonia, Brazil. first build irregular data cube using sits_cube().\nFigure 21: Sentinel-2 tile 20LLP date 2018-07-03 (Source: Authors).\ndifferent acquisition orbits Sentinel-2 Sentinel-2A satellites, two tiles also different timelines. Tile 20LKP 12 instances, tile 20LLP 24 instances chosen period. function sits_regularize() builds data cube regular timeline best estimate valid pixel interval. period parameter sets time interval two images. Values period use ISO8601 time period specification, defines time intervals P[n]Y[n]M[n]D, “Y” stands years, “M” months, “D” days. Thus, P1M stands one-month period, P15D fifteen-day period. joining different images get best image period, sits_regularize() uses aggregation method organizes images chosen interval order increasing cloud cover selects first cloud-free pixel.\nFigure 22: Regularized image tile Sentinel-2 tile 20LLP (Source: Authors).\nobtaining regular data cube, users can perform data analysis classification operations, shown following chapters.","code":"\n# Creating an irregular data cube from MSPC\ns2_cube <- sits_cube(\n    source = \"MPC\",\n    collection = \"SENTINEL-2-L2A\",\n    tiles = c(\"20LKP\", \"20LLP\"),\n    bands = c(\"B05\", \"B8A\", \"B12\", \"CLOUD\"),\n    start_date = as.Date(\"2018-07-01\"),\n    end_date = as.Date(\"2018-08-31\"))\n# Show the different timelines of the cube tiles\nsits_timeline(s2_cube)#> $`20LKP`\n#>  [1] \"2018-07-03\" \"2018-07-08\" \"2018-07-13\" \"2018-07-18\" \"2018-07-23\" \"2018-07-28\"\n#>  [7] \"2018-08-02\" \"2018-08-07\" \"2018-08-12\" \"2018-08-17\" \"2018-08-22\" \"2018-08-27\"\n#> \n#> $`20LLP`\n#>  [1] \"2018-07-03\" \"2018-07-05\" \"2018-07-08\" \"2018-07-10\" \"2018-07-13\" \"2018-07-15\"\n#>  [7] \"2018-07-18\" \"2018-07-20\" \"2018-07-23\" \"2018-07-25\" \"2018-07-28\" \"2018-07-30\"\n#> [13] \"2018-08-02\" \"2018-08-04\" \"2018-08-07\" \"2018-08-09\" \"2018-08-12\" \"2018-08-14\"\n#> [19] \"2018-08-17\" \"2018-08-19\" \"2018-08-22\" \"2018-08-24\" \"2018-08-27\" \"2018-08-29\"\n# plot the first image of the irregular cube\ns2_cube %>% \n    dplyr::filter(tile == \"20LLP\") %>% \n    plot(red = \"B12\", green = \"B8A\", blue = \"B05\", date = \"2018-07-03\")\n# Regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n          cube       = s2_cube,\n          output_dir = \"./tempdir/chp4\",\n          res        = 120,\n          period     = \"P15D\",\n          multicores = 4)\n# Plot the first image of the tile 20LLP of the regularized cube\n# The pixels of the regular data cube cover the full MGRS tile\nreg_cube %>% \n    dplyr::filter(tile == \"20LLP\") %>% \n    plot(red = \"B12\", green = \"B8A\", blue = \"B05\")"},{"path":"operations-on-data-cubes.html","id":"operations-on-data-cubes","chapter":"Operations on data cubes","heading":"Operations on data cubes","text":"","code":""},{"path":"operations-on-data-cubes.html","id":"pixel-based-and-neighborhood-based-operations","chapter":"Operations on data cubes","heading":"Pixel-based and neighborhood-based operations","text":"Pixel-based operations remote sensing images refer image processing techniques operate individual pixels cells image without considering spatial relationships neighboring pixels. operations typically applied pixel image independently can used extract information spectral, radiometric, spatial properties. Pixel-based operations produce spectral indexes combine data multiple bands.Neighborhood-based operations applied groups pixels image. neighborhood typically defined rectangular circular region centered given pixel. operations can used removing noise, detecting edges, sharpening, among uses.sits_apply() function computes new indices desired mathematical operation function bands available cube using valid R expression. applies operation tiles temporal intervals. two types operations sits_apply():Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin()).Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin()).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation), w_var() (variance). Users set window size (odd values allowed).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation), w_var() (variance). Users set window size (odd values allowed).following examples show use sits_apply().","code":""},{"path":"operations-on-data-cubes.html","id":"computing-ndvi-and-its-variations","chapter":"Operations on data cubes","heading":"Computing NDVI and its variations","text":"Using vegetation indexes established practice remote sensing. indexes aim improve discrimination vegetation structure combining two wavebands, one leaf pigments reflect incoming light another leaves absorb incoming radiation. Green leaves natural vegetation forests strong emissivity rate near-infrared bands low emissivity rates red bands electromagnetic spectrum. spectral properties used calculate Normalized Difference Vegetation Index (NDVI), widely used index computed normalized difference values infra-red red bands. Including red-edge bands Sentinel-2 images broadened scope bands used calculate indices [5], [6]. follows, show examples vegetation index calculation using Sentinel-2 data cube.First, define data cube tile state Rondonia, Brazil, including bands used compute different vegetation indexes. regularize cube using target resolution 60 meters reduce processing time.many options calculating NDVI-related indexes Sentinel-2 bands. widely used method combines band B08 (785-899 nm) band B04 (650-680 nm). Recent works literature propose using red-edge bands B05 (698-713 nm), B06 (733-748 nm), B07 (773-793 nm) capturing subtle variations chlorophyll absorption producing indexes, called Normalized Difference Vegetation Red-edge indexes (NDRE) [5]. recent paper, Sun et al. [6] argue vegetation index built using bands B06 B07 provide better approximation leaf area index estimates. recent review, Chaves et al. [7] argue red-edge bands important distinguishing leaf structure chlorophyll content different vegetation species. example , show include additional indexes regular data cube Sentinel-2 spectral bands.first calculate NDVI usual way, using bands B08 B04.\nFigure 23: NDVI using bands B08 B04 Sentinel-2 (Source: Authors).\nnow compare traditional NDVI vegetation indexes computed using red-edge bands. first compute NDRE1 using bands B06 B05.\nFigure 24: NDRE1 using bands B06 B05 Sentinel-2 (Source: Authors).\nNotice contrast forests deforested areas robust NDRE1 index NDVI. compare index red-edge based indexes, one option compute NDRE2 using bands B07 B05, shown .\nFigure 25: NDRE2 using bands B07 B05 Sentinel-2 (Source: Authors).\nFinally, can calculate third red-edge based vegetation index using bands B07 B06.\nFigure 26: NDVI using bands B07 B06 Sentinel-2 (Source: Authors).\n","code":"\n# Create a directory to store files\nif (!file.exists(\"./tempdir/chp5\"))\n    dir.create(\"./tempdir/chp5\")\n# Create an irregular data cube from MSPC\ns2_cube <- sits_cube(\n    source = \"AWS\",\n    collection = \"SENTINEL-S2-L2A-COGS\",\n    tiles = \"20LKP\",\n    bands = c(\"B02\", \"B03\", \"B04\", \n              \"B05\", \"B06\", \"B07\", \n              \"B08\", \"B8A\", \"B11\", \n              \"B12\",\"CLOUD\"),\n    start_date = as.Date(\"2018-07-01\"),\n    end_date = as.Date(\"2018-08-31\"))\n# Regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n          cube       = s2_cube,\n          output_dir = \"./tempdir/chp5\",\n          res        = 60,\n          period     = \"P15D\",\n          multicores = 4)\n# Calculate NDVI index using bands B08 and B04\nreg_cube <- sits_apply(reg_cube,\n    NDVI = (B08 - B04)/(B08 + B04),\n    output_dir = \"./tempdir/chp5\",\n    multicores = 4,\n    memsize = 12)\nplot(reg_cube, band = \"NDVI\", palette = \"RdYlGn\")\n# Calculate NDRE1 index using bands B06 and B05\nreg_cube <- sits_apply(reg_cube,\n    NDRE1 = (B06 - B05)/(B06 + B05),\n    output_dir = \"./tempdir/chp5\",\n    multicores = 4,\n    memsize = 12)\n# Plot NDRE1 index\nplot(reg_cube, band = \"NDRE1\",  palette = \"RdYlGn\")\n# Calculate NDRE2 index using bands B07 and B05\nreg_cube <- sits_apply(reg_cube,\n    NDRE2 = (B07 - B05)/(B07 + B05),\n    output_dir = \"./tempdir/chp5\",\n    multicores = 4,\n    memsize = 12)\n# Plot NDRE2 index\nplot(reg_cube, band = \"NDRE2\", palette = \"RdYlGn\")\n# Calculate NDRE3 index using bands B07 and B06 \nreg_cube <- sits_apply(reg_cube,\n    NDRE3 = (B07 - B06)/(B07 + B06),\n    output_dir = \"./tempdir/chp5\",\n    multicores = 4,\n    memsize = 12)\n# plot NDRE3 index\nplot(reg_cube, band = \"NDRE3\", palette = \"RdYlGn\")"},{"path":"operations-on-data-cubes.html","id":"spectral-indexes-for-identifying-burned-areas","chapter":"Operations on data cubes","heading":"Spectral indexes for identifying burned areas","text":"Band combination can also generate spectral indices detecting degradation fires, important element environmental degradation. Forest fires significantly impact emissions impoverish natural ecosystems [8]. Fires open canopy, making microclimate drier increasing amount dry fuel [9]. One well-established technique detecting burned areas remote sensing images normalized burn ratio (NBR), difference near-infrared short wave infrared band, calculated using bands B8A B12.\nFigure 27: NBR ratio regular data cube built using Sentinel-2 tiles 20LKP 20LLP (Source: Authors).\n","code":"\n# Calculate the NBR index\nreg_cube <- sits_apply(reg_cube,\n    NBR = (B12 - B8A)/(B12 + B8A),\n    output_dir = \"./tempdir/chp5\",\n    multicores = 4,\n    memsize = 12)\n# Plot the NBR for the first date\"\nplot(reg_cube, band = \"NBR\", palette = \"Reds\")"},{"path":"operations-on-data-cubes.html","id":"spectral-mixture-analysis","chapter":"Operations on data cubes","heading":"Spectral mixture analysis","text":"Mixture models statistical models represent pixel values remote sensing image combination multiple pure land cover types. due presence different land cover types, atmospheric conditions, sensor characteristics, can cause pixel values mix different spectral responses. Many pixels images medium-resolution satellites Landsat Sentinel-2 contain mixture spectral responses different land cover types inside resolution element [10]. Assuming set land cover classes (called endmembers) known, spectral mixture analysis derives set new bands containing endmember proportion. used method spectral mixture analysis linear model [10].main idea behind linear mixture model observed pixel spectrum can expressed linear combination spectra pure endmembers, weighted respective proportions (abundances) within pixel. Mathematically, model can represented :\\[\nR_i = \\sum_{j=1}^N a_{,j}*x_j + \\epsilon_i, \\{1,...M}, M > N,\n\\]\n\\(=1,..M\\) set spectral bands \\(j=1,..N\\) set land classes. pixel, \\(R_i\\) reflectance -th spectral band, \\(x_j\\) reflectance value due j-th endmember, \\(a_{,j}\\) proportion j-th endmember -th spectral band. model includes error term \\(e_i\\). linear model can interpreted system equations spectral response pixel linear combination spectral response endmembers [10]. solve system equations obtain proportion endmember, sits uses non-negative least squares (NNLS) regression algorithm, available R package RStoolbox developed Jakob Schwalb-Willmann, based sequential coordinate-wise algorithm (SCA) proposed Franc et al. [11].run mixture model sits, necessary inform values pixels represent spectral responses unique class. -called “pure” pixels. pixels chosen carefully based expert knowledge area. quality resulting endmember images depends quality pure pixels. Since sits supports multiple endmember spectral mixture analysis [12], users can specify one pure pixel per endmember account natural variability.sits, spectral mixture analysis done sits_mixture_model(), two mandatory parameters: cube (data cube) endmembers, named table (equivalent) defines pure pixels. endmembers table must following named columns: () type, defines class associated endmember; (b) names, names bands. line table must contain value endmember bands (see example). improve readability, suggest endmembers parameters defined tribble. tribble tibble easier read row--row layout. example , define three endmembers classes “forest”, “soil”, “water”. Note values band expressed integers ranging 0 10,000.\nFigure 28: Percentage forest per pixel estimated mixture model (Source: Authors).\n\nFigure 29: Percentage water per pixel estimated mixture model (Source: Authors).\n\nFigure 30: Percentage soil per pixel estimated mixture model (Source: Authors).\nLinear mixture models (LMM) improve interpretation remote sensing images accounting mixed pixels providing accurate representation Earth’s surface. key benefits include:Improved classification accuracy: LMMs provide accurate representation mixed pixels considering contributions multiple land classes within single pixel. can lead improved land cover classification accuracy compared conventional per-pixel classification methods, may struggle accurately classify mixed pixels.Improved classification accuracy: LMMs provide accurate representation mixed pixels considering contributions multiple land classes within single pixel. can lead improved land cover classification accuracy compared conventional per-pixel classification methods, may struggle accurately classify mixed pixels.Sub-pixel information: LMMs allow estimation abundances land class within pixel, providing valuable sub-pixel information. can especially useful applications spatial resolution sensor fine enough resolve individual land cover types, monitoring urban growth studying vegetation dynamics.Sub-pixel information: LMMs allow estimation abundances land class within pixel, providing valuable sub-pixel information. can especially useful applications spatial resolution sensor fine enough resolve individual land cover types, monitoring urban growth studying vegetation dynamics.Enhanced change detection: considering sub-pixel composition land classes, LMMs can provide sensitive measure changes land cover time. can lead accurate precise change detection, particularly areas complex land cover patterns subtle changes land cover may occur.Enhanced change detection: considering sub-pixel composition land classes, LMMs can provide sensitive measure changes land cover time. can lead accurate precise change detection, particularly areas complex land cover patterns subtle changes land cover may occur.Biophysical parameter estimation: LMMs can used estimate biophysical parameters, vegetation fraction, leaf area index (LAI), soil moisture content, relating endmember abundances parameters. can provide valuable information monitoring managing natural resources, agriculture, ecosystems.Biophysical parameter estimation: LMMs can used estimate biophysical parameters, vegetation fraction, leaf area index (LAI), soil moisture content, relating endmember abundances parameters. can provide valuable information monitoring managing natural resources, agriculture, ecosystems.Applications spectral mixture analysis remote sensing include forest degradation [16], wetland surface dynamics [17], urban area characterization [18]. models providing valuable information wide range applications, land mapping change detection resource management environmental monitoring.","code":"\n# Define the endmembers for three classes and six bands\nem <- tibble::tribble(\n    ~class,   ~B02, ~B03, ~B04, ~B8A, ~B11, ~B12,\n    \"forest\",  200,  352,  189, 2800, 1340,  546,\n    \"soil\",    400,  650,  700, 3600, 3500, 1800,\n    \"water\",   700, 1100, 1400,  850,   40,   26)\n# Generate the mixture model\nreg_cube <- sits_mixture_model(\n    data = reg_cube,\n    endmembers = em,\n    multicores = 4,\n    memsize = 12,\n    output_dir = \"./tempdir/chp5\")\n# Plot the FOREST for the first date using the Greens palette\nplot(reg_cube, band = \"FOREST\", palette = \"Greens\")\n# Plot the water endmember for the first date using the Blues palette\nplot(reg_cube, band = \"WATER\", palette = \"Blues\")\n# Plot the SOIL endmember for the first date using the orange red (OrRd) palette \nplot(reg_cube, band = \"SOIL\", palette = \"OrRd\")"},{"path":"working-with-time-series.html","id":"working-with-time-series","chapter":"Working with time series","heading":"Working with time series","text":"","code":""},{"path":"working-with-time-series.html","id":"data-structures-for-satellite-time-series","chapter":"Working with time series","heading":"Data structures for satellite time series","text":"sits package uses sets time series data describing properties spatiotemporal locations interest. land classification, sets consist samples labeled experts. package can also used type classification, provided timeline bands time series used training match data cubes.following code shows first three lines time series tibble containing 1,882 labeled samples land classes Mato Grosso state Brazil. samples time series extracted MODIS MOD13Q1 product 2000 2016, provided every 16 days 250-meter resolution Sinusoidal projection. Based ground surveys high-resolution imagery, includes samples nine classes: “Forest”, “Cerrado”, “Pasture”, “Soy_Fallow”, “Fallow_Cotton”, “Soy_Cotton”, “Soy_Corn”, “Soy_Millet”, “Soy_Sunflower”.time series tibble contains data metadata. first six columns contain spatial temporal information, label assigned sample, data cube data extracted. first sample labeled “Pasture” location (\\(-58.5631\\), \\(-13.8844\\)), valid period (2006-09-14, 2007-08-29). Informing dates label valid crucial correct classification. case, researchers labeling samples used agricultural calendar Brazil. relevant dates applications countries likely differ used example. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band.","code":"\n# Samples\ndata(\"samples_matogrosso_mod13q1\")\nsamples_matogrosso_mod13q1[1:4,]#> # A tibble: 4 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 3     -59.4    -9.31 2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 4     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>"},{"path":"working-with-time-series.html","id":"utilities-for-handling-time-series","chapter":"Working with time series","heading":"Utilities for handling time series","text":"package provides functions data manipulation displaying information time series tibbles. example, summary() shows labels sample set frequencies.many cases, helpful relabel data set. example, may situations using smaller set labels desirable samples one label original set may distinguishable samples labels. use sits_labels()<- assign new labels. example shows relabeling time series set shown ; samples associated crops grouped single “Croplands” label.Since metadata embedded time series use tibble data format, functions dplyr, tidyr, purrr packages tidyverse [19] can used process data. example, following code uses sits_select() get subset sample data set two bands (NDVI EVI) uses dplyr::filter() select samples labeled “Cerrado”.","code":"\nsummary(samples_matogrosso_mod13q1)#> # A tibble: 9 × 3\n#>   label         count   prop\n#>   <chr>         <int>  <dbl>\n#> 1 Cerrado         379 0.200 \n#> 2 Fallow_Cotton    29 0.0153\n#> 3 Forest          131 0.0692\n#> 4 Pasture         344 0.182 \n#> 5 Soy_Corn        364 0.192 \n#> 6 Soy_Cotton      352 0.186 \n#> 7 Soy_Fallow       87 0.0460\n#> 8 Soy_Millet      180 0.0951\n#> 9 Soy_Sunflower    26 0.0137\n# Copy the sample set for Mato Grosso \nsamples_new_labels <- samples_matogrosso_mod13q1\n# Show the current labels\nsits_labels(samples_new_labels)#> [1] \"Cerrado\"       \"Fallow_Cotton\" \"Forest\"        \"Pasture\"       \"Soy_Corn\"     \n#> [6] \"Soy_Cotton\"    \"Soy_Fallow\"    \"Soy_Millet\"    \"Soy_Sunflower\"\n# Update the labels\nsits_labels(samples_new_labels) <- c(\"Cerrado\",   \"Croplands\", \n                                     \"Forest\",    \"Pasture\",\n                                     \"Croplands\", \"Croplands\",\n                                     \"Croplands\", \"Croplands\",\n                                     \"Croplands\")\nsummary(samples_new_labels)#> # A tibble: 4 × 3\n#>   label     count   prop\n#>   <chr>     <int>  <dbl>\n#> 1 Cerrado     379 0.200 \n#> 2 Croplands  1038 0.549 \n#> 3 Forest      131 0.0692\n#> 4 Pasture     344 0.182\n# Select NDVI band\nsamples_ndvi <- sits_select(samples_matogrosso_mod13q1, \n                            bands = \"NDVI\")\n# Select only samples with Cerrado label\nsamples_cerrado <- dplyr::filter(samples_ndvi, \n                                 label == \"Cerrado\")"},{"path":"working-with-time-series.html","id":"time-series-visualisation","chapter":"Working with time series","heading":"Time series visualisation","text":"Given samples display, plot() tries group many spatial locations together. following example, first 12 samples labelled “Cerrado” refer spatial location consecutive time periods. reason, samples plotted together.\nFigure 31: Plot first ‘Cerrado’ samples (Source: Authors).\nmany samples, default visualization combines samples together single temporal interval, even belong different years. plot shows spread values time series band. strong red line plot indicates median values, two orange lines first third interquartile ranges. See ?sits::plot details data visualization sits.\nFigure 32: Plot Cerrado samples (Source: Authors).\n","code":"\n# Plot the first 12 samples\nplot(samples_cerrado[1:12,])\n# Plot all cerrado samples together\nplot(samples_cerrado)"},{"path":"working-with-time-series.html","id":"obtaining-time-series-data-from-data-cubes","chapter":"Working with time series","heading":"Obtaining time series data from data cubes","text":"get set time series sits, first create regular data cube request one time series cube using sits_get_data(). function uses two mandatory parameters: cube samples. cube indicates data cube time series extracted. samples parameter accepts following data types:data.frame information latitude longitude (mandatory), start_date, end_date, label sample point.csv file columns latitude, longitude, start_date, end_date, label.shapefile containing either POINTor POLYGON geometries. See details .sf object (sf package) POINT POLYGON geometry information. See details .example , given data cube, user provides latitude longitude desired location. Since bands, start date, end date time series missing, sits obtains data cube. result tibble one time series can visualized using plot().\n\nFigure 33: NDVI EVI time series fetched local raster cube (Source: Authors).\nuseful case set labeled samples can used training data set. case, trusted observations usually labeled commonly stored plain text files comma-separated values (csv) using shapefiles (shp).retrieve training samples time series analysis, users must provide temporal information (start_date end_date). simplest case, samples share dates. strict requirement. possible specify different dates long compatible duration. example, data set samples_matogrosso_mod13q1 provided sitsdata package contains samples different years covering duration. samples MOD13Q1 product, contains number images per year. Thus, time series data set samples_matogrosso_mod13q1 number dates.Given suitably built csv sample file, sits_get_data() requires two parameters: () cube, name R object describes data cube; (b) samples, name CSV file.Users can also specify samples providing shapefiles sf objects containing POINT POLYGON geometries. geographical location inferred geometries associated shapefile sf object. files containing points, geographical location obtained directly. polygon geometries, parameter n_sam_pol (defaults 20) determines number samples extracted polygon. temporal information can provided explicitly user; absent, inferred data cube. label information available shapefile sf object, parameter label_attr compulsory indicate column contains label associated time series.","code":"\n# Obtain a raster cube based on local files\ndata_dir <- system.file(\"extdata/sinop\", package = \"sitsdata\")\nraster_cube <- sits_cube(\n    source     = \"BDC\",\n    collection = \"MOD13Q1-6\",\n    data_dir   = data_dir,\n    parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\"))\n# Obtain a time series from the raster cube from a point\nsample_latlong <- tibble::tibble(\n    longitude = -55.57320, \n    latitude  = -11.50566)\nseries <- sits_get_data(cube    = raster_cube,\n                        samples = sample_latlong)\nplot(series)\n# Retrieve a list of samples described by a csv file\nsamples_csv_file <- system.file(\"extdata/samples/samples_sinop_crop.csv\",\n                                package = \"sits\")\n# Read the csv file into an R object\nsamples_csv <- read.csv(samples_csv_file)\n# Print the first three samples\nsamples_csv[1:3,]#> # A tibble: 3 × 6\n#>      id longitude latitude start_date end_date   label  \n#>   <int>     <dbl>    <dbl> <chr>      <chr>      <chr>  \n#> 1     1     -55.7    -11.8 2013-09-14 2014-08-29 Pasture\n#> 2     2     -55.6    -11.8 2013-09-14 2014-08-29 Pasture\n#> 3     3     -55.7    -11.8 2013-09-14 2014-08-29 Forest\n# Get the points from a data cube in raster brick format\npoints <- sits_get_data(cube = raster_cube, \n                        samples = samples_csv_file)\n# Show the tibble with the first three points\npoints[1:3,]#> # A tibble: 3 × 7\n#>   longitude latitude start_date end_date   label    cube      time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>    <chr>     <list>           \n#> 1     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 <tibble [23 × 3]>\n#> 2     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6 <tibble [23 × 3]>\n#> 3     -55.7    -11.7 2013-09-14 2014-08-29 Soy_Corn MOD13Q1-6 <tibble [23 × 3]>\n# Obtain a set of points inside the state of Mato Grosso, Brazil\nshp_file <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\", \n                        package = \"sits\")\n# Read the shapefile into an \"sf\" object\nsf_shape <- sf::st_read(shp_file)#> Reading layer `mt' from data source \n#>   `/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/sits/extdata/shapefiles/mato_grosso/mt.shp' \n#>   using driver `ESRI Shapefile'\n#> Simple feature collection with 1 feature and 3 fields\n#> Geometry type: MULTIPOLYGON\n#> Dimension:     XY\n#> Bounding box:  xmin: -61.63284 ymin: -18.03993 xmax: -50.22481 ymax: -7.349034\n#> Geodetic CRS:  SIRGAS 2000\n# Create a data cube based on MOD13Q1 collection from BDC\nmodis_cube <- sits_cube(\n    source      = \"BDC\",\n    collection  = \"MOD13Q1-6\",\n    bands       = c(\"NDVI\", \"EVI\"),\n    roi         = sf_shape,\n    start_date  = \"2020-06-01\", \n    end_date    = \"2021-08-29\")\n\n# Read the points from the cube and produce a tibble with time series\nsamples_mt <- sits_get_data(\n    cube         = modis_cube, \n    samples      = shp_file, \n    start_date   = \"2020-06-01\",\n    end_date     = \"2021-08-29\", \n    n_sam_pol    = 20,\n    multicores   = 4)"},{"path":"working-with-time-series.html","id":"filtering-time-series","chapter":"Working with time series","heading":"Filtering time series","text":"Satellite image time series generally contaminated atmospheric influence, geolocation error, directional effects [20]. Atmospheric noise, sun angle, interferences observations different equipment specifications, nature climate-land dynamics can sources variability [21]. Inter-annual climate variability also changes phenological cycles vegetation, resulting time series whose periods intensities match year--year basis. make best use available satellite data archives, methods satellite image time series analysis need deal noisy non-homogeneous data sets.literature satellite image time series several applications filtering correct smooth vegetation index data. package supports well-known Savitzky–Golay (sits_sgolay()) Whittaker (sits_whittaker()) filters. evaluation NDVI time series filtering estimating phenological parameters India, Atkinson et al. found Whittaker filter provides good results [21]. Zhou et al. found Savitzky-Golay filter suitable reconstructing tropical evergreen broadleaf forests [22].","code":""},{"path":"working-with-time-series.html","id":"savitzkygolay-filter","chapter":"Working with time series","heading":"Savitzky–Golay filter","text":"Savitzky-Golay filter fits successive array \\(2n+1\\) adjacent data points \\(d\\)-degree polynomial linear least squares. main parameters filter polynomial degree (\\(d\\)) length window data points (\\(n\\)). generally produces smoother results larger value \\(n\\) /smaller value \\(d\\) [23]. optimal value two parameters can vary case case. sits, parameter order sets order polynomial (default = 3), parameter length sets size temporal window (default = 5), parameter scaling sets temporal expansion (default = 1). following example shows effect Savitsky-Golay filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01.\nFigure 34: Savitzky-Golay filter applied multi-year NDVI time series (Source: Authors).\nresulting smoothed curve desirable unwanted properties. 2000 2008, Savitsky-Golay filter removes noise clouds. However, 2010, region converted agriculture, filter removes important part natural variability crop cycle. Therefore, length parameter arguably big, resulting oversmoothing.","code":"\n# Take NDVI band of the first sample data set\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# Apply Savitzky Golay filter\npoint_sg <- sits_sgolay(point_ndvi, length = 11)\n# Merge the point and plot the series\nsits_merge(point_sg, point_ndvi) %>% plot()"},{"path":"working-with-time-series.html","id":"whittaker-filter","chapter":"Working with time series","heading":"Whittaker filter","text":"Whittaker smoother attempts fit curve representing raw data, penalized subsequent points vary much [24]. Whittaker filter balances residual original data smoothness fitted curve. filter one parameter: \\(\\lambda{}\\) works smoothing weight parameter. following example shows effect Whittaker filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01. lambda parameter controls smoothing filter. default, set 0.5, small value. example shows effect larger smoothing parameter.\nFigure 35: Whittaker filter applied one-year NDVI time series (Source: Authors).\nSimilar observed Savitsky-Golay filter, high values smoothing parameter lambda produce -smoothed time series reduces capacity time series represent natural variations crop growth. reason, low smoothing values recommended using sits_whittaker().","code":"\n# Take NDVI band of the first sample data set\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# Apply Whitakker filter\npoint_whit <- sits_whittaker(point_ndvi, lambda = 8)\n# Merge the point and plot the series\nsits_merge(point_whit, point_ndvi) %>% plot()"},{"path":"improving-the-quality-of-training-samples.html","id":"improving-the-quality-of-training-samples","chapter":"Improving the quality of training samples","heading":"Improving the quality of training samples","text":"Selecting good training samples machine learning classification satellite images critical achieving accurate results. Experience machine learning methods demonstrated number quality training samples crucial factors obtaining accurate results [25]. Large accurate datasets preferable, regardless algorithm used, noisy training samples can negatively impact classification performance [26]. Thus, beneficial use pre-processing methods improve quality samples eliminate may incorrectly labeled possess low discriminatory power.necessary distinguish wrongly labelled samples differences resulting natural variability class signatures. training data belongs large geographic region, variability vegetation phenology leads different patterns assigned label. related issue limitation crisp boundaries describe natural world. Class definitions use idealized descriptions (e.g., “savanna woodland tree cover 50% 90% ranging 8 15 meters height”). practice, boundaries classes fuzzy sometimes overlap, making hard distinguish . improve sample quality, sits provides methods evaluating training data.","code":""},{"path":"improving-the-quality-of-training-samples.html","id":"geographical-variability-of-training-samples","chapter":"Improving the quality of training samples","heading":"Geographical variability of training samples","text":"working machine learning classification Earth observation data, important evaluate training samples well distributed study area. Training data often comes ground surveys made chosen locations. large areas, ideally representative samples need capture spatial variability. practice, however, ground surveys means data collection limited selected areas. many cases, geographical distribution training data cover study area equally. mismatch can problem achieving good quality classification. stated Meyer Pebesma [27]: “large gaps geographic space always imply large gaps feature space”.Meyer Pebesma [27] propose using spatial distance distribution plot, displays two distributions nearest-neighbor distances: sample--sample prediction-location--sample. difference two distributions reflects degree spatial clustering reference data. Ideally, two distributions similar. Cases sample--sample distance distribution match prediction-location--sample distribution indicate possible problems training data collection.sits implements spatial distance distribution plots sits_geo_dist() function. function gets training data samples parameter, study area roi parameter expressed sf object. Additional parameters n (maximum number samples distribution) crs (coordinate reference system samples). default, n 1000, crs “EPSG:4326”. example shows use sits_geo_dist().\nFigure 36: Distribution sample--sample sample--prediction distances (Source: Authors).\nplot shows mismatch sample--sample sample--prediction distributions. samples closer close location values need predicted. case, many areas samples collected prediction uncertainty higher. similar cases, improving distribution training samples always welcome. possible, areas insufficient samples lower accuracy. information must reported potential users classification results.","code":"\n# Read a shapefile for the state of Mato Grosso, Brazil\nmt_shp <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n                      package = \"sits\")\n# Convert to an sf object\nmt_sf <- sf::read_sf(mt_shp)\n\n# Calculate sample-to-sample and sample-to-prediction distances\ndistances <- sits_geo_dist(\n    samples = samples_modis_ndvi,\n    roi = mt_sf)\n# Plot sample-to-sample and sample-to-prediction distances\nplot(distances)"},{"path":"improving-the-quality-of-training-samples.html","id":"hierarchical-clustering-for-sample-quality-control","chapter":"Improving the quality of training samples","heading":"Hierarchical clustering for sample quality control","text":"package provides two clustering methods assess sample quality: Agglomerative Hierarchical Clustering (AHC) Self-organizing Maps (SOM). methods different computational complexities. AHC computational complexity \\(\\mathcal{O}(n^2)\\), given number time series \\(n\\), whereas SOM complexity linear. large data, AHC requires substantial memory running time; cases, SOM recommended. section describes run AHC sits. SOM-based technique presented next section.AHC computes dissimilarity two elements data set. Depending distance functions linkage criteria, algorithm decides two clusters merged iteration. approach helpful exploring samples due visualization power ease use [28]. sits, AHC implemented using sits_cluster_dendro().\nFigure 37: Example hierarchical clustering two class set time series (Source: Authors).\nsits_cluster_dendro() function one mandatory parameter (samples), samples evaluated. Optional parameters include bands, dist_method, linkage. dist_method parameter specifies calculate distance two time series. recommend metric uses dynamic time warping (DTW) [29], DTW reliable method measuring differences satellite image time series [30]. options available sits based provided package dtwclust, include dtw_basic, dtw_lb, dtw2. Please check ?dtwclust::tsclust information DTW distances.linkage parameter defines distance metric clusters. recommended linkage criteria : complete ward.D2. Complete linkage prioritizes within-cluster dissimilarities, producing clusters shorter distance samples, results sensitive outliers. alternative, Ward proposes use sum--squares error minimize data variance [31]; method available ward.D2 option linkage parameter. cut dendrogram, sits_cluster_dendro() function computes adjusted rand index (ARI) [32] returns height cut dendrogram maximizes index. example, ARI index indicates six clusters. result sits_cluster_dendro() time series tibble one additional column called “cluster”. function sits_cluster_frequency() provides information composition cluster.cluster frequency table shows cluster predominance either “Cerrado” “Pasture” labels, except cluster 3, mix samples labels. confusion may resulted incorrect labelling, inadequacy selected bands spatial resolution, even natural confusion due variability land classes. remove cluster 3, use dplyr::filter(). resulting clusters still contain mixed labels, possibly resulting outliers. case, sits_cluster_clean() removes outliers, leaving frequent label. cleaning samples, resulting set samples likely improve classification results.","code":"\n# Take a set of patterns for 2 classes\n# Create a dendrogram, plot, and get the optimal cluster based on ARI index\nclusters <- sits_cluster_dendro(\n    samples = cerrado_2classes, \n    bands = c(\"NDVI\", \"EVI\"),\n    dist_method = \"dtw_basic\",\n    linkage =  \"ward.D2\")\n# Show clusters samples frequency\nsits_cluster_frequency(clusters)#>          \n#>             1   2   3   4   5   6 Total\n#>   Cerrado 203  13  23  80   1  80   400\n#>   Pasture   2 176  28   0 140   0   346\n#>   Total   205 189  51  80 141  80   746\n# Remove cluster 3 from the samples\nclusters_new <- dplyr::filter(clusters, cluster != 3)\n# Clear clusters, leaving only the majority label\nclean <- sits_cluster_clean(clusters_new)\n# Show clusters samples frequency\nsits_cluster_frequency(clean)#>          \n#>             1   2   4   5   6 Total\n#>   Cerrado 203   0  80   0  80   363\n#>   Pasture   0 176   0 140   0   316\n#>   Total   203 176  80 140  80   679"},{"path":"improving-the-quality-of-training-samples.html","id":"using-som-for-sample-quality-control","chapter":"Improving the quality of training samples","heading":"Using SOM for sample quality control","text":"sits provides clustering technique based self-organizing maps (SOM) alternative hierarchical clustering quality control training samples. SOM dimensionality reduction technique [33], high-dimensional data mapped two-dimensional map, keeping topological relations data patterns. shown Figure 38, SOM 2D map composed units called neurons. neuron weight vector, dimension training samples. start, neurons assigned small random value trained competitive learning. algorithm computes distances member training set neurons finds neuron closest input, called best matching unit.\nFigure 38: SOM 2D map creation (Source: Santos et al. (2021). Reproduction fair use doctrine).\ninput data quality assessment set training samples, high-dimensional data; example, time series 25 instances 4 spectral bands 100 dimensions. projecting high-dimensional data set 2D SOM map, units map (called neurons) compete sample. time series mapped one neurons. Since number neurons smaller number classes, neuron associated many time series. resulting 2D map set clusters. Given SOM preserves topological structure neighborhoods multiple dimensions, clusters contain training samples given label usually neighbours 2D space. neighbors neuron SOM map provide information intraclass interclass variability, used detect noisy samples. methodology using SOM sample quality assessment discussed detail reference paper [34].\nFigure 39: Using SOM class noise reduction (Source: Santos et al. (2021). Reproduction fair use doctrine).\nexample, take set time series Cerrado region Brazil, second largest biome South America area 2 million km2. data ranges 2000 2017 includes 50,160 samples divided 12 classes (“Dense_Woodland”, “Dunes”, “Fallow_Cotton”, “Millet_Cotton”, “Pasture”, “Rocky_Savanna”, “Savanna”, “Savanna_Parkland”, “Silviculture”, “Soy_Corn”, “Soy_Cotton”, “Soy_Fallow”). time series covers 12 months (23 data points) MOD13Q1 product, 4 bands (EVI, NDVI, MIR, NIR). use bands NDVI EVI faster processing.","code":"\n# Take only the NDVI and EVI bands\nsamples_cerrado_mod13q1_2bands <- sits_select(\n    data = samples_cerrado_mod13q1, \n    bands = c(\"NDVI\", \"EVI\"))\n\n# Show the summary of the samples\nsummary(samples_cerrado_mod13q1_2bands)#> # A tibble: 12 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    9966 0.199  \n#>  2 Dunes              550 0.0110 \n#>  3 Fallow_Cotton      630 0.0126 \n#>  4 Millet_Cotton      316 0.00630\n#>  5 Pasture           7206 0.144  \n#>  6 Rocky_Savanna     8005 0.160  \n#>  7 Savanna           9172 0.183  \n#>  8 Savanna_Parkland  2699 0.0538 \n#>  9 Silviculture       423 0.00843\n#> 10 Soy_Corn          4971 0.0991 \n#> 11 Soy_Cotton        4124 0.0822 \n#> 12 Soy_Fallow        2098 0.0418"},{"path":"improving-the-quality-of-training-samples.html","id":"creating-the-som-map","chapter":"Improving the quality of training samples","heading":"Creating the SOM map","text":"perform SOM-based quality assessment, first step run sits_som_map(), uses kohonen R package [35] compute SOM grid, controlled five parameters. grid size given grid_xdim grid_ydim. starting learning rate alpha, decreases interactions. measure separation samples, use distance (either “sumofsquares” “euclidean”). number iterations set rlen. details, please consult ?kohonen::supersom.\nFigure 40: SOM map Cerrado samples (Source: Authors).\noutput sits_som_map() list three elements: () data, original set time series two additional columns time series: id_sample (original id sample) id_neuron (id neuron belongs); (b) labelled_neurons, tibble information neurons. neuron, gives prior posterior probabilities labels occur samples assigned ; (c) SOM grid. plot SOM grid, use plot(). neurons labelled using majority voting.SOM grid shows classes associated neurons close , although exceptions. “Pasture” neurons far main cluster transition open savanna pasture areas always well defined depends climate latitude. Also, neurons associated “Soy_Fallow” dispersed map, indicating possible problems distinguishing class agricultural classes. SOM map can used remove outliers, shown .","code":"\n# Clustering time series using SOM\nsom_cluster <- sits_som_map(samples_cerrado_mod13q1_2bands,\n    grid_xdim = 15,\n    grid_ydim = 15,\n    alpha = 1.0,\n    distance = \"euclidean\",\n    rlen = 20)\n# Plot the SOM map\nplot(som_cluster)"},{"path":"improving-the-quality-of-training-samples.html","id":"measuring-confusion-between-labels-using-som","chapter":"Improving the quality of training samples","heading":"Measuring confusion between labels using SOM","text":"second step SOM-based quality assessment understanding confusion labels. function sits_som_evaluate_cluster() groups neurons majority label produces tibble. Neurons grouped clusters, many clusters labels. results shows percentage samples label cluster. Ideally, samples cluster label. practice, cluster contain samples different label. information helps measuring confusion samples.Many labels associated clusters samples different label. confusion labels arises sample labeling subjective can biased. many cases, interpreters use high-resolution data identify samples. However, actual images classified captured satellites lower resolution. case study, MOD13Q1 image pixels \\(250 \\times 250\\) meter resolution. , correspondence labelled locations high-resolution images mid low-resolution images direct. confusion sample label can visualized bar plot using plot(), shown . bar plot shows confusion labels associated natural vegetation typical Brazilian Cerrado (“Savanna”, “Savanna_Parkland”, “Rocky_Savanna”). mixture due large variability natural vegetation Cerrado biome, makes difficult draw sharp boundaries classes. confusion also visible agricultural classes. “Millet_Cotton” class particularly difficult one since many samples assigned class confused “Soy_Cotton” “Fallow_Cotton”.\nFigure 41: Confusion classes measured SOM (Source: Authors).\n","code":"\n# Produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster)\n# Show the result\nsom_eval #> # A tibble: 77 × 4\n#>    id_cluster cluster        class          mixture_percentage\n#>         <int> <chr>          <chr>                       <dbl>\n#>  1          1 Dense_Woodland Dense_Woodland           80.7    \n#>  2          1 Dense_Woodland Fallow_Cotton             0.00887\n#>  3          1 Dense_Woodland Pasture                   5.48   \n#>  4          1 Dense_Woodland Rocky_Savanna             6.34   \n#>  5          1 Dense_Woodland Savanna                   4.18   \n#>  6          1 Dense_Woodland Silviculture              3.19   \n#>  7          1 Dense_Woodland Soy_Corn                  0.0177 \n#>  8          1 Dense_Woodland Soy_Cotton                0.0444 \n#>  9          1 Dense_Woodland Soy_Fallow                0.00887\n#> 10          2 Dunes          Dunes                   100      \n#> # ℹ 67 more rows\n# Plot the confusion between clusters\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"detecting-noisy-samples-using-som","chapter":"Improving the quality of training samples","heading":"Detecting noisy samples using SOM","text":"third step quality assessment uses discrete probability distribution associated neuron, included labeled_neurons tibble produced sits_som_map(). approch associates probabilities frequency occurrence. homogeneous neurons (one label high frequency) assumed composed good quality samples. Heterogeneous neurons (two classes significant frequencies) likely contain noisy samples. algorithm computes two values sample:prior probability: probability label assigned sample correct, considering frequency samples neuron. example, neuron 20 samples, 15 labeled “Pasture” 5 “Forest”, samples labelled “Forest” assigned prior probability 25%. indicates “Forest” samples neuron may good quality.prior probability: probability label assigned sample correct, considering frequency samples neuron. example, neuron 20 samples, 15 labeled “Pasture” 5 “Forest”, samples labelled “Forest” assigned prior probability 25%. indicates “Forest” samples neuron may good quality.posterior probability: probability label assigned sample correct, considering neighbouring neurons. Take case -mentioned neuron whose samples labeled “Pasture” prior probability 75%. happens neighbouring neurons “Forest” majority label? answer question, use Bayesian inference estimate samples noisy based surrounding neurons [36].posterior probability: probability label assigned sample correct, considering neighbouring neurons. Take case -mentioned neuron whose samples labeled “Pasture” prior probability 75%. happens neighbouring neurons “Forest” majority label? answer question, use Bayesian inference estimate samples noisy based surrounding neurons [36].identify noisy samples, take result sits_som_map() function first argument function sits_som_clean_samples(). function finds samples noisy, clean, need examined user. requires prior_threshold posterior_threshold parameters according following rules:prior probability sample less prior_threshold, sample assumed noisy tagged “remove”;prior probability greater equal prior_threshold posterior probability calculated Bayesian inference greater equal posterior_threshold, sample assumed noisy thus tagged “clean”;prior probability greater equal prior_threshold posterior probability less posterior_threshold, situation sample part majority level assigned neuron, label consistent neighbors. anomalous condition tagged “analyze”. Users encouraged inspect samples find whether fact noisy .default value prior_threshold posterior_threshold 60%. sits_som_clean_samples() additional parameter (keep), indicates samples kept set based prior posterior probabilities. default keep c(\"clean\", \"analyze\"). result cleaning, 900 samples considered noisy thus removed.samples class highest confusion others(“Millet_Cotton”) removed. samples class “Silviculture” (planted forests) also removed since confused natural forests woodlands SOM map. analysis includes calculating SOM map confusion matrix new set, shown following example.\nFigure 42: Cluster confusion plot samples cleaned SOM (Source: Authors).\nexpected, new confusion map shows significant improvement previous one. result interpreted carefully since may due different effects. direct interpretation “Millet_Cotton” “Silviculture” easily separated classes, given current attributes (time series NDVI EVI indices MODIS images). situations, users consider improving number samples less represented classes, including MODIS bands, working higher resolution satellites. results SOM method interpreted based users’ understanding ecosystems agricultural practices study region.comparison original clean samples run 5-fold validation original cleaned sample sets using sits_kfold_validate() random forest model. SOM procedure improves validation results 95% original data set 99% cleaned one. improvement interpreted providing better fit final map accuracy. 5-fold validation procedure measures well machine learning model fits samples; accuracy assessment classification results. result indicates training set SOM sample removal procedure internally consistent original one. details accuracy measures, please see Chapter Validation accuracy measures.SOM-based analysis discards samples can confused samples classes. removing noisy samples uncertain classes, data set obtains better validation score since less confusion classes. Users analyse results care. discarded samples low-quality ones. Confusion samples different classes can result inconsistent labelling lack capacity satellite data distinguish chosen classes. many samples discarded, current example, revising whole classification schema advisable. aim selecting training data always match reality ground power remote sensing data identify differences. analysis procedure can replace actual user experience knowledge study region.","code":"\nnew_samples <- sits_som_clean_samples(\n    som_map = som_cluster, \n    prior_threshold = 0.6,\n    posterior_threshold = 0.6,\n    keep = c(\"clean\", \"analyze\"))\n# Print the new sample distribution\nsummary(new_samples)#> # A tibble: 11 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    7973 0.200  \n#>  2 Dunes              550 0.0138 \n#>  3 Fallow_Cotton      320 0.00801\n#>  4 Millet_Cotton      166 0.00416\n#>  5 Pasture           5402 0.135  \n#>  6 Rocky_Savanna     6461 0.162  \n#>  7 Savanna           7349 0.184  \n#>  8 Savanna_Parkland  2153 0.0539 \n#>  9 Soy_Corn          4401 0.110  \n#> 10 Soy_Cotton        3723 0.0932 \n#> 11 Soy_Fallow        1433 0.0359\n# Evaluate the mixture in the SOM clusters of new samples\nnew_cluster <- sits_som_map(\n   data = new_samples,\n   grid_xdim = 15,\n   grid_ydim = 15,\n   alpha = 1.0,\n   distance = \"euclidean\")\nnew_cluster_mixture <- sits_som_evaluate_cluster(new_cluster)\n# Plot the mixture information.\nplot(new_cluster_mixture)\n# Run a k-fold validation\nassess_orig <- sits_kfold_validate(\n    samples = samples_cerrado_mod13q1_2bands, \n    folds = 5,\n    ml_method = sits_rfor())\n# Print summary \nsummary(assess_orig)#> Overall Statistics                            \n#>  Accuracy : 0.9451          \n#>    95% CI : (0.9431, 0.9471)\n#>     Kappa : 0.936\nassess_new <- sits_kfold_validate(\n    samples = new_samples,\n    folds = 5,\n    ml_method = sits_rfor())\n# Print summary \nsummary(assess_new)#> Overall Statistics                            \n#>  Accuracy : 0.9901          \n#>    95% CI : (0.9891, 0.9911)\n#>     Kappa : 0.9884"},{"path":"improving-the-quality-of-training-samples.html","id":"reducing-sample-imbalance","chapter":"Improving the quality of training samples","heading":"Reducing sample imbalance","text":"Many training samples Earth observation data analysis imbalanced. situation arises distribution samples associated label uneven. One example Cerrado data set used Chapter. three frequent labels (“Dense Woodland”, “Savanna” “Pasture”) include 53% samples, three least frequent labels (“Millet-Cotton”, “Silviculture”, “Dunes”) comprise 2.5% data set. Sample imbalance undesirable property training set since machine learning algorithms tend accurate classes many samples. instances belonging minority group misclassified often belonging majority group. Thus, reducing sample imbalance can positively affect classification accuracy [37].function sits_reduce_imbalance() deals training set imbalance; increases number samples least frequent labels, reduces number samples frequent labels. Oversampling requires generating synthetic samples. package uses SMOTE method estimates new samples considering cluster formed nearest neighbours minority label. SMOTE takes two samples cluster produces new one randomly interpolating [38].perform undersampling, sits_reduce_imbalance() builds SOM map majority label based required number samples selected. dimension SOM set ceiling(sqrt(new_number_samples/4)) allow reasonable number neurons group similar samples. calculating SOM map, algorithm extracts four samples per neuron generate reduced set samples approximates variation original one.sits_reduce_imbalance() algorithm two parameters: n_samples_over n_samples_under. first parameter indicates minimum number samples per class. classes samples less value oversampled. second parameter controls maximum number samples per class; classes samples value undersampled. following example uses sits_reduce_imbalance() Cerrado samples. generate balanced data set classes minumim 1000 maximum 1500 samples. use sits_som_evaluate_cluster() estimate confusion classes balanced data set.\nFigure 43: Confusion cluster balanced data set (Source: Authors).\nshown Figure 43, balanced data set shows less confusion per label unbalanced one. case, many classes confused others original confusion map now better represented. Reducing sample imbalance tried alternative reducing number samples classes using SOM. general, users balance training data better performance.","code":"\n# Reducing imbalances in the Cerrado data set\nbalanced_samples <- sits_reduce_imbalance(\n    samples = samples_cerrado_mod13q1_2bands,\n    n_samples_over = 1000,\n    n_samples_under = 1500,\n    multicores = 4)\n# Print the balanced samples\n# Some classes have more than 1500 samples due to the SOM map\n# Each label has between 10% and 6% of the full set\nsummary(balanced_samples)#> # A tibble: 12 × 3\n#>    label            count   prop\n#>    <chr>            <int>  <dbl>\n#>  1 Dense_Woodland    1600 0.0969\n#>  2 Dunes             1000 0.0605\n#>  3 Fallow_Cotton     1000 0.0605\n#>  4 Millet_Cotton     1000 0.0605\n#>  5 Pasture           1600 0.0969\n#>  6 Rocky_Savanna     1496 0.0906\n#>  7 Savanna           1596 0.0966\n#>  8 Savanna_Parkland  1584 0.0959\n#>  9 Silviculture      1000 0.0605\n#> 10 Soy_Corn          1588 0.0961\n#> 11 Soy_Cotton        1560 0.0944\n#> 12 Soy_Fallow        1496 0.0906\n# Clustering time series using SOM\nsom_cluster_bal <- sits_som_map(\n    data = balanced_samples,\n    grid_xdim = 10,\n    grid_ydim = 10,\n    alpha = 1.0,\n    distance = \"euclidean\",\n    rlen = 20)\n# Produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster_bal)\n# Show the result\nplot(som_eval) "},{"path":"improving-the-quality-of-training-samples.html","id":"conclusion","chapter":"Improving the quality of training samples","heading":"Conclusion","text":"quality training data critical improving accuracy maps resulting machine learning classification methods. address challenge, sits package provides three methods improving training samples. large datasets, recommend using imbalance-reducing SOM-based algorithms. SOM-based method identifies potential mislabeled samples outliers require investigation. results demonstrate positive impact overall classification accuracy.complexity diversity planet defy simple label names hard boundaries. Due representational data handling issues, classification systems limited number categories, inevitably fail adequately describe nuances planet’s landscapes. representation systems thus limited application-dependent. stated Janowicz [39]: “geographical concepts situated context-dependent can described different, equally valid, points view; thus, ontological commitments arbitrary large extent”.availability big data satellite image time series challenge. principle, image time series can capture subtle changes land classification. Experts must conceive classification systems training data collections understanding time series information relates actual land change. Methods quality analysis, presented Chapter, replace user understanding informed choices.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-for-data-cubes","chapter":"Machine learning for data cubes","heading":"Machine learning for data cubes","text":"","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-classification","chapter":"Machine learning for data cubes","heading":"Machine learning classification","text":"Machine learning classification kind supervised learning algorithm trained predict class input data point belongs .involves teaching computer program recognize patterns data use patterns predict class new data. Classification aims build model can accurately assign class new data based patterns learned previously labelled data. sits, machine learning used classify individual time series using time-first approach.goal machine learning models approximate function \\(y = f(x)\\) maps input \\(x\\) class \\(y\\). model defines mapping \\(y = f(x;\\theta)\\) learns value parameters \\(\\theta\\) result best function approximation [40]. difference different algorithms approach building mapping classifies input data.sits package includes two kinds methods time series classification:Machine learning algorithms explicitly consider temporal structure time series. treat time series vector high-dimensional feature space, taking time series instance independent others. include random forest (sits_rfor()), support vector machine (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptron (sits_mlp()).Machine learning algorithms explicitly consider temporal structure time series. treat time series vector high-dimensional feature space, taking time series instance independent others. include random forest (sits_rfor()), support vector machine (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptron (sits_mlp()).Deep learning methods designed work time series. Temporal relations observed values time series taken account. kind models, sits supports 1D convolution neural networks (sits_tempcnn()), residual 1D networks (sits_resnet()), temporal attention-based encoders (sits_tae() sits_lighttae()). algorithms, temporal ordering samples relevant classifier.Deep learning methods designed work time series. Temporal relations observed values time series taken account. kind models, sits supports 1D convolution neural networks (sits_tempcnn()), residual 1D networks (sits_resnet()), temporal attention-based encoders (sits_tae() sits_lighttae()). algorithms, temporal ordering samples relevant classifier.Based experience sits, random forest, extreme gradient boosting, temporal deep learning models outperform SVM multilayer perceptron models. specific dates provide information others temporal behavior land classes. instance, monitoring deforestation, dates corresponding forest removal actions informative earlier later dates. Similarly, dates may capture large portion variation crop mapping. Therefore, classification methods consider temporal order samples likely capture seasonal behavior image time series. Random forest extreme gradient boosting methods use individual measures nodes decision trees can also capture specific events deforestation.following examples show train machine learning methods apply classify single time series. use set samples_matogrosso_mod13q1, containing time series samples Brazilian Mato Grosso state obtained MODIS MOD13Q1 product. 1,892 samples nine classes (Cerrado, Fallow_Cotton, Forest, Pasture, Soy_Corn, Soy_Cotton, Soy_Fallow, Soy_Millet, Soy_Sunflower). time series covers 12 months (23 data points) six bands (NDVI, EVI, BLUE, RED, NIR, MIR). samples arranged along agricultural year, starting September ending August. data set used paper “Big Earth observation time series analysis monitoring Brazilian agriculture” [41], available R package sitsdata. Please see Chapter Setup instructions obtain package.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"visualizing-sample-patterns","chapter":"Machine learning for data cubes","heading":"Visualizing sample patterns","text":"One helpful way describing understanding samples plotting . direct way using plot function, discussed Chapter Working time series. useful alternative estimate statistical approximation idealized pattern based generalized additive model (GAM). GAM linear model linear predictor depends linearly smooth function predictor variables.\\[\ny = \\beta_{} + f(x) + \\epsilon, \\epsilon \\sim N(0, \\sigma^2).\n\\]function sits_patterns() uses GAM predict smooth, idealized approximation time series associated class bands. function uses R package dtwSat[42], implements TWDTW time series matching method described [30]. resulting patterns can viewed using plot().\nFigure 44: Patterns samples Mato Grosso (Source: Authors).\nresulting patterns provide insights time series behaviour class. response Forest class quite distinctive. also show possible separate single double cropping classes. similarities double-cropping classes (Soy_Corn, Soy_Millet, Soy_Sunflower, Soy_Sunflower) Cerrado Pasture classes. subtle differences class signatures provide hints possible ways machine learning algorithms might distinguish classes. One example difference middle-infrared response dry season (May September) differentiate Cerrado Pasture.","code":"\n# Estimate the patterns for each class and plot them\nsamples_matogrosso_mod13q1 %>% \n    sits_patterns() %>% \n    plot()"},{"path":"machine-learning-for-data-cubes.html","id":"common-interface-to-machine-learning-and-deep-learning-models","chapter":"Machine learning for data cubes","heading":"Common interface to machine learning and deep learning models","text":"sits_train() function provides standard interface machine learning models. function takes two mandatory parameters: training data (samples) ML algorithm (ml_method). model estimated, can classify individual time series data cubes sits_classify(). follows, show apply method classify single time series. , Chapter Image classification data cubes, discuss classify data cubes.Since sits aimed remote sensing users machine learning experts, provides set default values classification models. settings chosen based testing authors. Nevertheless, users can control parameters model. Novice users can rely default values, experienced ones can fine-tune model parameters meet needs. Model tuning discussed end Chapter.set time series organized tibble taken input classifier, result tibble one additional column (“predicted”), contains information labels assigned interval. results can shown text format using function sits_show_prediction() graphically using plot().","code":""},{"path":"machine-learning-for-data-cubes.html","id":"random-forest","chapter":"Machine learning for data cubes","heading":"Random forest","text":"Random forest machine learning algorithm uses ensemble learning method classification tasks. algorithm consists multiple decision trees, trained different subset training data different subset features. make prediction, decision tree forest independently classifies input data. final prediction made based majority vote decision trees. randomness algorithm comes random subsets data features used train decision tree, helps reduce overfitting improve accuracy model. classifier measures importance feature classification task, can helpful feature selection data visualization. Pelletier et al. discuss robustness random forest method satellite image time series classification [43].\nFigure 45: Random forest algorithm (Source: Venkata Jagannath Wikipedia - licenced CC--SA 4.0).\nsits provides sits_rfor(), uses R randomForest package [44]; main parameter num_trees, number trees grow default value 100. model can visualized using plot().\nFigure 46: important variables random forest model (Source: Authors).\nimportant explanatory variables NIR (near infrared) band date 17 (2007-05-25) MIR (middle infrared) band date 22 (2007-08-13). NIR value end May captures growth second crop double cropping classes. Values MIR band end period (late July late August) capture bare soil signatures distinguish agricultural natural classes. corresponds summertime ground drier harvesting crops.\nFigure 47: Classification time series using random forest (Source: Authors).\nresult shows area started forest 2000, deforested 2004 2005, used pasture 2006 2007, double-cropping agriculture 2009 onwards. behavior consistent expert evaluation land change process region Amazonia.Random forest robust outliers can deal irrelevant inputs [45]. method tends overemphasize variables performance tends stabilize part trees grown [45]. cases abrupt change occurs, deforestation mapping, random forest (properly trained) emphasize temporal instances bands capture quick change.","code":"\n# Train the Mato Grosso samples with random forest model\nrfor_model <- sits_train(\n    samples = samples_matogrosso_mod13q1, \n    ml_method = sits_rfor(num_trees = 100))\n# Plot the most important variables of the model\nplot(rfor_model)\n# Classify using random forest model and plot the result\npoint_class <- sits_classify(\n    data = point_mt_mod13q1, \n    ml_model  = rfor_model)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"support-vector-machine","chapter":"Machine learning for data cubes","heading":"Support vector machine","text":"support vector machine (SVM) classifier generalization linear classifier finds optimal separation hyperplane minimizes misclassification [46]. Since set samples \\(n\\) features defines n-dimensional feature space, hyperplanes linear \\({(n-1)}\\)-dimensional boundaries define linear partitions space. classes linearly separable feature space, optimal solution defined maximal margin hyperplane, separating hyperplane farthest training observations [47]. maximal margin computed smallest distance observations hyperplane. solution hyperplane coefficients depends samples define maximum margin criteria, -called support vectors.\nFigure 48: Maximum-margin hyperplane margins SVM trained samples two classes. Samples margin called support vectors. (Source: Larhmam Wikipedia - licensed CC--SA-4.0).\ndata linearly separable, SVM includes kernel functions map original feature space higher dimensional space, providing nonlinear boundaries original feature space. Despite linear boundary enlarged feature space, new classification model generally translates hyperplane nonlinear boundary original attribute space. Kernels efficient computational strategy produce nonlinear boundaries input attribute space; thus, improve training-class separation. SVM one widely used algorithms machine learning applications applied classify remote sensing data [48].sits, SVM implemented wrapper e1071 R package uses LIBSVM implementation [49]. sits package adopts one--one method multiclass classification. \\(q\\) class problem, method creates \\({q(q-1)/2}\\) SVM binary models, one class pair combination, testing unknown input vectors throughout models. voting scheme computes overall result.example shows apply SVM classify time series using default values. main parameters kernel, controls whether use nonlinear transformation (default radial), cost, measures punishment wrongly-classified samples (default 10), cross, sets value k-fold cross validation (default 10).\nFigure 49: Classification time series using SVM (Source: Authors).\nSVM classifier less stable less robust outliers random forest method. example, tends misclassify data. 2008, likely correct land class still “Pasture” rather “Soy_Millet” produced algorithm, “Soy_Cotton” class 2012 also inconsistent previous latter classification “Soy_Corn”.","code":"\n# Train an SVM model\nsvm_model <- sits_train(\n    samples = samples_matogrosso_mod13q1, \n    ml_method = sits_svm())\n# Classify using the SVM model and plot the result\npoint_class <- sits_classify(\n    data = point_mt_mod13q1, \n    ml_model = svm_model)\n# Plot the result\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"extreme-gradient-boosting","chapter":"Machine learning for data cubes","heading":"Extreme gradient boosting","text":"boosting method starts weak predictor improves performance sequentially fitting better model iteration. fits simple classifier training data uses residuals fit build predictor. Typically, base classifier regression tree. Although random forest boosting use trees classification, significant differences. performance random forest generally increases number trees becomes stable. Boosting trees apply finer divisions previous results improve performance [45]. However, result generalizable since quality training data set controls actual performance.Gradient boosting variant boosting methods minimize cost function gradient descent. Extreme gradient boosting [50], called XGBoost, efficiently approximates gradient loss function. recent papers show outperforms random forest remote sensing image classification[51]. However, result generalizable since actual performance controlled quality training data set.sits, XGBoost method implemented sits_xbgoost() function, based XGBoost R package, five hyperparameters require tuning. sits_xbgoost() function takes user choices input cross-validation determine suitable values predictor.learning rate eta varies 0.0 1.0 kept small (default 0.3) avoid overfitting. minimum loss value gamma specifies minimum reduction required make split. default 0; increasing makes algorithm conservative. max_depth value controls maximum depth trees. Increasing value make model complex likely overfit (default 6). subsample parameter controls percentage samples supplied tree. default 1 (maximum). Setting lower values means xgboost randomly collects part data instances grow trees, thus preventing overfitting. nrounds parameter controls maximum number boosting interactions; default 100, proven enough cases. follow convergence algorithm, users can turn verbose parameter . general, results using extreme gradient boosting algorithm similar random forest method.\nFigure 50: Classification time series using XGBoost (Source: Authors).\n","code":"\n# Train using  XGBoost\nxgb_model <- sits_train(\n    samples = samples_matogrosso_mod13q1, \n    ml_method = sits_xgboost(verbose = 0))\n# Classify using SVM model and plot the result\npoint_class <- sits_classify(\n    data = point_mt_mod13q1, \n    ml_model = xgb_model)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"deep-learning-using-multilayer-perceptron","chapter":"Machine learning for data cubes","heading":"Deep learning using multilayer perceptron","text":"support deep learning methods, sits uses torch R package, takes Facebook torch C++ library back-end. Machine learning algorithms use R torch package similar developed using PyTorch. simplest deep learning method multilayer perceptron (MLP), feedforward artificial neural networks. MLP consists three kinds nodes: input layer, set hidden layers, output layer. input layer dimension number features data set. hidden layers attempt approximate best classification function. output layer decides class assigned input.sits, MLP models can built using sits_mlp(). Since established model generic classification satellite image time series, designing MLP models requires parameter customization. important decisions number layers model number neurons per layer. values set layers parameter, list integer values. size list number layers, element indicates number nodes per layer.choice number layers depends inherent separability data set classified. data sets classes different signatures, shallow model (three layers) may provide appropriate responses. complex situations require models deeper hierarchy. Models many hidden layers may take long time train may converge. suggest start three layers test different options number neurons per layer increasing number layers. experience, using three five layers reasonable compromise training data good quality. increase number layers improve model.MLP models also need include activation function. activation function node defines output node given input set inputs. Following standard practices [40], use relu activation function.optimization method (optimizer) represents gradient descent algorithm used. methods aim maximize objective function updating parameters opposite direction gradient objective function [52]. Based experience image time series, recommend start using default method provided sits, optimizer_adamw, package torchopt. Please refer torchopt package additional information.Another relevant parameter list dropout rates (dropout). Dropout technique randomly dropping units neural network training [53]. randomly discarding neurons, dropout reduces overfitting. Since cascade neural nets aims improve learning data acquired, discarding neurons may seem like waste resources. practice, dropout prevents early convergence local minimum [40]. suggest users experiment different dropout rates, starting small values (10-30%) increasing required.following example shows use sits_mlp(). default parameters chosen based modified version [54], proposes using multilayer perceptron baseline time series classification. parameters : () Three layers 512 neurons , specified parameter layers; (b) Using “relu” activation function; (c) dropout rates 40%, 30%, 20% layers; (d) “optimizer_adamw” optimizer (default value); (e) number training steps (epochs) 100; (f) batch_size 64, indicates many time series used input given step; (g) validation percentage 20%, means 20% samples randomly set aside validation.simplify output, verbose option turned . model generated, plot training history.\nFigure 51: Evolution training accuracy MLP model (Source: Authors).\n, classify 16-year time series using multilayer perceptron model.\nFigure 52: Classification time series using MLP (Source: Authors).\ntheory, multilayer perceptron model can capture subtle changes random forest XGBoost specific case, result similar . Although model mixes “Soy_Corn” “Soy_Millet” classes, distinction temporal signatures quite subtle. Also, case, suggests need improve number samples. example, MLP model shows increase sensitivity compared previous models. recommend compare different configurations since MLP model sensitive changes parameters.","code":"\n# Train using an MLP model\n# This is an example of how to set parameters\n# First-time users should test default options first\nmlp_model <- sits_train(\n    samples = samples_matogrosso_mod13q1, \n    ml_method = sits_mlp(\n        layers           = c(512, 512, 512),\n        dropout_rates    = c(0.40, 0.30, 0.20),\n        epochs           = 100,\n        batch_size       = 64,\n        verbose          = FALSE,\n        validation_split = 0.2))\n# Show training evolution\nplot(mlp_model)\n# Classify using MLP model and plot the result\npoint_mt_mod13q1 %>% \n    sits_classify(mlp_model) %>% \n    plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"temporal-convolutional-neural-network-tempcnn","chapter":"Machine learning for data cubes","heading":"Temporal Convolutional Neural Network (TempCNN)","text":"Convolutional neural networks (CNN) deep learning methods apply convolution filters (sliding windows) input data sequentially. Temporal Convolutional Neural Network (TempCNN) neural network architecture specifically designed process sequential data time series. case time series, 1D CNN applies moving temporal window time series produce another time series result convolution.TempCNN applies one-dimensional convolutions input sequence capture temporal dependencies, allowing network learn long-term dependencies input sequence. layer model captures temporal dependencies different scale. Due multi-scale approach, TempCNN can capture complex temporal patterns data produce accurate predictions.TempCNN architecture satellite image time series classification proposed Pelletier et al. [55]. three 1D convolutional layers final softmax layer classification (see Figure 53). authors combine different methods avoid overfitting reduce vanishing gradient effect, including dropout, regularization, batch normalization. TempCNN reference paper [55], authors favourably compare model Recurrent Neural Network proposed Russwurm Körner [56]. Figure 53 shows architecture TempCNN model.\nFigure 53: Structure tempCNN architecture (Source: Pelletier et al. (2019). Reproduction fair use doctrine).\nfunction sits_tempcnn() implements model. parameter cnn_layers controls number 1D-CNN layers size filters applied layer; default values three CNNs 128 units. parameter cnn_kernels indicates size convolution kernels; default kernels size 7. Activation 1D-CNN layers uses “relu” function. dropout rates 1D-CNN layer controlled individually parameter cnn_dropout_rates. validation_split controls size test set relative full data set. recommend setting aside least 20% samples validation.\nFigure 54: Training evolution TempCNN model (Source: Authors).\n, classify 16-year time series using TempCNN model.\nFigure 55: Classification time series using TempCNN (Source: Authors).\nresult important differences previous ones. TempCNN model indicates “Soy_Cotton” class likely one 2004. result possibly wrong, shows time series 2004 different “Forest” “Pasture” classes. One possible explanation forest degradation 2004, leading signature mix forest bare soil. case, including forest degradation samples improve training data. experience, TempCNN models reliable way classifying image time series [57]. Recent work compares different models also provides evidence TempCNN models satisfactory behavior, especially case crop classes [58].","code":"\nlibrary(torchopt)\n# Train using tempCNN\ntempcnn_model <- sits_train(samples_matogrosso_mod13q1, \n                       sits_tempcnn(\n                          optimizer            = torchopt::optim_adamw,\n                          cnn_layers           = c(128, 128, 128),\n                          cnn_kernels          = c(7, 7, 7),\n                          cnn_dropout_rates    = c(0.2, 0.2, 0.2),\n                          epochs               = 100,\n                          batch_size           = 64,\n                          validation_split     = 0.2,\n                          verbose              = FALSE))\n# Show training evolution\nplot(tempcnn_model)\n# Classify using TempCNN model and plot the result\nclass <- point_mt_mod13q1 %>% \n    sits_classify(tempcnn_model) %>% \n    plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"residual-1d-cnn-networks-resnet","chapter":"Machine learning for data cubes","heading":"Residual 1D CNN networks (ResNet)","text":"residual 1D CNN network, also known ResNet, extension standard 1D CNN architecture, adding residual connections layers. Residual connections allow network learn residual mappings, difference input output layer. adding residual connections, network can learn bypass specific layers still capture essential features data.Residual Network (ResNet) time series classification proposed Wang et al. [54], based idea deep residual networks 2D image recognition [59]. ResNet architecture comprises 11 layers, three blocks three 1D CNN layers (see Figure 56). block corresponds 1D CNN architecture. output block combined shortcut links output input, called skip connection. purpose combining input layer block output layer (convolutions) avoid -called “vanishing gradient problem”. issue occurs deep networks neural network’s weights updated based partial derivative error function. gradient small, weights updated, stopping training [60]. Skip connections aim avoid vanishing gradients occurring, allowing deep networks trained.\nFigure 56: Structure ResNet architecture (Source: Wang et al. (2017). Reproduction fair use doctrine).\nsits, Residual Network implemented using sits_resnet(). default parameters proposed Wang et al. [54], implemented Fawaz et al. [61]. first parameter blocks, controls number blocks size filters block. default, model implements three blocks, first 64 filters others 128. parameter kernels controls size kernels three layers inside block. useful experiment bit kernel sizes case satellite image time series. default activation “relu”, recommended literature reduce problem vanishing gradients. default optimizer optim_adamw, available package torchopt.\nFigure 57: Training evolution ResNet model (Source: Authors).\n, classify 16-year time series using ResNet model. behavior ResNet model similar TempCNN, variability.\nFigure 58: Classification time series using ResNet (Source: Authors).\n","code":"\n# Train using ResNet\nresnet_model <- sits_train(samples_matogrosso_mod13q1, \n                       sits_resnet(\n                          blocks               = c(64, 128, 128),\n                          kernels              = c(7, 5, 3),\n                          epochs               = 100,\n                          batch_size           = 64,\n                          validation_split     = 0.2,\n                          verbose              = FALSE))\n# Show training evolution\nplot(resnet_model)\n# Classify using DL model and plot the result\nclass <- point_mt_mod13q1 %>% \n    sits_classify(tempcnn_model) %>% \n    plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"attention-based-models","chapter":"Machine learning for data cubes","heading":"Attention-based models","text":"Attention-based deep learning models class models use mechanism inspired human attention focus specific parts input processing. models shown effective various tasks machine translation, image captioning, speech recognition.basic idea behind attention-based models allow model selectively focus different input parts different times. can done introducing mechanism assigns weights element input, indicating relative importance element current processing step. model can use compute weighted sum input. results capture model’s attention specific parts input.Attention-based models become one used deep learning architectures problems involve sequential data inputs, e.g., text recognition automatic translation. general idea inputs alike applications language translation. Consider English sentence “Look lonely people”. sound translation system needs relate words “look” “people” key parts sentence ensure link captured translation. specific type attention models, called transformers, enables recognition complex relationships input output sequences [62].basic structure transformers neural network algorithms. encoder transforms textual input values numerical vectors decoder processes vectors provide suitable answers. difference values handled internally. MLP, inputs treated equally first; based iterative matching training test data, backpropagation technique feeds information back initial layers identify suitable combination inputs produces best output.Convolutional nets (CNN) combine input values close time (1D) space (2D) produce higher-level information helps distinguish different components input data. text recognition, initial choice deep learning studies use recurrent neural networks (RNN) handle input sequences.However, neither MLPs, CNNs, RNNs able capture structure complex inputs natural language. success transformer-based solutions accounts substantial improvements natural language processing.two main differences transformer models algorithms positional encoding self-attention. Positional encoding assigns index input value, ensuring relative locations inputs maintained throughout learning processing phases. Self-attention compares every word sentence every word sentence, including . way, learns contextual information relation words. conception validated large language models BERT [63] GPT-3 [64].application attention-based models satellite image time series analysis proposed Garnot et al. [65] Russwurm Körner [58]. self-attention network can learn focus specific time steps image features relevant distinguishing different classes. algorithm tries identify combination individual temporal observations relevant identify class. example, crop identification use observations capture onset growing season, date maximum growth, end growing season. case deforestation, algorithm tries identify dates forest cut. Attention-based models means identify events characterize land class.first model proposed Garnot et al. full transformer-based model [65]. Considering image time series classification easier natural language processing, Garnot et al. also propose simplified version full transformer model [66]. simpler model uses reduced way compute attention matrix, reducing time training classification without loss quality result.sits, full transformer-based model proposed Garnot et al. [65] implemented using sits_tae(). default parameters proposed authors. default optimizer optim_adamw, available package torchopt.\nFigure 59: Training evolution Temporal Self-Attention model (Source: Authors).\n, classify 16-year time series using TAE model.\nFigure 60: Classification time series using TAE (Source: Authors).\nGarnot co-authors [65] also proposed Lightweight Temporal Self-Attention Encoder (LTAE), authors claim can achieve high classification accuracy fewer parameters compared neural network models. good choice applications computational resources limited. sits_lighttae() function implements algorithm. default optimizer optim_adamw, available package torchopt. important parameter set learning rate lr. Values ranging 0.001 0.005 produce good results. See also section model tuning.\nFigure 61: Training evolution Lightweight Temporal Self-Attention model (Source: Authors).\n, classify 16-year time series using LightTAE model.\nFigure 62: Classification time series using LightTAE (Source: Authors).\nbehaviour sits_tae() sits_lighttae() similar sits_tempcnn(). points possible need classes training data better represent transition period 2004 2010. One possibility training data associated Pasture class consistent time series years 2005 2008. However, transition Forest Pasture 2004 Pasture Agriculture 2009-2010 subject uncertainty since classifiers agree resulting classes. general, deep learning temporal-aware models sensitive class variability random forest extreme gradient boosters.","code":"\n# Train a machine learning model using TAE\ntae_model <- sits_train(samples_matogrosso_mod13q1, \n                       sits_tae(\n                          epochs               = 150,\n                          batch_size           = 64,\n                          optimizer            = torchopt::optim_adamw,\n                          validation_split     = 0.2,\n                          verbose              = FALSE))\n# Show training evolution\nplot(tae_model)\n# Classify using DL model and plot the result\nclass <- point_mt_mod13q1 %>% \n    sits_classify(tae_model) %>% \n    plot(bands = c(\"NDVI\", \"EVI\"))\n# Train a machine learning model using TAE\nltae_model <- sits_train(samples_matogrosso_mod13q1, \n                       sits_lighttae(\n                          epochs               = 150,\n                          batch_size           = 64,\n                          optimizer            = torchopt::optim_adamw,\n                          opt_hparams = list(lr = 0.001),\n                          validation_split     = 0.2))\n# Show training evolution\nplot(ltae_model)\n# Classify using DL model and plot the result\nclass <- point_mt_mod13q1 %>% \n    sits_classify(ltae_model) %>% \n    plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"model-tuning","chapter":"Machine learning for data cubes","heading":"Model tuning","text":"Deep learning model tuning process selecting best set hyperparameters specific application. Model tuning enables better fit algorithm training data. Hyperparameters parameters model learned training instead set prior training affect behavior model training. Examples include learning rate, batch size, number epochs, number hidden layers, number neurons layer, activation functions, regularization parameters, optimization algorithms.Deep learning model tuning involves selecting best combination hyperparameters results optimal performance model given task. done training evaluating model different sets hyperparameters select set gives best performance.Deep learning algorithms try find optimal point representing best value prediction function , given input \\(X\\) data points, predicts result \\(Y\\). case, \\(X\\) multidimensional time series, \\(Y\\) vector probabilities possible output classes. complex situations, best prediction function time-consuming estimate. reason, deep learning methods rely gradient descent methods speed predictions converge faster exhaustive search [67]. gradient descent methods use optimization algorithm adjusted hyperparameters learning regularization rates [68]. learning rate controls numerical step gradient descent function, regularization rate controls model overfitting. Adjusting values optimal setting requires using model tuning methods.reduce learning curve, sits provides default values machine learning deep learning methods, ensuring reasonable baseline performance. However, refininig model hyperparameters might necessary, especially complex models sits_lighttae() sits_tempcnn(). end, package provides sits_tuning() function.straightforward approach model tuning run grid search; involves defining range hyperparameter testing possible combinations. approach leads combinational explosion thus recommended. Instead, Bergstra Bengio [69] propose use randomly chosen trials. paper, authors show randomized trials efficient grid search trials, selecting adequate hyperparameters fraction computational cost. sits_tuning() function follows Bergstra Bengio [69] uses random search chosen hyperparameters.Since gradient descent plays key role deep learning model fitting, developing optimizers important topic research [70]. Many optimizers proposed literature, recent results reviewed Schmidt et al. [68]. Adam optimizer [71] provides good baseline reliable performance general deep learning applications. reason, Adam default optimizer R torch package. Experiments image time series show optimizers may better performance specific problem land classification. reason, authors developed torchopt R package, includes several recently proposed optimizers, including Adamw [72], Madgrad [73], Yogi [74]. Based experiments, selected Adamw default optimizer deep learning methods. Using sits_tuning() function allows testing optimizers available torch torch_opt packages.sits_tuning() function takes following parameters:samples: Training data set used model.samples_validation: Optional data set containing time series used validation. missing, next parameter used.validation_split: samples_validation used, parameter defines proportion time series training data set used validation (default 20%).ml_method(): Deep learning method (either sits_mlp(), sits_tempcnn(), sits_resnet(), sits_tae() sits_lighttae()).params: Defines optimizer hyperparameters calling sits_tuning_hparams(), shown example .trials: Number trials run random search.multicores: Number cores used procedure.progress: Show progress bar?sits_tuning_hparams() function inside sits_tuning() allows defining optimizers hyperparameters, including lr (learning rate), eps (controls numerical stability), weight_decay (controls overfitting). default values eps weight_decay sits deep learning functions 1e-08 1e-06, respectively. default lr sits_lighttae() sits_tempcnn() 0.005, sits_tae() sits_resnet() 0.001. Users different ways randomize hyperparameters, including: choice() (list options), uniform (uniform distribution), randint (random integers uniform distribution), normal(mean, sd) (normal distribution), beta(shape1, shape2) (beta distribution). options allow extensive combination hyperparameters.example, sits_tuning() finds good hyperparameters train sits_lighttae() Mato Grosso data set. tests 100 combinations learning rate weight decay Adamw optimizer. randomize learning rate, uses beta distribution parameters 0.35 10, allows variation 0.2 1; weight decay, beta distribution parameters 0.1 2 generates values roughly 1 1e-24.result tibble different values accuracy, kappa, decision matrix, hyperparameters. 10 best results obtain accuracy values 0.976 0.958, shown . best result obtained learning rate 0.0011 weight decay 2.14e-05.large data sets, tuning process time-consuming. Despite cost, recommended achieve best performance. general, tuning hyperparameters models sits_tempcnn() sits_lighttae() result slight performance improvement default parameters overall accuracy. performance gain stronger less well represented classes, significant gains producer’s user’s accuracies possible. detecting change less frequent classes, tuning can make substantial difference results.","code":"\ntuned <- sits_tuning(\n     samples = samples_matogrosso_mod13q1,\n     ml_method = sits_lighttae(),\n     params = sits_tuning_hparams(\n         optimizer = torchopt::optim_adamw,\n         opt_hparams = list(\n             lr = beta(0.35, 10),\n             weight_decay = beta(0.1, 2))),\n     trials = 100,\n     multicores = 6,\n     progress = FALSE)\n# Obtain accuracy, kappa, lr, and weight decay for the 10 best results\n# Hyperparameters are organized as a list\nhparams_10 <- tuned[1:10,]$opt_hparams\n# Extract learning rate and weight decay from the list\nlr_10 <- purrr::map_dbl(hparams_10, function(h) h$lr)\nwd_10 <- purrr::map_dbl(hparams_10, function(h) h$weight_decay)\n\n# Create a tibble to display the results\nbest_10 <- tibble::tibble(\n    accuracy = tuned[1:10,]$accuracy,\n    kappa = tuned[1:10,]$kappa,\n    lr    = lr_10,\n    weight_decay = wd_10)\n# Print the best combination of hyperparameters\nbest_10#> # A tibble: 10 × 4\n#>    accuracy kappa       lr weight_decay\n#>       <dbl> <dbl>    <dbl>        <dbl>\n#>  1    0.976 0.972 0.00117      2.14e- 5\n#>  2    0.971 0.965 0.00125      2.07e- 4\n#>  3    0.968 0.962 0.000281     2.70e- 2\n#>  4    0.966 0.959 0.000418     1.54e- 2\n#>  5    0.963 0.956 0.000432     1.76e- 6\n#>  6    0.960 0.953 0.000263     2.35e- 4\n#>  7    0.960 0.953 0.000254     3.13e- 3\n#>  8    0.958 0.950 0.000973     1.35e- 2\n#>  9    0.958 0.949 0.000694     8.95e-15\n#> 10    0.958 0.950 0.000428     1.09e- 1"},{"path":"machine-learning-for-data-cubes.html","id":"considerations-on-model-choice","chapter":"Machine learning for data cubes","heading":"Considerations on model choice","text":"results taken indication method performs better. crucial factor achieving good result quality training data [25]. Experience shows classification quality depends training samples well model matches samples. examples ML classifying large areas, please see papers authors [4], [41], [75], [76].specific case satellite image time series, Russwurm et al. [58] present comparative study seven deep neural networks classification agricultural crops, using random forest baseline. data composed Sentinel-2 images Britanny, France. results indicate slight difference best model (attention-based transformer model) TempCNN, ResNet, random forest. Attention-based models obtain accuracy ranging 80-81%, TempCNN gets 78-80%, random forest obtains 78%. Based result also authors’ experience, make following recommendations:Random forest provide good baseline image time series classification included users’ assessments.Random forest provide good baseline image time series classification included users’ assessments.XGBoost worthy alternative random forest. principle, XGBoost sensitive data variations cost possible overfitting.XGBoost worthy alternative random forest. principle, XGBoost sensitive data variations cost possible overfitting.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.Attention-based models (TAE LightTAE) can achieve best overall performance well-designed balanced training sets hyperparameter tuning.Attention-based models (TAE LightTAE) can achieve best overall performance well-designed balanced training sets hyperparameter tuning.best means improving classification performance provide accurate reliable training data set. class enough samples account spatial temporal variability.best means improving classification performance provide accurate reliable training data set. class enough samples account spatial temporal variability.","code":""},{"path":"image-classification-in-data-cubes.html","id":"image-classification-in-data-cubes","chapter":"Image classification in data cubes","heading":"Image classification in data cubes","text":"Chapter discusses classify data cubes providing step--step example. study area state Rondonia, Brazil, underwent substantial deforestation last decades. objective case study detect deforested areas.","code":""},{"path":"image-classification-in-data-cubes.html","id":"training-the-classification-model","chapter":"Image classification in data cubes","heading":"Training the classification model","text":"case study uses training data set samples_prodes_4bands, available package sitsdata. data set consists 480 samples collected Sentinel-2 images covering state Rondonia. samples intended detect deforestation events include four classes: “Forest”, “Burned_Area”, “Cleared_Area”, “Highly_Degraded”. time series cover set 29 dates period 16 days, ranging 2020-06-04 2021-08-26. data 12 attributes, including original bands (B02, B03, B04, B05, B08, B8A, B11, B12) indices (NDVI, EVI, NBR).helpful plot basic patterns associated samples understand training set better. function sits_patterns() uses generalized additive model (GAM) predict smooth, idealized approximation time series associated class bands. Since data cube used classification three bands (B02, B8A, B11), filter samples bands showing patterns.\nFigure 63: Patterns associated training samples (Source: Authors).\npatterns show different temporal responses selected classes. match typical behavior deforestation Amazon. First, forest cut start dry season (June/July). end dry season, clear-cut areas burned clean remains; action reflected steep fall response B8A values burned area samples July. cleared burned areas, response middle infra-red band B11 increases significantly end dry season, B8A values remain high. sign mixed pixels, combine forest remains bare soil. Forest areas show constant spectral response year. Degraded areas show increase values middle infra-red band B11 compared native forests, showing mixed response vegetation soil.","code":"\nlibrary(sitsdata)\n# Obtain the samples \ndata(\"samples_prodes_4classes\")\n# Show the contents of the samples\nsummary(samples_prodes_4classes)#> # A tibble: 4 × 3\n#>   label           count  prop\n#>   <chr>           <int> <dbl>\n#> 1 Burned_Area        96 0.244\n#> 2 Cleared_Area      115 0.293\n#> 3 Forest            107 0.272\n#> 4 Highly_Degraded    75 0.191\nsamples_3bands <- sits_select(\n    data = samples_prodes_4classes,\n    bands = c(\"B02\", \"B8A\", \"B11\"))\n\nplot(sits_patterns(samples_3bands))"},{"path":"image-classification-in-data-cubes.html","id":"building-a-data-cube","chapter":"Image classification in data cubes","heading":"Building a data cube","text":"now build data cube Sentinel-2 images available package sitsdata. images SENTINEL-2-L2A collection Microsoft Planetary Computer (MPC). chosen bands BO2, B8A, B11 images small area \\(1000 \\times 1000\\) pixels state Rondonia. explained Chapter Earth observation data cubes, must inform sits parse file names obtain tile, date, band information. Image files named according convention “cube_tile_band_date” (e.g., cube_20LKP_BO2_2020_06_04.tif).\nFigure 64: Color composite image cube date 2021-07-25 (Source: Authors).\n","code":"\n# Files are available in a local directory \ndata_dir <- system.file(\"extdata/Rondonia-20LKP/\", package = \"sitsdata\")\n# Read data cube\nro_cube_20LKP <- sits_cube(\n    source = \"MPC\",\n    collection = \"SENTINEL-2-L2A\",\n    data_dir = data_dir,\n    parse_info = c('X1', \"tile\", \"band\", \"date\"))\n\n# Plot the cube\nplot(ro_cube_20LKP, dates = \"2021-07-25\", red = \"B11\", green = \"B8A\", blue = \"B02\")"},{"path":"image-classification-in-data-cubes.html","id":"training-a-deep-learning-model","chapter":"Image classification in data cubes","heading":"Training a deep learning model","text":"next step train Lightweight Temporal Attention Encoder (LightTAE) model, using adamw optimizer learning rate 0.001. Since data cube classified bands BO2, B8A, B11, select bands training data.\nFigure 65: Training evolution LightTAE model (Source: Authors).\n","code":"\n# Use only the bands available in the cube\nsamples_3bands <- sits_select(\n    data = samples_prodes_4classes, \n    bands = sits_bands(ro_cube_20LKP))\n\n# Train model using LightTAE algorithm\nltae_model <- sits_train(\n    samples = samples_3bands, \n    ml_method = sits_lighttae(opt_hparams = list(lr = 0.001)))\n\n# Plot the evolution of the model\nplot(ltae_model)"},{"path":"image-classification-in-data-cubes.html","id":"classification-using-parallel-processing","chapter":"Image classification in data cubes","heading":"Classification using parallel processing","text":"classify data cubes sets time series, use sits_classify(), uses parallel processing speed performance, described end Chapter. relevant parameters : () data, either data cube set time series; (b) ml_model, trained model using one machine learning methods provided; (c) multicores, number CPU cores used processing; (d) memsize, memory available classification; (e) output_dir, directory results stored; (f) version, version control. follow processing steps, turn parameters verbose print information progress get progress bar. classification result data cube set probability layers, one output class. probability layer contains model’s assessment likely pixel belongs related class. probability cube can visualized plot().\nFigure 66: Probability maps produced LightTAE model (Source: Authors).\nprobability cube helpful tool data analysis. used post-processing smoothing, described Chapter, also uncertainty estimates active learning, described Chapter Uncertainty active learning.\nFigure 67: Final classification map (Source: Authors).\nlabeled map generated pixel-based time series classification method exhibits several misclassified pixels, small patches surrounded different class. occurrence outliers common issue arises due inherent nature classification approach. Regardless resolution, mixed pixels prevalent images, class exhibits considerable data variability. result, factors can lead outliers likely misclassified. overcome limitation, sits employs post-processing smoothing techniques leverage spatial context probability cubes refine results. techniques discussed next Chapter.","code":"\n# Classify data cube\nro_cube_20LKP_probs <- sits_classify(\n    data     = ro_cube_20LKP,\n    ml_model = ltae_model,\n    output_dir = \"./tempdir/chp9\",\n    version = \"ltae\",\n    multicores = 4,\n    memsize = 12)\n\nplot(ro_cube_20LKP_probs, palette = \"YlGn\")\n# Generate a thematic map\ndefor_map <- sits_label_classification(\n    cube = ro_cube_20LKP_probs,\n    multicores = 4,\n    memsize = 12,\n    output_dir = \"./tempdir/chp9\",\n    version = \"no_smooth\")\n\nplot(defor_map)"},{"path":"image-classification-in-data-cubes.html","id":"map-reclassification","chapter":"Image classification in data cubes","heading":"Map reclassification","text":"Reclassification remote sensing map refers changing classes assigned different pixels image. purpose reclassification modify information contained image better suit specific use case. sits, reclassification involves assigning new classes pixels based additional information reference map. Users define rules according desired outcome. rules applied classified map. result new map updated classes.illustrate reclassification sits, take classified data cube stored sitsdata package. discussed Chapter Earth observation data cubes, sits can create data cube classified image file. Users need provide original data source collection, directory data stored (data_dir), information retrieve data cube parameters file names (parse_info), labels used classification.\nFigure 68: Original classification map (Source: Authors).\nmap shows total extent deforestation clear cuts estimated sits random forest algorithm area Rondonia, Brazil, based time series Sentinel-2 images period 2020-06-04 2021-08-26. Suppose want estimate deforestation occurred June 2020 August 2021. need reference map containing information forest cuts 2020.example, use reference PRODES deforestation map Amazonia created Brazil’s National Institute Space Research (INPE). map produced visual interpretation. PRODES measures deforestation every year, starting August one year July following year. contains classes represent natural world (“Forest”, “Water”, “NonForest”, “NonForest2”) classes capture yearly deforestation increments. classes named “dYYYY” “rYYYY”; first refers deforestation given year (e.g., “d2008” deforestation August 2007 July 2008); second places satellite data sufficient determine land class (e.g, “r2010” 2010). map available package sitsdata, shown .Since labels deforestation map specialized part default sits color table, define legend better visualization different deforestation classes. Using new legend, can plot PRODES deforestation map.\nFigure 69: Deforestation map produced PRODES (Source: Authors).\nTaking PRODES map reference, can include new labels classified map produced sits using sits_reclassify(). new name “Defor_2020” applied pixels PRODES considers deforested July 2020. also include “Non_Forest” class include pixels PRODES takes covered native vegetation, wetlands rocky areas. PRODES classes used mask sits deforestation map.sits_reclassify() operation requires parameters: () cube, classified data cube whose pixels reclassified; (b) mask, reference data cube used mask; (c) rules, named list. names rules list new label. new label associated mask vector includes labels reference map joined. sits_reclassify() compares original reference map pixel pixel. pixel reference map whose labels one rules, algorithm relabels original map. result reclassified map original labels plus new labels masked using reference map.\nFigure 70: Deforestation map sits masked PRODES map (Source: Authors).\nreclassified map split deforestation mid-2020 (using PRODES map) areas classified sits taken deforested mid-2020 mid-2021. allows experts measure much deforestation occurred period according sits compare result PRODES map.sits_reclassify() function restricted comparing deforestation maps. can used case requires masking result based reference map.","code":"\n# Open classification map\ndata_dir <- system.file(\"extdata/Rondonia-Class\", package = \"sitsdata\")\nro_class <- sits_cube(\n    source = \"MPC\",\n    collection = \"SENTINEL-2-L2A\",\n    data_dir = data_dir,\n    parse_info = c(\"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\",\n                   \"band\", \"version\"),\n    bands = \"class\",\n    labels = c(\"Water\", \"ClearCut_Burn\", \"ClearCut_Soil\",\n               \"ClearCut_Veg\", \"Forest\", \"Bare_Soil\", \"Wetland\"))\n\nplot(ro_class)\ndata_dir <- system.file(\"extdata/PRODES\", package = \"sitsdata\")\nprodes2021 <- sits_cube(\n    source = \"USGS\",\n    collection = \"LANDSAT-C2L2-SR\",\n    data_dir = data_dir,\n    parse_info = c(\"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\",\n                   \"band\", \"version\"),\n    bands = \"class\",\n    version = \"v20220606\",\n    labels = c(\"Forest\", \"Water\", \"NonForest\",\n               \"NonForest2\", \"NoClass\", \"d2007\", \"d2008\",\n               \"d2009\", \"d2010\", \"d2011\", \"d2012\",\n               \"d2013\", \"d2014\", \"d2015\", \"d2016\",\n               \"d2017\", \"d2018\", \"r2010\", \"r2011\",\n               \"r2012\", \"r2013\", \"r2014\", \"r2015\",\n               \"r2016\", \"r2017\", \"r2018\", \"d2019\",\n               \"r2019\", \"d2020\", \"NoClass\", \"r2020\",\n               \"Clouds2021\", \"d2021\", \"r2021\"))\n# Use the RColorBrewer palette \"YlOrBr\" for the deforestation years\ncolors <- grDevices::hcl.colors(n = 15, palette = \"YlOrBr\")\n# Define the legend for the deforestation map\ndef_legend <- c(\n    \"Forest\" = \"forestgreen\", \"Water\" = \"dodgerblue3\", \n    \"NonForest\" = \"bisque2\", \"NonForest2\" = \"bisque2\",\n    \"d2007\" = colors[1],  \"d2008\" = colors[2],\n    \"d2009\" = colors[3],  \"d2010\" = colors[4], \n    \"d2011\" = colors[5],  \"d2012\" = colors[6],\n    \"d2013\" = colors[7],  \"d2014\" = colors[8],\n    \"d2015\" = colors[9],  \"d2016\" = colors[10],\n    \"d2017\" = colors[11], \"d2018\" = colors[12],\n    \"d2019\" = colors[13], \"d2020\" = colors[14], \n    \"d2021\" = colors[15], \"r2010\" = \"azure2\",\n    \"r2011\" = \"azure2\",   \"r2012\" = \"azure2\",\n    \"r2013\" = \"azure2\",   \"r2014\" = \"azure2\",\n    \"r2015\" = \"azure2\",   \"r2016\" = \"azure2\",\n    \"r2017\" = \"azure2\",   \"r2018\" = \"azure2\",\n    \"r2019\" = \"azure2\",   \"r2020\" = \"azure2\",\n    \"r2021\" = \"azure2\",   \"NoClass\" = \"grey90\",\n    \"Clouds2021\" = \"grey90\")\n\nplot(prodes2021, legend = def_legend)\n# Reclassify cube\nro_def_2021 <- sits_reclassify(\n    cube = ro_class,\n    mask = prodes2021,\n    rules = list(\n        \"Non_Forest\" = mask %in% c(\"NonForest\", \"NonForest2\"),\n        \"Deforestation_Mask\" = mask %in% c(\n            \"d2007\", \"d2008\", \"d2009\",\n            \"d2010\", \"d2011\", \"d2012\",\n            \"d2013\", \"d2014\", \"d2015\",\n            \"d2016\", \"d2017\", \"d2018\",\n            \"d2019\", \"d2020\",\n            \"r2010\", \"r2011\", \"r2012\",\n            \"r2013\", \"r2014\", \"r2015\",\n            \"r2016\", \"r2017\", \"r2018\",\n            \"r2019\", \"r2020\", \"r2021\"),\n        \"Water\" = mask == \"Water\"),\n    memsize = 8,\n    multicores = 2,\n    output_dir = \"./tempdir/chp9\",\n    version = \"reclass\")\n\n# Plot the reclassified map\nplot(ro_def_2021)#> Warning: palette colors names missing for 8, 9. Therefore, palette color names will\n#> be ignored"},{"path":"image-classification-in-data-cubes.html","id":"how-parallel-processing-works","chapter":"Image classification in data cubes","heading":"How parallel processing works","text":"section provides overview sits_classify(), sits_smooth(), sits_label_classification() process images parallel. achieve efficiency, sits implements fault-tolerant multitasking procedure big Earth observation data classification. learning curve shortened need learn multiprocessing. Image classification sits done cluster independent workers linked virtual machine. avoid communication overhead, large payloads read stored independently; direct interaction main process workers kept minimum.classification procedure benefits fact images available cloud collections stored COGs (cloud-optimized GeoTIFF). COGs regular GeoTIFF files organized regular square blocks improve visualization access large data sets. Thus, data requests can optimized access portions images. cloud services supported sits use COG files. classification algorithm sits uses COGs ensure optimal data access, reducing /O demand much possible.approach parallel processing sits, depicted Figure 71, following steps:Based block size individual COG files, calculate size chunk must loaded memory, considering number bands timeline’s length. Chunk access optimized efficient transfer data blocks.Divide total memory available chunk size determine many processes can run parallel.core processes chunk produces subset result.Repeat process chunks cube processed.Check subimages produced correctly. problem one subimages, run failure recovery procedure ensure data processed.generating subimages, join obtain result.\nFigure 71: Parallel processing sits (Source: Simoes et al. (2021). Reproduction fair use doctrine).\napproach many advantages. dependencies proprietary software runs virtual machine supports R. Processing done concurrent independent way, communication workers. Failure one worker cause failure big data processing. software prepared resume classification processing last processed chunk, preventing failures memory exhaustion, power supply interruption, network breakdown.reduce processing time, necessary adjust sits_classify(), sits_smooth(), sits_label_classification() according capabilities host environment. memsize parameter controls size main memory (GBytes) used classification. practical approach set memsize maximum memory available virtual machine classification choose multicores largest number cores available. Based memory available size blocks COG files, sits access images optimized way. way, sits tries ensure best possible use available resources.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"bayesian-smoothing-for-post-processing","chapter":"Bayesian smoothing for post-processing","heading":"Bayesian smoothing for post-processing","text":"","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"introduction-1","chapter":"Bayesian smoothing for post-processing","heading":"Introduction","text":"Image classification post-processing defined “refinement labeling classified image enhance classification accuracy” [77]. remote sensing image analysis, procedures combine pixel-based classification methods spatial post-processing method remove outliers misclassified pixels. pixel-based classifiers, post-processing methods allow including spatial information final results.sits package uses time-first, space-later approach. Since machine learning classifiers sits mostly pixel-based, necessary complement spatial smoothing methods. methods improve accuracy land classification incorporating spatial contextual information classification process.statistical classifiers use training samples derived “pure” pixels users selected represent desired output classes. However, images contain many mixed pixels irrespective resolution. Also, considerable degree data variability class. effects lead outliers whose chance misclassification significant. offset problems, post-processing methods use “smoothness assumption” [78]: nearby pixels tend label. put assumption practice, smoothing methods sits use neighborhood information remove outliers enhance consistency resulting map.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"motivation","chapter":"Bayesian smoothing for post-processing","heading":"Motivation","text":"smoothing method available sits uses Bayesian inference including expert knowledge derivation probabilities. stated Spiegelhalter Rice [79]: “Bayesian paradigm, degrees belief states nature specified. Bayesian statistical methods start existing ‘prior’ beliefs update using data give ‘posterior’ beliefs, may used basis inferential decisions”. Bayesian inference established major method assessing probability.assumption class probabilities local level similar provide baseline comparison pixel values produced classifier. Based two elements, Bayesian smoothing adjusts probabilities pixels, considering spatial dependence.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"bayesian-estimation","chapter":"Bayesian smoothing for post-processing","heading":"Bayesian estimation","text":"Bayesian estimate based two random variables: () observed class probabilities pixel denoted random variable \\(p_{,k}\\), \\(\\) index pixel \\(k\\) indicates class; (b) underlying class probabilities pixel, denoted random variable \\(\\phi_{,k}\\). probabilities \\(p_{,k}\\) classifier’s output, subject noise, outliers, classification errors. estimation aims remove effects obtain \\(\\phi_{,k}\\) approximate actual class probability better.first convert class probability values \\(p_{,k}\\) log-odds values using logit function, shown . logit function converts probability values ranging \\(0\\) \\(1\\) values negative infinity infinity. conversion probabilities logit values helpful support assumption normal distribution data.\\[\n    x_{,k} = \\ln \\left(\\frac{p_{,k}}{1 - p_{,k}}\\right)\n\\]\nfollows, consider two random variables pixel \\(\\): () \\(x_{,k}\\), observed class logits; (b) \\(\\mu_{,k}\\), inferred logit values. words, measure \\(x_{,k}\\), want obtain \\(\\mu_{,k} | x_{,k}\\). Bayesian inference procedure can expressed \\[\n    \\pi(\\mu|x) \\propto{} \\pi(x|\\mu)\\pi(\\mu).\n\\]\nestimate conditional posterior distribution \\(\\pi(\\theta{}|x)\\), combine two distributions: () distribution \\(\\pi(x|\\mu)\\), known likelihood function, expresses dependency measured values \\(x_{,k}\\) underlying values \\(\\mu_{,k}\\); (b) \\(\\pi(\\mu)\\), guess actual data distribution, known prior. simplicity, also assume independence different classes \\(k\\), instead considering multivariate distribution. Therefore, class \\(k\\) updated separately.assume likelihood \\(x_{,k} | \\mu_{,k}\\) follows normal distribution, \\(N(\\mu_{,k}, \\sigma^2_{k})\\), mean \\(\\mu_{,k}\\) variance \\(\\sigma^2_{k}\\). variance \\(\\sigma^2_{k}\\) hyperparameter controls smoothness resulting estimate. Therefore\\[\nx_{,k} | \\mu_{,k} \\sim N(\\mu_{,k}, \\sigma^2_{k})\n\\]\nlikelihood function. assume normal local prior parameter \\(\\mu_{,k}\\) parameters \\(m_{,k}\\) \\(s^2_{,k}\\):\\[\n\\mu_{,k} \\sim N(m_{,k}, s^2_{,k}).\n\\]\nestimate local means variances prior distribution considering spatial neighboring. Let \\(\\#(V_{})\\) number elements neighborhood \\(V_{}\\). can calculate mean value \\[\nm_{,t,k} = \\frac{\\sum_{(j) \\V_{}} x_{j,k}}{\\#(V_{})}\n\\]\nvariance \n\\[\ns^2_{,k} = \\frac{\\sum_{(j) \\V_{}} [x_{j,k} - m_{,k}]^2}{\\#(V_{})-1}.    \n\\]\nGiven assumptions, Bayesian update expected conditional mean \\({E}[\\mu_{,k} | x_{,k}]\\) given :\n\\[\n\\begin{equation}\n{E}[\\mu_{,k} | x_{,k}] =\n\\frac{m_{,t} \\times \\sigma^2_{k} +\nx_{,k} \\times s^2_{,k}}{ \\sigma^2_{k} +s^2_{,k}},\n\\end{equation}\n\\]can expressed weighted mean\\[\n{E}[\\mu_{,k} | x_{,k}] =\n\\Biggl [ \\frac{s^2_{,k}}{\\sigma^2_{k} +s^2_{,k}} \\Biggr ] \\times\nx_{,k} +\n\\Biggl [ \\frac{\\sigma^2_{k}}{\\sigma^2_{k} +s^2_{,k}} \\Biggr ] \\times m_{,k},\n\\]\\(x_{,k}\\) logit value pixel \\(\\) class \\(k\\).\\(m_{,k}\\) average logit values pixels class \\(k\\) neighborhood pixel \\(\\).\\(s^2_{,k}\\) variance logit values pixels class \\(k\\) neighborhood pixel \\(\\).\\(\\sigma^2_k\\) prior variance logit values class \\(k\\).equation weighted average value \\(x_{,k}\\) pixel mean \\(m_{,k}\\) neighboring pixels. variance \\(s^2_{,k}\\) neighbors high, smoothing algorithm gives weight pixel value \\(x_{,k}\\). hand, noise \\(\\sigma^2_k\\) increases, method gives weight neighborhood mean \\(m_{,k}\\).parameter \\(\\sigma^2_k\\) controls level smoothness. \\(\\sigma^2_k\\) zero, smoothed value \\({E}[\\mu_{,k} | x_{,k}]\\) equal pixel value \\(x_{,k}\\). Making \\(\\sigma^2_k\\) high leads much smoothness. Values prior variance \\(\\sigma^2_k\\), small relative local variance \\(s^2_{,k}\\), increase confidence original probabilities. Conversely, values prior variance \\(\\sigma^2_k\\), big relative local variance \\(s^2_{,k}\\), increase confidence average probability neighborhood.Thus, parameter \\(\\sigma^2_k\\) expresses confidence inherent variability distribution values class \\(k\\). smaller parameter \\(\\sigma^2_k\\), trust estimated probability values produced classifier class \\(k\\). Conversely, higher values \\(\\sigma^2_k\\) indicate lower confidence classifier outputs improved confidence local averages.Consider following two-class example. Take pixel probability \\(0.4\\) (logit \\(x_{,1} = -0.4054\\)) class probability \\(0.6\\) (logit \\(x_{,2} = 0.4054\\)) class B. Without post-processing, pixel labeled class B. Consider local average \\(0.6\\) (logit \\(m_{,1} = 0.4054\\)) class \\(0.4\\) (logit \\(m_{,2} = -0.4054\\)) class B. case outlier classified originally class B midst set class pixels. Take local variance logits \\(s^2_{,1} = 5\\) class \\(s^2_{,2} = 10\\) class B. difference expected local variability class smaller class B.complete estimate, need set parameter \\(\\sigma^2_{k}\\), representing prior belief variability probability values class. take \\(\\sigma^2_{}\\) class \\(\\sigma^2_{B}\\) class B \\(10\\), Bayesian estimated probability class \\(0.52\\) class B \\(0.48\\). case, pixel relabeled class . However, belief original values higher, get different result. set \\(\\sigma^2\\) \\(5\\) classes B, Bayesian probability estimate \\(0.48\\) class \\(0.52\\) class B. case, original label kept.make following recommendations setting \\(\\sigma^2_{k}\\) parameter:Set \\(\\sigma^2_{k}\\) parameter high values (\\(20\\) ) increase neighborhood influence compared probability values pixel. Classes whose probabilities strong spatial autocorrelation tend replace outliers different classes.Set \\(\\sigma^2_{k}\\) parameter high values (\\(20\\) ) increase neighborhood influence compared probability values pixel. Classes whose probabilities strong spatial autocorrelation tend replace outliers different classes.Set \\(\\sigma^2_{k}\\) parameter low values (\\(5\\) ) reduce neighborhood influence compared probabilities pixel class \\(k\\). way, classes low spatial autocorrelation likely relabeled.Set \\(\\sigma^2_{k}\\) parameter low values (\\(5\\) ) reduce neighborhood influence compared probabilities pixel class \\(k\\). way, classes low spatial autocorrelation likely relabeled.Consider case forest areas watersheds. expert wishes compact areas classified forests without many outliers inside , set \\(\\sigma^2\\) parameter class “Forest” high. comparison, avoid small watersheds similar neighbors relabeled, advisable avoid strong influence neighbors, setting \\(\\sigma^2\\) low possible.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"defining-the-neighborhood","chapter":"Bayesian smoothing for post-processing","heading":"Defining the neighborhood","text":"intuition Bayesian smoothing homogeneous neighborhoods class. homogeneous neighborhoods, dominant class higher average probabilities lower variance classes. neighborhoods, pixel different class likely associated lower average probabilities higher local variance. Mixed pixels limits areas different classes pose problem. pixels contain signatures two classes. account cases, Bayesian smoothing sits uses special definition neighborhood.reliable, local statistics include pixels likely belong single class. Windows centred border pixels contain pixels belonging class central pixel; others belong different class. Consider window size \\(7 \\times 7\\) around pixel probability map class “Forest”. contain central pixel 48 neighbours.surrounding pixels used compute local statistics. Local statistics estimates use pixels high probability belonging class “Forest”. window defined taking percentage surrounding pixels highest probabilities calculate local statistics. default, percentage set 50%. intuition border pixels half neighbours one class half another.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"measuring-the-local-variance","chapter":"Bayesian smoothing for post-processing","heading":"Measuring the local variance","text":"discussed , effect Bayesian estimator depends values prior variance \\(\\sigma^2_k\\) set user local variance \\(s^2_{,1}\\) measured pixel. illustrate impact choices \\(\\sigma^2_k\\) parameter, present detailed example. first step take probability cube deforestation detection application area Brazilian Amazon. cube produced random forest model six classes. first build data cube plot probabilities classes “Water” “Forest”.\nFigure 72: Probability map produced classes Forest Water (Source: Authors).\nprobability map class “Forest” shows high values associated compact patches linear stretches riparian areas. contrast, probability map class “Water” mostly low values, except places high chance occurrence class. understand behavior Bayesian estimator, helpful examine local variance associated logits probabilities.sits_variance() function estimates local variances logits, correspond \\(s^2_{,k}\\) parameter Bayesian estimator. following parameters: () cube, probability cube; (b) window_size, dimension local neighborhood; (c) neigh_fraction, percentage pixels neighborhood used calculate variance; (d) multicores, number CPU cores used processing; (e) memsize, memory available; (f) output_dir, directory results stored; (g) version, version control. example , use half pixels \\(7 \\times 7\\) window estimate variance. chosen pixels highest probability representative actual class distribution. output values variances logits.\nFigure 73: Variance map class Forest (Source: Authors).\nplot “Forest” class shows areas low variance associated dense forest patches well areas trees completely removed. Areas high variance primarily associated borders forest areas classes. contrast, plot “Water” class informative, small areas high variance located near areas high water probability. plots show variance values low, high values reach 30. information relevant setting values prior variance \\(\\sigma^2\\), discussed .","code":"\n# define the classes of the probability cube\nlabels <- c(\"Water\", \"ClearCut_Burn\", \"ClearCut_Soil\",\n            \"ClearCut_Veg\", \"Forest\", \"Wetland\")\n# directory where the data is stored \ndata_dir <- system.file(\"extdata/Rondonia-20LLQ/\", package = \"sitsdata\")\n# create a probability data cube from a file \nprobs_cube <- sits_cube(\n    source = \"MPC\",\n    collection = \"SENTINEL-2-L2A\",\n    data_dir = data_dir,\n    bands = \"probs\",\n    labels = labels,\n    parse_info = c(\"X1\", \"X2\", \"tile\", \"start_date\", \"end_date\", \"band\", \"version\"))\n\n# plot the probabilities for water and forest\nplot(probs_cube, labels = c(\"Water\", \"Forest\"))\nvar_cube <- sits_variance(\n    cube = probs_cube,\n    window_size = 7,\n    neigh_fraction = 0.5,\n    multicores = 4,\n    memsize = 24,\n    output_dir = \"./tempdir/chp10\",\n    version = \"w7-n05\")\n\nplot(var_cube, labels = c(\"Water\", \"Forest\"))"},{"path":"bayesian-smoothing-for-post-processing.html","id":"running-bayesian-smoothing","chapter":"Bayesian smoothing for post-processing","heading":"Running Bayesian smoothing","text":"run Bayesian smoothing, use sits_smooth() parameters: () cube, probability cube produced sits_classify(); (b) window_size, local window compute neighborhood probabilities; (d) neigh_fraction, fraction local neighbors used calculate local statistics; (e) smoothness, vector estimates prior variance class; (f) multicores, number CPU cores used processing; (g) memsize, memory available classification; (h) output_dir, directory results stored; () version, version control. resulting cube can visualized plot(). follows, compare smoothing effect varying window_size smoothness parameters.Together, parameters window_size neigh_fraction control many pixels neighborhood Bayesian estimator use calculate local statistics. example, setting window size \\(7\\) neigh_fraction \\(0.5\\) (defaults) ensures \\(25\\) samples used estimate local statistics.first reference classified map without smoothing, shows presence outliers classification errors. obtain , use sits_label_classification(), taking probability map input, follows.\nFigure 74: Classified map without smoothing (Source: Authors).\nremove outliers classification errors, run smoothing procedure prior variances set value \\(20\\), relatively high compared maximum local class variance shown . case, situations, new value probability strongly influenced local average.\nFigure 75: Probability maps bayesian smoothing (Source: Authors).\nBayesian smoothing removed local variability associated misclassified pixels differ neighbors. side effect: water areas surrounded forests preserved forest probability map. smoothing impact best appreciated comparing labeled map produced without smoothing one follows procedure, shown .\nFigure 76: Final classification map Bayesian smoothing 7 x 7 window, using neigh_fraction = 0.5 smoothness = 20 (Source: Authors).\nsmoothed map, outliers removed expanding forest areas. Forests replaced small corridors water soil encircled trees. effect due high probability forest detection training data. keep water areas reduce expansion forest area, viable alternative reduce smoothness (\\(\\sigma^2\\)) “Forest” “Water” classes. way, local influence forest classes reduced. water areas, since narrow, neighborhoods many low probability values, reduce expected value Bayesian estimator.\nFigure 77: Probability maps Bayesian smoothing 7 x 7 window low smoothness classes Water Forest (Source: Authors).\nComparing two maps, narrow water streams inside forest area better preserved. Small corridors forest areas also maintained. better comparison two maps requires importing QGIS. Exporting data sits QGIS discussed Chapter Visualising exporting data.conclusion, post-processing desirable step classification process. Bayesian smoothing improves borders objects created classification removes outliers result pixel-based classification. reliable method used situations.","code":"\n# Generate the thematic map\nclass_map <- sits_label_classification(\n    cube = probs_cube,\n    multicores = 4,\n    memsize = 12,\n    output_dir = \"./tempdir/chp10\",\n    version = \"no_smooth\")\n\n# Plot the result\nplot(class_map)\n# Compute Bayesian smoothing\ncube_smooth_w7_f05_s20 <- sits_smooth(\n    cube = probs_cube,\n    window_size = 7,\n    neigh_fraction = 0.50,\n    smoothness = 20, \n    multicores = 4,\n    memsize = 12,\n    version = \"w7-f05-s20\",\n    output_dir = \"./tempdir/chp10\")\n\n# Plot the result\nplot(cube_smooth_w7_f05_s20, labels = c(\"Water\", \"Forest\"), palette = \"YlGn\")\n# Generate the thematic map\ndefor_map_w7_f05_20 <- sits_label_classification(\n    cube = cube_smooth_w7_f05_s20,\n    multicores = 4,\n    memsize = 12,\n    output_dir = \"./tempdir/chp8\",\n    version = \"w7-f05-s20\")\n\nplot(defor_map_w7_f05_20)\n# Reduce smoothing for classes Water and Forest\n# Labels:  \"Water\", \"ClearCut_Burn\", \"ClearCut_Soil\", \n#          \"ClearCut_Veg\", \"Forest\", \"Wetland\"\nsmooth_water_forest <- c(5, 20, 20, 20, 5, 20)\n# Compute Bayesian smoothing\ncube_smooth_w7_f05_swf <- sits_smooth(\n    cube = probs_cube,\n    window_size = 7,\n    neigh_fraction = 0.5,\n    smoothness = smooth_water_forest,\n    multicores = 4,\n    memsize = 12,\n    version = \"w7-f05-swf\",\n    output_dir = \"./tempdir/chp10\")\n\n# Computed labeled map\ndefor_map_w7_f05_swf <- sits_label_classification(\n    cube = cube_smooth_w7_f05_swf,\n    multicores = 4,\n    memsize = 12,\n    output_dir = \"./tempdir/chp10\",\n    version = \"w7-f05-swf\")\n\nplot(defor_map_w7_f05_swf)"},{"path":"validation-and-accuracy-measurements.html","id":"validation-and-accuracy-measurements","chapter":"Validation and accuracy measurements","heading":"Validation and accuracy measurements","text":"","code":""},{"path":"validation-and-accuracy-measurements.html","id":"case-study","chapter":"Validation and accuracy measurements","heading":"Case study","text":"show validation accuracy assessment insits, run example land classification Cerrado biome, second largest biome Brazil 1.9 million km\\(^2\\). Brazilian Cerrado tropical savanna ecoregion rich ecosystem ranging grasslands woodlands. home 7000 species plants high levels endemism [80]. includes three major types natural vegetation: Open Cerrado, typically composed grasses small shrubs sporadic presence small tree vegetation; Cerrado, typical savanna formation presence low, irregularly branched, thin-trunked trees; Cerradão, areas medium-sized trees (10–12 m) [81]. natural areas converted agriculture fast pace, one world’s fast-moving agricultural frontiers [82]. main agricultural land uses include cattle ranching, crop farms, planted forests. classification follows work Simoes et al. [57].data comprises 67 Landsat-8 tiles Brazil Data Cube (BDC), 23 time steps covering 2017-08-29 2018-08-29. Since data available Brazil Data Cube, users first obtain access BDC obtaining access key. obtaining access key, include credentials using environment variables, shown . Obtaining BDC access key free. obtain key, users need register BDC site.obtaining BDC access key, can now create data cube Cerrado biome.\nFigure 78: Color composite image first date cube (Source: Authors).\nclassify Cerrado, use training data set produced Simoes et al. [57]. authors carried systematic sampling using \\(5 \\times 5\\) km grid throughout Cerrado biome, collecting 85,026 samples. training data labels extracted three sources: 2018 pastureland map Parente et al. [83], MapBiomas Collection 5 2018 [84], Brazil’s National Mapping Agency IBGE land maps 2016–2018. 85,026 samples, authors selected without disagreement labels assigned three sources. final training set consists 48,850 points authors extracted time series using Landsat-8 data cube available BDC. classes training set : “Annual Crop”, “Cerradao”, “Cerrado”, “Open Cerrado”, “Nat_NonVeg” (Dunes), “Pasture”, “Perennial_Crop”, “Silviculture” (Planted Forests), “Sugarcane”, “Water”.data set available package sitsdata samples_cerrado_lc8.","code":"Sys.setenv(\n    \"BDC_ACCESS_KEY\" = <your_bdc_access_key>\n)\n# Files are available in the Brazil Data Cube\n# \n# Obtain the region of interest covering the Cerrado biome\nroi_cerrado_shp <- system.file(\n    \"extdata/shapefiles/cerrado_border/cerrado_border.shp\",\n    package = \"sitsdata\")\n# Read the shapefile as an object of the \"sf\" package\nroi_cerrado <- sf::st_read(roi_cerrado_shp, quiet = TRUE)\n# Create a data cube for the entire Cerrado biome\ncerrado_cube <- sits_cube(\n        source = \"BDC\",\n        collection = \"LC8_30_16D_STK-1\",\n        roi = roi_cerrado,\n        start_date = \"2017-08-29\",\n        end_date = \"2018-08-29\",\n        multicores = 3)\n\n# Plot the first date with NDVI and EVI bands\nplot(cerrado_cube, \n     tile = \"044049\", \n     red = \"B7\", \n     green = \"B5\", \n     blue = \"B4\")\nlibrary(sitsdata)\ndata(\"samples_cerrado_lc8\")\n# Show the class distribution in the new training set\nsummary(samples_cerrado_lc8)#> # A tibble: 10 × 3\n#>    label          count     prop\n#>    <chr>          <int>    <dbl>\n#>  1 Annual_Crop     6887 0.141   \n#>  2 Cerradao        4211 0.0862  \n#>  3 Cerrado        16251 0.333   \n#>  4 Nat_NonVeg        38 0.000778\n#>  5 Open_Cerrado    5658 0.116   \n#>  6 Pasture        12894 0.264   \n#>  7 Perennial_Crop    68 0.00139 \n#>  8 Silviculture     805 0.0165  \n#>  9 Sugarcane       1775 0.0363  \n#> 10 Water            263 0.00538"},{"path":"validation-and-accuracy-measurements.html","id":"cross-validation-of-training-set","chapter":"Validation and accuracy measurements","heading":"Cross-validation of training set","text":"Cross-validation technique estimate inherent prediction error model [45]. Since cross-validation uses training samples, results accuracy measures unless samples carefully collected represent diversity possible occurrences classes study area [85]. practice, working large areas, hard obtain random stratified samples cover different variations land classes associated ecosystems study area. Thus, cross-validation taken measure model performance training data estimate overall map accuracy.Cross-validation uses part available samples fit classification model different part test . k-fold validation method splits data \\(k\\) partitions approximately size proceeds fitting model testing \\(k\\) times. step, take one distinct partition test remaining \\({k-1}\\) training model calculate prediction error classifying test partition. simple average gives us estimation expected prediction error. recommended choices \\(k\\) \\(5\\) \\(10\\) [45].sits_kfold_validate() supports k-fold validation sits. result confusion matrix accuracy statistics (overall class). examples , use multiprocessing speed results.Since data set big highly imbalanced, use sits_reduce_imbalance() reduce size produce smaller, balanced sample data set validation examples.following code five-fold validation using random forest algorithm.One useful function sits capacity compare different validation methods store XLS file analysis. following example shows using Cerrado data set. take models: random forest (sits_rfor()), extreme gradient boosting (sits_xgboost()), temporal CNN (sits_tempcnn()), lightweight temporal attention encoder (sits_lighttae()). computing confusion matrix statistics model, also store result list. calculation finished, function sits_to_xlsx() writes results Excel-compatible spreadsheet.resulting Excel file can opened R using spreadsheet programs. Figure 79 shows printout read Excel. sheet corresponds output one model. simplicity, show result TempCNN, overall accuracy 90%.\nFigure 79: Result 5-fold cross-validation Mato Grosso data using LightTAE (Source: Authors).\nscores overall accuracy similar models. However, models significant differences, shown comparing F1 scores .table shows F1-scores classes model, produced k-fold validation. F1-scores harmonic mean user’s accuracy precision accuracy class. results show , although deep learning models TempCNN LightTAE similar overall accuracies random forest XGBoost, F1-scores per class generally better.cross-validation results interpreted carefully. Cross-validation measures well model fits training data. Using results measure classification accuracy valid training data good sample entire data set. practice, training data subject various sources bias. cases land classification, classes much frequent others, , training data set imbalanced. large areas, regional differences soil climate condition lead classes different spectral responses. collecting samples large areas, field analysts may restricted areas access (e.g., along roads). additional problem mixed pixels. Expert interpreters tend select samples stand fieldwork reference images. Border pixels unlikely chosen part training data. reasons, cross-validation results considered indicative accuracy measurement entire data set.","code":"\n# Reduce imbalance in the data set\n# Maximum number of samples per class will be 1000 \n# Minimum number of samples per class will be 500\nsamples_cerrado_bal <- sits_reduce_imbalance(\n    samples = samples_cerrado_lc8,\n    n_samples_over = 500,\n    n_samples_under = 1000,\n    multicores = 4)\n\n# Show new sample distribution\nsummary(samples_cerrado_bal)#> # A tibble: 10 × 3\n#>    label          count   prop\n#>    <chr>          <int>  <dbl>\n#>  1 Annual_Crop     1000 0.124 \n#>  2 Cerradao         884 0.110 \n#>  3 Cerrado          980 0.121 \n#>  4 Nat_NonVeg       500 0.0619\n#>  5 Open_Cerrado     960 0.119 \n#>  6 Pasture          972 0.120 \n#>  7 Perennial_Crop   500 0.0619\n#>  8 Silviculture     805 0.0997\n#>  9 Sugarcane        972 0.120 \n#> 10 Water            500 0.0619\n# Perform a five-fold validation for the Cerrado data set\n# Random forest machine learning method using default parameters\nval_rfor <- sits_kfold_validate(\n    samples = samples_cerrado_bal, \n    folds = 5, \n    ml_method = sits_rfor(),\n    multicores = 5)\n\n# Print the validation statistics\nsummary(val_rfor)#> Overall Statistics                          \n#>  Accuracy : 0.8774        \n#>    95% CI : (0.87, 0.8844)\n#>     Kappa : 0.8627\n# Compare different models for the Cerrado data set\n# Create a list to store the results\nresults <- list()\n# Give a name to the results of the random forest model (see above)\nval_rfor$name <- \"rfor\"\n# Store the rfor results in a list\nresults[[length(results) + 1]] <- val_rfor\n# Extreme Gradient Boosting\nval_xgb <- sits_kfold_validate(\n    samples = samples_cerrado_bal,\n    ml_method = sits_xgboost(),\n    folds = 5,\n    multicores = 5\n)\n# Give a name to the SVM model\nval_xgb$name <- \"xgboost\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_xgb\n# Temporal CNN\nval_tcnn <- sits_kfold_validate(\n    samples = samples_cerrado_bal,\n    ml_method = sits_tempcnn(\n        optimizer = torchopt::optim_adamw,\n        opt_hparams = list(lr = 0.001)),\n    folds = 5,\n    multicores = 5\n)\n# Give a name to the result\nval_tcnn$name <- \"TempCNN\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_tcnn\n# Light TAE\nval_ltae <- sits_kfold_validate(\n    samples = samples_cerrado_bal,\n    ml_method = sits_lighttae(\n        optimizer = torchopt::optim_adamw,\n        opt_hparams = list(lr = 0.001)),\n    folds = 5,\n    multicores = 5\n)\n# Give a name to the result\nval_ltae$name <- \"LightTAE\"\n# store the results in a list\nresults[[length(results) + 1]] <- val_ltae\n# Save to an XLS file\nxlsx_file <- \"./model_comparison.xlsx\"\n\nsits_to_xlsx(results, file = xlsx_file)\nmodel_acc <- tibble::tibble(\n    \"Random Forest\" = val_rfor$overall[[\"Accuracy\"]],\n    \"XGBoost\"       = val_xgb$overall[[\"Accuracy\"]],\n    \"TempCNN\"       = val_tcnn$overall[[\"Accuracy\"]],\n    \"LightTAE\"      = val_ltae$overall[[\"Accuracy\"]])\n\noptions(digits = 3)\nmodel_acc#> # A tibble: 1 × 4\n#>   `Random Forest` XGBoost TempCNN LightTAE\n#>             <dbl>   <dbl>   <dbl>    <dbl>\n#> 1           0.879   0.889   0.897    0.894\nf1_score_rfor <- unname(val_rfor$byClass[,\"F1\"])\nf1_score_xgb <-  unname(val_xgb$byClass[,\"F1\"])\nf1_score_tcnn <-  unname(val_tcnn$byClass[,\"F1\"])\nf1_score_ltae <-  unname(val_ltae$byClass[,\"F1\"])\n\nf1_scores <- tibble::tibble(\n    \"Classes\"  = sits_labels(samples_cerrado_bal),\n    \"RandFor\"  = f1_score_rfor,\n    \"XGBoost\"  = f1_score_xgb,\n    \"TempCNN\"  = f1_score_tcnn,\n    \"LightTAE\" = f1_score_ltae)\n\nf1_scores#> # A tibble: 10 × 5\n#>    Classes        RandFor XGBoost TempCNN LightTAE\n#>    <chr>            <dbl>   <dbl>   <dbl>    <dbl>\n#>  1 Annual_Crop      0.909   0.903   0.924    0.912\n#>  2 Cerradao         0.878   0.889   0.877    0.882\n#>  3 Cerrado          0.746   0.759   0.755    0.748\n#>  4 Nat_NonVeg       0.823   0.835   0.838    0.833\n#>  5 Open_Cerrado     0.824   0.847   0.854    0.859\n#>  6 Pasture          0.917   0.933   0.947    0.931\n#>  7 Perennial_Crop   0.999   0.999   0.998    1    \n#>  8 Silviculture     0.977   0.976   0.990    0.995\n#>  9 Sugarcane        0.998   0.998   1        0.998\n#> 10 Water            0.890   0.911   0.945    0.936"},{"path":"validation-and-accuracy-measurements.html","id":"accuracy-assessment-of-classified-images","chapter":"Validation and accuracy measurements","heading":"Accuracy assessment of classified images","text":"measure accuracy classified images, sits_accuracy() uses area-weighted technique, following best practices proposed Olofsson et al. [86]. need area-weighted estimates arises land classes evenly distributed space. applications (e.g., deforestation) interest lies assessing much image changed, area mapped deforested likely small fraction total area. users disregard relative importance small areas change taking place, overall accuracy estimate inflated unrealistic. reason, Olofsson et al. [86] argue “mapped areas adjusted eliminate bias attributable map classification error, error-adjusted area estimates accompanied confidence intervals quantify sampling variability estimated area”.motivation, measuring accuracy classified images, sits_accuracy() follows procedure set Olofsson et al. [86]. Given classified image validation file, first step calculates confusion matrix traditional way, .e., identifying commission omission errors. calculates unbiased estimator proportion area cell \\(,j\\) error matrix\\[\n\\hat{p_{,j}} = W_i\\frac{n_{,j}}{n_i},\n\\]\ntotal area map \\(A_{tot}\\), mapping area class \\(\\) \\(A_{m,}\\) proportion area mapped class \\(\\) \\(W_i = {A_{m,}}/{A_{tot}}\\). Adjusting area size allows producing unbiased estimation total area class \\(j\\), defined stratified estimator\n\\[\n\\hat{A_j} = A_{tot}\\sum_{=1}^KW_i\\frac{n_{,j}}{n_i}.\n\\]unbiased area estimator includes effect false negatives (omission error) considering effect false positives (commission error). area estimates also allow unbiased estimate user’s producer’s accuracy class. Following Olofsson et al. [86], provide 95% confidence interval \\(\\hat{A_j}\\).produce adjusted area estimates, sits_accuracy() must get classified image together csv file containing set well-selected labeled points. csv file format one used obtain samples, discussed earlier.labeled points based random stratified sample. areas associated class contribute test data used accuracy assessment.biases inherent cross-validation training data, independent validation data set used measure classification accuracy. case study, Simoes et al. [57] systematic sampling Cerrado biome using \\(20 \\times 20\\) km grid total 5,402 points. samples independent training set used classification. interpreted five specialists using high-resolution images period classification. resulted 5,286 evaluation samples thus distributed: “Annual Crop” (553), “Cerrado” (3,155), “Natural Non Vegetated” (44), “Pasture” (1,246), “Perennial Crop” (38), “Silviculture” (94), “Sugarcane” (77), “Water” (79). data set available package sitsdata, described . validation file, samples belonging classes “Cerrado”, “Open Cerrado”, “Cerradao” (Woody Savanna) grouped together single class.first step obtain classification map. code full classification Cerrado biome, using TempCNN algorithm, shown . large data size, code executed. accuracy assessment, use labeled classification map available Dropbox folder.Since code included information , use labeled cube stored Dropbox folder perform accuracy assessment. First, retrieve metadata cube.\nFigure 80: Classification tile 044048 Landsat data cube Brazilian Cerrado 2017/2018 (Source: Authors).\nnext step provide csv file validation points, described .example shows important correct area estimates land classification reduce bias effect misclassification consider different producer’s accuracies associated class. also shows actual overall accuracy generally lower result cross-validation.","code":"\n# This code shows the classification of the Cerrado biome\n# It is included for information purposes\n# It takes a long time to run\ntcnn_model <- sits_train(\n    samples = samples_cerrado_lc8,\n    ml_method = sits_tempcnn())\n\n# Using the tempCNN model to classify the Cerrado\n# This example should be run on a large virtual machine\ncerrado_probs_cube <- sits_classify(\n    cube = cerrado_cube,\n    ml_model = tcnn_model,\n    memsize = 128,\n    multicores = 64,\n    output_dir = \"./tempdir/chp11\")\n\ncerrado_bayes_cube <- sits_smooth(\n    cube = cerrado_probs_cube,\n    memsize = 128,\n    multicores = 64,\n    output_dir = \"./tempdir/chp11\")\n\ncerrado_classif <- sits_label_classification(\n    cube = cerrado_bayes_cube,\n    memsize = 128,\n    multicores = 64,\n    output_dir = \"./tempdir/chp11\")\n# Retrieve the metadata for the classified cube\n# The files are stored in the sitsdata package\ndata_dir <- system.file(\"extdata/Cerrado\", package = \"sitsdata\")\n# labels for the classification\nlabels <- c(\n  \"Annual_Crop\", \"Cerrado\", \"Cerrado\", \"Nat_NonVeg\", \"Cerrado\",\n  \"Pasture\", \"Perennial_Crop\", \"Silviculture\", \"Sugarcane\", \"Water\"\n)\n# Read the cube metadata\ncerrado_classif <- sits_cube(\n  source = \"USGS\",\n  collection = \"LANDSAT-C2L2-SR\",\n  bands = \"class\",\n  labels = labels,\n  data_dir = data_dir,\n  parse_info = c(\"X1\", \"tile\", \"band\", \"start_date\", \"end_date\", \"version\")\n)\n# Plot one tile of the classification\nplot(cerrado_classif, tiles = \"044048\")\n# Get ground truth points\nvalid_csv <- system.file(\"extdata/csv/cerrado_lc8_validation.csv\",\n  package = \"sitsdata\"\n)\n# Calculate accuracy according to Olofsson's method\narea_acc <- sits_accuracy(cerrado_classif,\n  validation_csv = valid_csv\n)\n# Print the area estimated accuracy\narea_acc#> $error_matrix\n#>                 \n#>                  Annual_Crop Cerrado Nat_NonVeg Pasture Perennial_Crop Silviculture Sugarcane\n#>   Annual_Crop            469      13          0      47              0            0         2\n#>   Cerrado                  4    2813          0     191              3           12         2\n#>   Nat_NonVeg               0       2         43       0              0            0         0\n#>   Pasture                 67     287          0     999              5            3         2\n#>   Perennial_Crop           0      23          0       2             26            2         0\n#>   Silviculture             0      16          0       2              4           77         0\n#>   Sugarcane               13       0          0       5              0            0        71\n#>   Water                    0       1          1       0              0            0         0\n#>                 \n#>                  Water\n#>   Annual_Crop        0\n#>   Cerrado            4\n#>   Nat_NonVeg         2\n#>   Pasture            4\n#>   Perennial_Crop     0\n#>   Silviculture       0\n#>   Sugarcane          0\n#>   Water             69\n#> \n#> $area_pixels\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>       3.12e+07       2.02e+08       9.97e+05       1.09e+08       1.62e+06       6.96e+06 \n#>      Sugarcane          Water \n#>       1.06e+07       1.42e+07 \n#> \n#> $error_ajusted_area\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>       3.47e+07       2.14e+08       1.11e+06       9.58e+07       1.67e+06       6.51e+06 \n#>      Sugarcane          Water \n#>       8.84e+06       1.44e+07 \n#> \n#> $stderr_prop\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>       0.002328       0.004194       0.000542       0.004386       0.000735       0.001060 \n#>      Sugarcane          Water \n#>       0.001282       0.000931 \n#> \n#> $stderr_area\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>         876650        1579665         204161        1651840         276851         399372 \n#>      Sugarcane          Water \n#>         483007         350471 \n#> \n#> $conf_interval\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>        1718233        3096142         400156        3237606         542628         782769 \n#>      Sugarcane          Water \n#>         946693         686924 \n#> \n#> $accuracy\n#> $accuracy$user\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>          0.883          0.929          0.915          0.731          0.491          0.778 \n#>      Sugarcane          Water \n#>          0.798          0.972 \n#> \n#> $accuracy$producer\n#>    Annual_Crop        Cerrado     Nat_NonVeg        Pasture Perennial_Crop   Silviculture \n#>          0.794          0.880          0.820          0.830          0.474          0.831 \n#>      Sugarcane          Water \n#>          0.954          0.956 \n#> \n#> $accuracy$overall\n#> [1] 0.861\n#> \n#> \n#> attr(,\"class\")\n#> [1] \"sits_area_assessment\" \"list\""},{"path":"uncertainty-and-active-learning.html","id":"uncertainty-and-active-learning","chapter":"Uncertainty and active learning","heading":"Uncertainty and active learning","text":"Land classification tasks unique characteristics differ machine learning domains, image recognition natural language processing. main challenge land classification describe diversity planet’s landscapes handful labels. However, diversity world’s ecosystem makes classification systems biased approximations reality. stated Murphy: “gradation properties world means smallish number categories never map perfectly onto objects” [87]. reason, sits provides tools improve classifications using process called active learning.Active learning remote sensing data classification iterative process sample selection, labeling, model retraining. following steps provide general overview use active learning remote sensing data classification:Collect initial training samples: Start collecting small set representative training samples cover range land classes interest.Train machine learning model: Use initial training samples train machine learning model classify remote sensing data.Classify data cube using model.Identify areas uncertainty.Select samples re-labelling: Select set unlabelled samples model uncertain , .e., model least confident classifying.Label selected samples: user labels selected samples, adding training set.Retrain model: model retrained using newly labeled samples, process repeats , starting step 2.Stop classification accuracy satisfactory: iterative process continues classification accuracy reaches satisfactory level.traditional classification methods, experts provide set training samples use machine learning algorithm produce map. contrast, active learning approach puts human loop [88]. iteration, unlabelled set samples presented user, assigns classes includes training set [89]. process repeated expert satisfied result, shown Figure 81.\nFigure 81: Active learning approach (Source: Crawford et al. (2013). Reproduction fair use doctrine).\nActive learning aims reduce bias errors sample selection , , improve accuracy result. interaction, experts asked review pixels machine learning classifier indicates high uncertainty value. Sources classification uncertainty include missing classes mislabeled samples. sits, active learning supported combination three functions: sits_uncertainty(), sits_uncertainty_sampling(), sits_confidence_sampling().","code":""},{"path":"uncertainty-and-active-learning.html","id":"measuring-uncertainty","chapter":"Uncertainty and active learning","heading":"Measuring uncertainty","text":"Uncertainty refers degree doubt ambiguity accuracy classification results. Several sources uncertainty can arise land classification using satellite data, including:Classification errors: can occur classification algorithm misinterprets spectral spatial characteristics input data, leading misclassification land classes.Ambiguity classification schema: definition land classes can ambiguous subjective, leading inconsistencies classification results.Variability landscape: Natural human-induced variations landscape can make difficult accurately classify land areas.Limitations data: quality quantity input data can influence accuracy classification results.Quantifying uncertainty land classification important ensuring results reliable valid decision-making. Various methods, confusion error matrices, can used estimate visualize level uncertainty classification results. Additionally, incorporating uncertainty estimates decision-making processes can help identify regions investigation data collection needed.function sits_uncertainty() calculates uncertainty cube based probabilities produced classifier. takes probability cube input. uncertainty measure relevant context active learning. helps increase quantity quality training samples providing information model’s confidence. supported types uncertainty ‘entropy’, ‘least’, ‘margin’, ‘ratio’.Least confidence sampling difference uncertainty (100% confidence) probability likely class, normalized number classes. Let \\(P_1()\\) higher class probability pixel \\(\\). least confidence sampling expressed \\[\n\\theta_{LC} = (1 - P_1()) * \\frac{n}{n-1}.\n\\]margin confidence sampling difference two confident predictions, expressed 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_2()\\) two higher class probabilities pixel \\(\\). , margin confidence expressed \\[\n\\theta_{MC} = 1 - P_1() - P_2().\n\\]ratio confidence measure ratio two confident predictions, expressed range 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_2()\\) two higher class probabilities pixel \\(\\). , ratio confidence expressed \n\\[\n\\theta_{RC} = \\frac{P_2()}{P_1()}.\n\\]Entropy measure uncertainty used Claude Shannon classic work “Mathematical Theory Communication”. related amount variability probabilities associated pixel. lower variability, lower entropy. Let \\(P_k()\\) probability class \\(k\\) pixel \\(\\). entropy calculated \n\\[\n\\theta_{E} = \\frac{-\\sum_{k=1}^K P_k() * log_2(P_k())}{log_2{n}}.\n\\]parameters sits_uncertainty() : cube, probability data cube; type, uncertainty measure (default least). case entropy, also requires parameters window_size, size neighborhood calculate entropy (default 5), window_fn, function applied entropy calculation (default median). processing functions, multicores number cores run function memsize maximum overall memory (GB) run function, output_dir output directory image files, version version result.","code":""},{"path":"uncertainty-and-active-learning.html","id":"using-uncertainty-measures-for-active-learning","chapter":"Uncertainty and active learning","heading":"Using uncertainty measures for active learning","text":"following case study shows uncertainty measures can used context active learning. study area subset one Sentinel-2 tile state Rondonia, Brazil. work aims detect deforestation Brazilian Amazonia.study area close Samuel Hydroelectric Dam, located Madeira River Brazilian state Rondônia. Building dam led loss 56,000 ha native forest. dam’s construction caused displacement several indigenous communities traditional populations, leading social cultural disruption. Additionally, flooding large forest areas resulted losing habitats biodiversity, including several endangered species. dam altered natural flow Madeira River, leading changes water quality temperature affecting aquatic life depends river. changes river flow also impacted navigation transportation activities local communities.first step produce regular data cube chosen area 2020-06-01 2021-09-01. reduce processing time storage, use three bands (B02, B8A, B11) plus cloud band, take small area inside tile. obtaining regular cube, plot study area dates temporal interval data cube. first image taken beginning dry season 2020-07-04, inundation area dam covered shallow water.\nFigure 82: Area Rondonia near Samuel dam (Source: Authors).\nsecond image 2020-11-09 shows inundation area dries dry season. early November 2020, end dry season, inundation area dry response similar bare soil burned areas. Madeira River can seen running dried inundation area.\nFigure 83: Area Rondonia near Samuel dam November 2021 (Source: Authors).\nthird image 2021-08-08. early August 2021, wet season, inundation area covered shallow water layer. Several burned clear-cut areas can also seen August 2021 image compared July 2020 one. Given contrast wet dry seasons, correct land classification area hard.\nFigure 84: Area Rondonia near Samuel dam August 2021 (Source: Authors).\nnext step classify study area using training set 480 times series collected state Rondonia (Brazil) detecting deforestation. training set uses 4 classes (“Burned_Area”, “Forest”, “Highly_Degraded”, “Cleared_Area”). cube classified using LightTAE model, post-processed Bayesian smoothing, labeled.\nFigure 85: Classified map area Rondonia near Samuel dam (Source: Authors).\nresulting map correctly identifies forest area deforestation. However, wrongly classifies area covered Samuel hydroelectric dam. reason lack samples classes related surface water wetlands. improve classification, need improve samples. , first step calculate uncertainty classification.\nFigure 86: Uncertainty map classification Rondonia near Samuel dam (Source: Authors).\nexpected, places highest uncertainty covered surface water associated wetlands. places likely misclassified. reason, sits provides sits_uncertainty_sampling(), takes uncertainty cube input produces tibble locations WGS84 high uncertainty. function three parameters: n, number uncertain points included; min_uncert, minimum value uncertainty pixels included list; sampling_window, improve spatial distribution new samples avoiding points neighborhood included. running function, can use sits_view() visualize location samples.\nFigure 87: Location uncertain pixel classification Rondonia near Samuel dam (Source: Authors).\nvisualization shows samples located areas covered Samuel data. designate samples, “Wetlands” can used first approximation labelling. detailed evaluation, recommended practice, requires analysing samples exploration software QGIS individually labelling sample. case, take direct approach illustration purposes.\nFigure 88: New land classification Rondonia near Samuel dam (Source: Authors).\nresults show significant quality gain earlier classification. still confusion areas exposed soils inside inundation area, classified burned areas. also useful show uncertainty map associated second model.\nFigure 89: Uncertainty map classification Rondonia near Samuel dam - improved model (Source: Authors).\nnew uncertainty map shows, significant improvement quality classification. remaining areas high uncertainty affected contrast wet dry seasons close inundation area. areas low-laying places sometimes covered water sometimes bare soil areas throughout year, depending intensity rainy season. improve classification quality, obtain new samples uncertain areas, label , add samples. general, Chapter shows, combining uncertainty measurements active learning recommended practice improving classification results.","code":"\n# Select a S2 tile\ns2_cube_ro <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LMR\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"SCL\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2021-09-01\")\n)\n\n# Select a small area inside the tile\nroi <- c(\n  lon_max = -63.25790, lon_min = -63.6078,\n  lat_max = -8.72290, lat_min = -8.95630\n)\n# Regularize the small area cube\ns2_reg_cube_ro <- sits_regularize(\n  cube = s2_cube_ro,\n  output_dir = \"./tempdir/chp12/\",\n  res = 20,\n  roi = roi,\n  period = \"P16D\",\n  multicores = 4\n)\n\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-07-04\"\n)\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-11-09\"\n)\nplot(s2_reg_cube_ro, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2021-08-08\")\nlibrary(sitsdata)\n# Load the training set\ndata(\"samples_prodes_4classes\")\n# Select the same three bands used in the data cube\nsamples_4classes_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n)\n\n# Train a lightTAE model\nltae_model <- sits_train(\n  samples = samples_4classes_3bands,\n  ml_method = sits_lighttae()\n)\n\n# Classify the small area cube\ns2_cube_probs <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = ltae_model,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 15,\n  multicores = 5\n)\n\n# Post-process the probability cube\ns2_cube_bayes <- sits_smooth(\n  cube = s2_cube_probs,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the post-processed  probability cube\ns2_cube_label <- sits_label_classification(\n  cube = s2_cube_bayes,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_label)\n# Calculate the uncertainty cube\ns2_cube_uncert <- sits_uncertainty(\n  cube = s2_cube_bayes,\n  type = \"entropy\",\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert)\n# Calculate the uncertainty cube\nnew_samples <- sits_uncertainty_sampling(\n  uncert_cube = s2_cube_uncert,\n  n = 20,\n  min_uncert = 0.5,\n  sampling_window = 10\n)\n\n# View the location of the samples\nsits_view(new_samples)\n# Label the new samples\nnew_samples$label <- \"Wetland\"\n# Obtain the time series from the regularized cube\nnew_samples_ts <- sits_get_data(\n  cube = s2_reg_cube_ro,\n  samples = new_samples\n)\n\n# Join the new samples with the original ones with 4 classes\nsamples_4classes_3bands_round_2 <- dplyr::bind_rows(\n  samples_4classes_3bands,\n  new_samples_ts\n)\n\n# Train a lightTAE model with the new sample set\nltae_model_v2 <- sits_train(\n  samples = samples_4classes_3bands_round_2,\n  ml_method = sits_lighttae()\n)\n\n# Classify the small area cube\ns2_cube_probs_v2 <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = ltae_model_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Post-process the probability cube\ns2_cube_bayes_v2 <- sits_smooth(\n  cube = s2_cube_probs_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the post-processed  probability cube\ns2_cube_label_v2 <- sits_label_classification(\n  cube = s2_cube_bayes_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Plot the second version of the classified cube\nplot(s2_cube_label_v2)\n# Calculate the uncertainty cube\ns2_cube_uncert_v2 <- sits_uncertainty(\n  cube = s2_cube_bayes_v2,\n  type = \"entropy\",\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert_v2)"},{"path":"ensemble-prediction-from-multiple-models.html","id":"ensemble-prediction-from-multiple-models","chapter":"Ensemble prediction from multiple models","heading":"Ensemble prediction from multiple models","text":"Ensemble prediction powerful technique combining predictions multiple models produce accurate robust predictions. general, ensemble predictions produce better predictions using single model. errors individual models can cancel reduced combined predictions models. result, ensemble predictions can lead better overall accuracy reduce risk overfitting. can especially useful working complex uncertain data. combining predictions multiple models, users can identify features factors important making accurate predictions. using ensemble methods, choosing diverse models different sources error important ensure ensemble predictions accurate robust.sits package provides sits_combine_predictions() estimate ensemble predictions using probability cubes produced sits_classify() optionally post-processed sits_smooth(). two ways make ensemble predictions multiple models:Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely ones valid.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely ones valid.follows, use data used Chapter Image classification data cubes illustrate produce ensemble prediction. simplicity, repeat steps taken classify image Chapter: create data cube, train model using lightweight temporal attention encoder algorithm (sits_lighttae()), classify, post-process, label data cube. starting point, plot two instances data cube start end time series.\nFigure 90: Color composite image date 2020-07-06 (Source: Authors).\nimage 2020-07-06 shows many areas deforestation, especially large one located top center image. helpful compare image one year later, shows several burned areas resulting forest removal followed fire.\nFigure 91: Color composite image date 2021-08-10 (Source: Authors).\nsamples used classification used Chapter Image classification data cubes. Please refer chapter detailed description temporal response samples. first reproduce result obtained Chapter using sits_tempcnn().\nFigure 92: Image Classification using TempCNN model (Source: Authors).\ndeforestation map produced sits_tempcnn() spatial consistency; arguably, underestimates burned areas right-hand corner image. method tries model temporal behavior reflectances. reason, sometimes fails detect changes last dates time series, occurs areas burned August.build two-member ensemble, now classify image using random forest.\nFigure 93: Land classification Rondonia using random forest algorithm (Source: Authors).\nComparing two results, land areas classified equally, places disagreement concerning places classified “Burned_Area” “Highly_Degraded”. Since random forest model sensitive response images end period, tends better distinguish burned areas. However, tends reduce forest areas, classifying highly degraded. misclassification happens random forest algorithm disregards temporal correlation input data. Values single date used distinguish natural degraded forest areas.Given differences complementaries two predicted outcomes, combining using sits_combine_predictions() useful. first option ensemble prediction take average probability maps reduce noise.\nFigure 94: Land classification Rondonia near Samuel dam using average probabilities produced lightTAE tempCNN algorithms (Source: Authors).\nCompared initial map, result increased number pixels classified burned areas highly degraded. areas classified degraded forest random forest method included final map. places random forest high confidence included. average map generally results better classification individual results.Overall, ensemble predictions powerful tool improving accuracy robustness machine learning models. combining predictions multiple models, can reduce errors uncertainty gain new insights underlying patterns data.","code":"\n# Files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LKP/\", package = \"sitsdata\")\n# Read data cube\nro_cube_20LKP <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\"X1\", \"tile\", \"band\", \"date\")\n)\n\nplot(ro_cube_20LKP,\n  date = \"2020-07-06\",\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\"\n)\nplot(ro_cube_20LKP,\n  date = \"2021-08-10\",\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\"\n)\n# Get the samples from library \"sitsdata\"\nlibrary(sitsdata)\ndata(samples_prodes_4classes)\n# Use only the bands available in the cube\nsamples_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = sits_bands(ro_cube_20LKP)\n)\n# Train model using LightTAE algorithm\ntcnn_model <- sits_train(\n  samples = samples_3bands,\n  ml_method = sits_tempcnn(\n    opt_hparams = list(lr = 0.001)\n  )\n)\n# Classify data cube\nro_cube_probs_tcnn <- sits_classify(\n  data = ro_cube_20LKP,\n  ml_model = tcnn_model,\n  output_dir = \"./tempdir/chp13\",\n  version = \"tcnn\",\n  multicores = 4,\n  memsize = 12\n)\n# Smooth data cube\nro_cube_bayes_tcnn <- sits_smooth(\n  cube = ro_cube_probs_tcnn,\n  output_dir = \"./tempdir/chp13\",\n  version = \"tcnn\",\n  multicores = 4,\n  memsize = 12\n)\n# Generate a thematic map\ndefor_map_tcnn <- sits_label_classification(\n  cube = ro_cube_bayes_tcnn,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp12\",\n  version = \"tcnn\"\n)\nplot(defor_map_tcnn)\n# Train model using random forest algorithm\nrfor_model <- sits_train(\n  samples = samples_3bands,\n  ml_method = sits_rfor()\n)\n# Classify the data cube using the tempCNN model\nro_cube_probs_rfor <- sits_classify(\n  data = ro_cube_20LKP,\n  ml_model = rfor_model,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n# Post-process the probability cube\nro_cube_bayes_rfor <- sits_smooth(\n  cube = ro_cube_probs_rfor,\n  output_dir = \"./tempdir/chp13/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n# Label the post-processed  probability cube\nro_cube_label_rfor <- sits_label_classification(\n  cube = ro_cube_bayes_rfor,\n  output_dir = \"./tempdir/chp13/\",\n  version = \"rfor\",\n  memsize = 16,\n  multicores = 4\n)\n# Plot the random forest version of the classified cube\nplot(ro_cube_label_rfor)\n# Combine the two predictions by taking the average of the probabilities for each class\ns2_cube_average_probs <- sits_combine_predictions(\n  cubes = list(ro_cube_bayes_tcnn, ro_cube_bayes_rfor),\n  type = \"average\",\n  output_dir = \"./tempdir/chp13/\",\n  version = \"average\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the average probability cube\ns2_cube_average_class <- sits_label_classification(\n  cube = s2_cube_average_probs,\n  output_dir = \"./tempdir/chp13/\",\n  version = \"average\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Plot the second version of the classified cube\nplot(s2_cube_average_class)"},{"path":"visualising-and-exporting-data.html","id":"visualising-and-exporting-data","chapter":"Visualising and exporting data","heading":"Visualising and exporting data","text":"Chapter intended programmers experts like extend capabilities sits including new data sources, machine learning algorithms, exporting data used Python QGIS, including new display colors.","code":""},{"path":"visualising-and-exporting-data.html","id":"how-colors-work-in-sits","chapter":"Visualising and exporting data","heading":"How colors work in sits","text":"examples provided book, color legend taken predefined color table provided sits. default color table displayed using sits_colors_show(). color definition file assigns colors 99 class names, including IPCC IGBP land classes.\nFigure 95: Default colors used sits package (Source: Authors).\ncolor table can extended adjusted accessing modifying default color table, retrieved using sits_colors().default color table can redefined using sits_colors_set(). example user-defined color table, consider definition covers level 1 Anderson Classification System used US National Land Cover Data, obtained defining new color table, shown . colors can defined HEX values names accepted R color codes.\nFigure 96: Example Anderson Land Classification Scheme use sits (Source: Authors).\noriginal default sits color table can restored using sits_colors_reset().alternative, legend can used directly parameter plot(). Please see example provided Section “Map Reclassification” Chapter Image classification data cubes.","code":"\n# Retrieve the color table\ncolor_tb <- sits_colors()\n# Show the color table\ncolor_tb#> # A tibble: 99 × 3\n#>    name                       color   group          \n#>    <chr>                      <chr>   <chr>          \n#>  1 Evergreen_Broadleaf_Forest #1E8449 Tropical_Forest\n#>  2 Forest                     #1E8449 Tropical_Forest\n#>  3 Closed_Forest              #1E8449 Tropical_Forest\n#>  4 Woodland                   #27AE60 Tropical_Forest\n#>  5 Dense_Woodland             #27AE60 Tropical_Forest\n#>  6 Woody_Savanna              #27AE60 Tropical_Forest\n#>  7 Open_Forest                #27AE60 Tropical_Forest\n#>  8 Cerradao                   #27AE60 Tropical_Forest\n#>  9 Mixed_Forest               #27AE60 Tropical_Forest\n#> 10 Sparse_Forest              #27AE60 Tropical_Forest\n#> # ℹ 89 more rows\n# Define a color table based on the Anderson Land Classification System\nus_nlcd <- tibble::tibble(name = character(), color = character())\nus_nlcd <- us_nlcd %>%\n  tibble::add_row(name = \"Urban Built Up\", color = \"#85929E\") %>%\n  tibble::add_row(name = \"Agricultural Land\", color = \"#F0B27A\") %>%\n  tibble::add_row(name = \"Rangeland\", color = \"#F1C40F\") %>%\n  tibble::add_row(name = \"Forest Land\", color = \"#27AE60\") %>%\n  tibble::add_row(name = \"Water\", color = \"#2980B9\") %>%\n  tibble::add_row(name = \"Wetland\", color = \"#D4E6F1\") %>%\n  tibble::add_row(name = \"Barren Land\", color = \"#FDEBD0\") %>%\n  tibble::add_row(name = \"Tundra\", color = \"#EBDEF0\") %>%\n  tibble::add_row(name = \"Snow and Ice\", color = \"#F7F9F9\")\n# Load the color table into `sits`\nsits_colors_set(us_nlcd)\n# Show the new color table used by sits\nsits_colors_show()"},{"path":"visualising-and-exporting-data.html","id":"exporting-data-to-json","chapter":"Visualising and exporting data","heading":"Exporting data to JSON","text":"data cube time series tibble can exported exchange formats JSON.","code":"\nlibrary(jsonlite)\n# Export the data cube to JSON\njsonlite::write_json(\n  x = s2_20LKP_cube_MPC,\n  path = \"./data_cube.json\",\n  pretty = TRUE\n)\n\n# Export the time series to JSON\njsonlite::write_json(\n  x = samples_prodes_4classes,\n  path = \"./time_series.json\",\n  pretty = TRUE\n)"},{"path":"technical-annex.html","id":"technical-annex","chapter":"Technical Annex","heading":"Technical Annex","text":"Chapter contains technical details algorithms available sits. intended support want understand package works also want contribute development.","code":""},{"path":"technical-annex.html","id":"including-new-methods-for-machine-learning","chapter":"Technical Annex","heading":"Including new methods for machine learning","text":"section provides guidance experts want include new methods machine learning work connection sits. discussion assumes familiarity R language. Developers consult Hadley Wickham’s excellent book “Advanced R” (https://adv-r.hadley.nz/), especially Chapter 10 “Function Factories”.machine learning deep learning algorithm sits follow logic; models created sits_train() function. function two parameters: () samples, set time series training samples; (b) ml_method, function fits model input data. result function passed sits_classify() classify time series data cubes. structure sits_train() simple, shown .R terms, sits_train() function factory, function makes functions. behaviour possible functions first-class objects R. words, can bound name way variables . second propriety R functions capture (enclose) environment created. words, function returned result another function, internal variables used create function available inside environment. programming language, technique called “closure”.sits, properties closures used basis making training classification independent. return sits_train() model contains information classify input values, well information samples used train model.ensure models work fashion, machine learning functions sits also share data structure prediction. data structure created sits_predictors() function, transforms time series tibble set values suitable using training data, shown following example.predictors tibble organized combination “X” “Y” values used machine learning algorithms. first two columns sample_id label. columns contain data values, organized band time. machine learning methods time-sensitive, random forest, organization sufficient training. case time-sensitive methods tempCNN, arrangements necessary ensure tensors right dimensions. Please refer sits_tempcnn() source code example adapt prediction table appropriate torch tensor.algorithms require data normalization. Therefore, sits_predictors code usually combined methods extract statistical information normalize data, example .following example shows implementation LightGBM algorithm, designed efficiently handle large-scale datasets perform fast training inference [Ke2017]. Gradient boosting machine learning technique builds ensemble weak prediction models, typically decision trees, create stronger model. LightGBM specifically focuses optimizing training prediction speed, making particularly suitable large datasets. example builds model using lightgbm package. function applied later obtain classification.Since lightGBM gradient boosting model, uses part data testing. data improve model’s performance. split training test samples controlled parameter, shown following code extract.parameters lightgbm algorithm, defined documentation, : () boosting_type, boosting algorithm; (b) objective, classification objectivel (c) num_iterations, number run; (d) max_depth, maximum tree depth; (d) min_samples_leaf, minimum size data one leaf (avoid overfitting); (f) learning_rate, learning rate algorithm; (g) n_iter_no_change, number sucessive iterations stop training validation metrics don’t improve; (h) validation_split, fraction training data used validation data.training part lightgbm algorithm uses two functions: () lgb.Dataset, transforms training test samples internal structures; (b) lgb.train, trains model.code two nested functions: results_fun() predict_fun(). lightgbm_method() function called, transforms input samples predictors, normalizes . , uses predictors train algorithm, creating model (result_mlr). model included part function’s closure becomes available classification time. code creates prediction_fun(), applies result_mlr model input values classified. function returned results_fun contains necessary information classification. classification time, model called directly.last lines code also includes convenience function sits_factory_function(), shown . function allows model called either part sits_train() called independently, result.one additional requirement algorithm compatible sits. Data cube processing algorithms sits run parallel. reason, classification model trained, serialized, shown following line. serialized version model exported function closure, can used classification time.classification, predict_fun() called parallel CPU. moment, serialized string transformed back model, run obtain classification, shown code.Therefore, using function factories produce closures, sits keeps classification function independent ML/DL algorithm. policy allows independent proposal, testing development new classification methods. also enables improvements parallel processing methods without affecting existing classification methods.illustrate separation training classification, new algorithm developed chapter using lightgbm used classify data cube. code one Chapter Introduction example data cube classification, except use lightgbm method.\nFigure 97: Classification map Sinop using LightGBM.\nexample shows possible extend sits new ML/DL algorithms.","code":"\nsits_train <- function(samples, ml_method) {\n  # train a ml classifier with the given data\n  result <- ml_method(samples)\n  # return a valid machine learning method\n  return(result)\n}\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\npred <- sits_predictors(samples_matogrosso_mod13q1)\npred#> # A tibble: 1,892 × 94\n#>    sample_id label   NDVI1 NDVI2 NDVI3 NDVI4 NDVI5 NDVI6 NDVI7 NDVI8 NDVI9 NDVI10 NDVI11 NDVI12\n#>        <int> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n#>  1         1 Pasture 0.500 0.485 0.716 0.654 0.591 0.662 0.734 0.739 0.768  0.797  0.798  0.776\n#>  2         2 Pasture 0.364 0.484 0.605 0.726 0.778 0.829 0.762 0.762 0.643  0.610  0.578  0.596\n#>  3         3 Pasture 0.577 0.674 0.639 0.569 0.596 0.623 0.650 0.650 0.637  0.646  0.655  0.664\n#>  4         4 Pasture 0.597 0.699 0.789 0.792 0.794 0.72  0.646 0.705 0.757  0.810  0.757  0.769\n#>  5         5 Pasture 0.388 0.491 0.527 0.660 0.677 0.746 0.816 0.816 0.825  0.835  0.844  0.854\n#>  6         6 Pasture 0.350 0.345 0.364 0.429 0.506 0.583 0.660 0.616 0.580  0.651  0.620  0.633\n#>  7         7 Pasture 0.490 0.527 0.543 0.583 0.594 0.605 0.616 0.627 0.622  0.644  0.666  0.688\n#>  8         8 Pasture 0.435 0.574 0.395 0.392 0.518 0.597 0.648 0.774 0.786  0.798  0.811  0.823\n#>  9         9 Pasture 0.396 0.473 0.542 0.587 0.649 0.697 0.696 0.695 0.699  0.703  0.714  0.726\n#> 10        10 Pasture 0.354 0.387 0.527 0.577 0.626 0.723 0.655 0.655 0.646  0.536  0.544  0.551\n#> # ℹ 1,882 more rows\n#> # ℹ 80 more variables: NDVI13 <dbl>, NDVI14 <dbl>, NDVI15 <dbl>, NDVI16 <dbl>, NDVI17 <dbl>,\n#> #   NDVI18 <dbl>, NDVI19 <dbl>, NDVI20 <dbl>, NDVI21 <dbl>, NDVI22 <dbl>, NDVI23 <dbl>,\n#> #   EVI1 <dbl>, EVI2 <dbl>, EVI3 <dbl>, EVI4 <dbl>, EVI5 <dbl>, EVI6 <dbl>, EVI7 <dbl>,\n#> #   EVI8 <dbl>, EVI9 <dbl>, EVI10 <dbl>, EVI11 <dbl>, EVI12 <dbl>, EVI13 <dbl>, EVI14 <dbl>,\n#> #   EVI15 <dbl>, EVI16 <dbl>, EVI17 <dbl>, EVI18 <dbl>, EVI19 <dbl>, EVI20 <dbl>, EVI21 <dbl>,\n#> #   EVI22 <dbl>, EVI23 <dbl>, NIR1 <dbl>, NIR2 <dbl>, NIR3 <dbl>, NIR4 <dbl>, NIR5 <dbl>, …\n# Data normalization\nml_stats <- sits_stats(samples)\n# extract the training samples\ntrain_samples <- sits_predictors(samples)\n# normalize the training samples\ntrain_samples <- sits_pred_normalize(pred = train_samples, stats = ml_stats)\n# split the data into training and validation data sets\n# create partitions different splits of the input data\ntest_samples <- sits_pred_sample(train_samples,\n  frac = validation_split\n)\n# Remove the lines used for validation\nsel <- !(train_samples$sample_id %in% test_samples$sample_id)\ntrain_samples <- train_samples[sel, ]\n# install \"nnet\" package if not available\nif (!require(\"lightgbm\")) install.packages(\"lightgbm\")\n# create a function in sits style for lightGBM algorithm\nlgb_method <- function(samples = NULL,\n                       boosting_type = \"gbdt\",\n                       objective = \"multiclass\",\n                       min_samples_leaf = 10,\n                       max_depth = 6,\n                       learning_rate = 0.1,\n                       num_iterations = 100,\n                       n_iter_no_change = 10,\n                       validation_split = 0.2, ...) {\n  # function that returns MASS::lda model based on a sits sample tibble\n  result_fun <- function(samples) {\n    # Data normalization\n    ml_stats <- sits_stats(samples)\n    train_samples <- sits_predictors(samples)\n    train_samples <- sits_pred_normalize(pred = train_samples, stats = ml_stats)\n\n    # find number of labels\n    labels <- sits_labels(samples)\n    n_labels <- length(labels)\n    # lightGBM uses numerical labels starting from 0\n    int_labels <- c(1:n_labels) - 1\n    # create a named vector with integers match the class labels\n    names(int_labels) <- labels\n\n    # add number of classes to lightGBM params\n    # split the data into training and validation data sets\n    # create partitions different splits of the input data\n    test_samples <- sits_pred_sample(train_samples,\n      frac = validation_split\n    )\n\n    # Remove the lines used for validation\n    sel <- !(train_samples$sample_id %in% test_samples$sample_id)\n    train_samples <- train_samples[sel, ]\n\n    # transform the training data to LGBM dataset\n    lgbm_train_samples <- lightgbm::lgb.Dataset(\n      data = as.matrix(train_samples[, -2:0]),\n      label = unname(int_labels[train_samples[[2]]])\n    )\n    # transform the test data to LGBM dataset\n    lgbm_test_samples <- lightgbm::lgb.Dataset(\n      data = as.matrix(test_samples[, -2:0]),\n      label = unname(int_labels[test_samples[[2]]])\n    )\n    # set the parameters for the lightGBM training\n    lgb_params <- list(\n      boosting_type = boosting_type,\n      objective = objective,\n      min_samples_leaf = min_samples_leaf,\n      max_depth = max_depth,\n      learning_rate = learning_rate,\n      num_iterations = num_iterations,\n      n_iter_no_change = n_iter_no_change,\n      num_class = n_labels\n    )\n    # call method and return the trained model\n    lgbm_model <- lightgbm::lgb.train(\n      data    = lgbm_train_samples,\n      valids  = list(test_data = lgbm_test_samples),\n      params  = lgb_params,\n      verbose = -1,\n      ...\n    )\n    # serialize the model for parallel processing\n    lgbm_model_string <- lgbm_model$save_model_to_string(NULL)\n    # construct model predict closure function and returns\n    predict_fun <- function(values) {\n      # reload the model (unserialize)\n      lgbm_model <- lightgbm::lgb.load(model_str = lgbm_model_string)\n      # Performs data normalization - returns only values\n      # in the prediction only values are available\n      values <- sits_pred_normalize(pred = values, stats = ml_stats)\n      # predict probabilities\n      prediction <- stats::predict(lgbm_model,\n        data = as.matrix(values),\n        rawscore = FALSE,\n        reshape = TRUE\n      )\n      # adjust the names of the columns of the probs\n      colnames(prediction) <- labels\n      # retrieve the prediction results\n      return(prediction)\n    }\n    # Set model class\n    class(predict_fun) <- c(\"sits_model\", class(predict_fun))\n    return(predict_fun)\n  }\n  result <- sits_factory_function(samples, result_fun)\n  return(result)\n}\nsits_factory_function <- function(samples, fun) {\n  # if no data is given, we prepare a\n  # function to be called as a parameter of other functions\n  if (purrr::is_null(data)) {\n    result <- fun\n  } else {\n    # ...otherwise compute the result on the input data\n    result <- fun(data)\n  }\n  return(result)\n}\n# serialize the model for parallel processing\nlgbm_model_string <- lgbm_model$save_model_to_string(NULL)\n# unserialize the model\nlgbm_model <- lightgbm::lgb.load(model_str = lgbm_model_string)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\n# Create a data cube using local files\nsinop <- sits_cube(\n  source = \"BDC\",\n  collection = \"MOD13Q1-6\",\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),\n  parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\")\n)\n# The data cube has only \"NDVI\" and \"EVI\" bands\n# Select the bands NDVI and EVI\nsamples_2bands <- sits_select(\n  data = samples_matogrosso_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n# train lightGBM model\nlgb_model <- sits_train(samples_2bands, lgb_method())\n\n# Classify the data cube\nsinop_probs <- sits_classify(\n  data = sinop,\n  ml_model = lgb_model,\n  multicores = 1,\n  memsize = 8,\n  output_dir = \"./tempdir/chp15\"\n)\n# Perform spatial smoothing\nsinop_bayes <- sits_smooth(\n  cube = sinop_probs,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp15\"\n)\n# Label the smoothed file\nsinop_map <- sits_label_classification(\n  cube = sinop_bayes,\n  output_dir = \"./tempdir/chp3\"\n)\n# plot the result\nplot(sinop_map, title = \"Sinop Classification Map\")"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
