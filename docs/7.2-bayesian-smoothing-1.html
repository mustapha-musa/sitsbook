<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.2 Bayesian smoothing | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes" />
<meta property="og:type" content="book" />
<meta property="og:image" content="/images/cover_sits_book.png" />
<meta property="og:description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes." />


<meta name="author" content="Gilberto Camara" />
<meta name="author" content="Rolf Simoes" />
<meta name="author" content="Felipe Souza" />
<meta name="author" content="Charlotte Peletier" />
<meta name="author" content="Alber Sanchez" />
<meta name="author" content="Pedro R. Andrade" />
<meta name="author" content="Karine Ferreira" />
<meta name="author" content="Gilberto Queiroz" />

<meta name="date" content="2022-07-15" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book presents sits, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classifying image time series obtained from Earth observation data cubes.">

<title>7.2 Bayesian smoothing | sits: Satellite Image Time Series Analysis on Earth Observation Data Cubes</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a>
<ul>
<li><a href="who-this-book-is-for.html#who-this-book-is-for">Who this book is for</a></li>
<li><a href="main-reference-for-sits.html#main-reference-for-sits">Main reference for sits</a></li>
</ul></li>
<li class="has-sub"><a href="setup.html#setup">Setup</a>
<ul>
<li><a href="support-for-gdal-and-proj.html#support-for-gdal-and-proj">Support for GDAL and PROJ</a></li>
<li><a href="installing-the-sits-package.html#installing-the-sits-package">Installing the <code>sits</code> package</a></li>
</ul></li>
<li class="has-sub"><a href="acknowledgements.html#acknowledgements">Acknowledgements</a>
<ul>
<li><a href="funding-sources.html#funding-sources">Funding Sources</a></li>
<li><a href="community-contributions.html#community-contributions">Community Contributions</a></li>
<li><a href="reproducible-papers-used-in-building-sits.html#reproducible-papers-used-in-building-sits">Reproducible papers used in building sits</a></li>
<li><a href="publications-using-sits.html#publications-using-sits">Publications using sits</a></li>
</ul></li>
<li class="has-sub"><a href="1-introduction-to-sits.html#introduction-to-sits"><span class="toc-section-number">1</span> Introduction to SITS</a>
<ul>
<li><a href="how-sits-works.html#how-sits-works">How <code>sits</code> works</a></li>
<li><a href="creating-a-data-cube.html#creating-a-data-cube">Creating a Data Cube</a></li>
<li><a href="the-time-series-table.html#the-time-series-table">The time series table</a></li>
<li><a href="training-a-machine-learning-model.html#training-a-machine-learning-model">Training a machine learning model</a></li>
<li><a href="data-cube-classification.html#data-cube-classification">Data cube classification</a></li>
<li><a href="spatial-smoothing.html#spatial-smoothing">Spatial smoothing</a></li>
<li><a href="labelling-a-probability-data-cube.html#labelling-a-probability-data-cube">Labelling a probability data cube</a></li>
<li><a href="final-remarks.html#final-remarks">Final remarks</a></li>
</ul></li>
<li class="has-sub"><a href="2-earth-observation-data-cubes.html#earth-observation-data-cubes"><span class="toc-section-number">2</span> Earth observation data cubes</a>
<ul>
<li><a href="analysis-ready-data-image-collections.html#analysis-ready-data-image-collections">Analysis-ready data image collections</a></li>
<li><a href="ard-image-collections-handled-by-sits.html#ard-image-collections-handled-by-sits">ARD image collections handled by sits</a></li>
<li><a href="regular-image-data-cubes.html#regular-image-data-cubes">Regular image data cubes</a></li>
<li><a href="creating-data-cubes.html#creating-data-cubes">Creating data cubes</a></li>
<li><a href="assessing-amazon-web-services.html#assessing-amazon-web-services">Assessing Amazon Web Services</a></li>
<li><a href="assessing-microsofts-planetary-computer.html#assessing-microsofts-planetary-computer">Assessing Microsoft’s Planetary Computer</a></li>
<li><a href="assessing-digital-earth-africa.html#assessing-digital-earth-africa">Assessing Digital Earth Africa</a></li>
<li><a href="assessing-the-brazil-data-cube.html#assessing-the-brazil-data-cube">Assessing the Brazil Data Cube</a></li>
<li><a href="defining-a-data-cube-using-ard-local-files.html#defining-a-data-cube-using-ard-local-files">Defining a data cube using ARD local files</a></li>
<li><a href="defining-a-data-cube-using-classified-images.html#defining-a-data-cube-using-classified-images">Defining a data cube using classified images</a></li>
<li><a href="regularizing-data-cubes.html#regularizing-data-cubes">Regularizing data cubes</a></li>
<li><a href="mathematical-operations-on-regular-data-cubes.html#mathematical-operations-on-regular-data-cubes">Mathematical operations on regular data cubes</a></li>
</ul></li>
<li class="has-sub"><a href="3-working-with-time-series.html#working-with-time-series"><span class="toc-section-number">3</span> Working with time series</a>
<ul>
<li><a href="data-structures-for-satellite-time-series.html#data-structures-for-satellite-time-series">Data structures for satellite time series</a></li>
<li><a href="utilities-for-handling-time-series.html#utilities-for-handling-time-series">Utilities for handling time series</a></li>
<li><a href="time-series-visualisation.html#time-series-visualisation">Time series visualisation</a></li>
<li><a href="obtaining-time-series-data-from-data-cubes.html#obtaining-time-series-data-from-data-cubes">Obtaining time series data from data cubes</a></li>
<li class="has-sub"><a href="filtering-techniques-for-time-series.html#filtering-techniques-for-time-series">Filtering techniques for time series</a>
<ul>
<li><a href="filtering-techniques-for-time-series.html#savitzkygolay-filter">Savitzky–Golay filter</a></li>
<li><a href="filtering-techniques-for-time-series.html#whittaker-filter">Whittaker filter</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-improving-the-quality-of-training-samples.html#improving-the-quality-of-training-samples"><span class="toc-section-number">4</span> Improving the Quality of Training Samples</a>
<ul>
<li><a href="introduction.html#introduction">Introduction</a></li>
<li><a href="hierachical-clustering-for-sample-quality-control.html#hierachical-clustering-for-sample-quality-control">Hierachical clustering for sample quality control</a></li>
<li class="has-sub"><a href="using-self-organizing-maps-for-sample-quality-control.html#using-self-organizing-maps-for-sample-quality-control">Using self-organizing maps for sample quality control</a>
<ul>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-creating-the-som-map">SOM-based quality assessment: creating the SOM map</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-measuring-confusion-between-labels">SOM-based quality assessment: measuring confusion between labels</a></li>
<li><a href="using-self-organizing-maps-for-sample-quality-control.html#som-based-quality-assessment-part-3-using-probabilities-to-detect-noisy-samples">SOM-based quality assessment part 3: using probabilities to detect noisy samples</a></li>
</ul></li>
<li><a href="reducing-sample-imbalance.html#reducing-sample-imbalance">Reducing sample imbalance</a></li>
<li><a href="conclusion.html#conclusion">Conclusion</a></li>
</ul></li>
<li class="has-sub"><a href="5-machine-learning-for-data-cubes-using-the-sits-package.html#machine-learning-for-data-cubes-using-the-sits-package"><span class="toc-section-number">5</span> Machine Learning for Data Cubes using the SITS package</a>
<ul>
<li><a href="machine-learning-classification.html#machine-learning-classification">Machine learning classification</a></li>
<li><a href="visualizing-sample-patterns.html#visualizing-sample-patterns">Visualizing Sample Patterns</a></li>
<li><a href="common-interface-to-machine-learning-and-deep-learning-models.html#common-interface-to-machine-learning-and-deep-learning-models">Common interface to machine learning and deep learning models</a></li>
<li><a href="random-forests.html#random-forests">Random forests</a></li>
<li><a href="support-vector-machines.html#support-vector-machines">Support Vector Machines</a></li>
<li><a href="extreme-gradient-boosting.html#extreme-gradient-boosting">Extreme Gradient Boosting</a></li>
<li><a href="deep-learning-using-multilayer-perceptrons.html#deep-learning-using-multilayer-perceptrons">Deep learning using multilayer perceptrons</a></li>
<li><a href="temporal-convolutional-neural-network-tempcnn.html#temporal-convolutional-neural-network-tempcnn">Temporal Convolutional Neural Network (TempCNN)</a></li>
<li><a href="residual-1d-cnn-networks-resnet.html#residual-1d-cnn-networks-resnet">Residual 1D CNN Networks (ResNet)</a></li>
<li><a href="attention-based-models.html#attention-based-models">Attention-based models</a></li>
<li><a href="model-tuning.html#model-tuning">Model tuning</a></li>
<li><a href="considerations-on-model-choice.html#considerations-on-model-choice">Considerations on model choice</a></li>
</ul></li>
<li class="has-sub"><a href="classification-of-images-in-data-cubes-using-satellite-image-time-series.html#classification-of-images-in-data-cubes-using-satellite-image-time-series">Classification of Images in Data Cubes using Satellite Image Time Series</a>
<ul>
<li><a href="training-the-classification-model.html#training-the-classification-model">Training the classification model</a></li>
<li><a href="building-the-data-cube.html#building-the-data-cube">Building the data cube</a></li>
<li><a href="classification-using-parallel-processing.html#classification-using-parallel-processing">Classification using parallel processing</a></li>
<li class="has-sub"><a href="post-classification-smoothing.html#post-classification-smoothing">Post-classification smoothing</a>
<ul>
<li><a href="post-classification-smoothing.html#bayesian-smoothing">Bayesian smoothing</a></li>
</ul></li>
<li class="has-sub"><a href="bilateral-smoothing.html#bilateral-smoothing">Bilateral smoothing</a>
<ul>
<li><a href="bilateral-smoothing.html#how-parallel-processing-works-in-sits"><span class="toc-section-number">5.0.1</span> How parallel processing works in <code class="unnumbered">sits</code></a></li>
<li><a href="bilateral-smoothing.html#processing-time-estimates">Processing time estimates</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="6-validation-and-accuracy-measurements-in-sits.html#validation-and-accuracy-measurements-in-sits"><span class="toc-section-number">6</span> Validation and accuracy measurements in SITS</a>
<ul>
<li><a href="6.1-case-study-used-in-this-chapter.html#case-study-used-in-this-chapter"><span class="toc-section-number">6.1</span> Case study used in this Chapter</a></li>
<li><a href="6.2-validation-techniques.html#validation-techniques"><span class="toc-section-number">6.2</span> Validation techniques</a></li>
<li><a href="6.3-comparing-different-machine-learning-methods-using-k-fold-validation.html#comparing-different-machine-learning-methods-using-k-fold-validation"><span class="toc-section-number">6.3</span> Comparing different machine learning methods using k-fold validation</a></li>
<li class="has-sub"><a href="6.4-accuracy-assessment.html#accuracy-assessment"><span class="toc-section-number">6.4</span> Accuracy assessment</a>
<ul>
<li><a href="6.4-accuracy-assessment.html#time-series"><span class="toc-section-number">6.4.1</span> Time series</a></li>
<li><a href="6.4-accuracy-assessment.html#classified-images"><span class="toc-section-number">6.4.2</span> Classified images</a></li>
</ul></li>
</ul></li>
<li><a href="uncertainty-and-active-learning.html#uncertainty-and-active-learning">Uncertainty and active learning</a></li>
<li class="has-sub"><a href="7-design-and-extensibility-considerations.html#design-and-extensibility-considerations"><span class="toc-section-number">7</span> Design and extensibility considerations</a>
<ul>
<li><a href="7.1-design-decisions.html#design-decisions"><span class="toc-section-number">7.1</span> Design decisions</a></li>
</ul></li>
<li class="has-sub"><a href="technical-annex.html#technical-annex">Technical Annex</a>
<ul>
<li class="has-sub"><a href="7.2-bayesian-smoothing-1.html#bayesian-smoothing-1"><span class="toc-section-number">7.2</span> Bayesian smoothing</a>
<ul>
<li><a href="7.2-bayesian-smoothing-1.html#derivation-of-bayesian-parameters-for-spatiotemporal-smoothing"><span class="toc-section-number">7.2.1</span> Derivation of bayesian parameters for spatiotemporal smoothing</a></li>
</ul></li>
<li><a href="7.3-bilateral-smoothing-1.html#bilateral-smoothing-1"><span class="toc-section-number">7.3</span> Bilateral smoothing</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="bayesian-smoothing-1" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Bayesian smoothing</h2>
<p>Doing post-processing using Bayesian smoothing in SITS is straightforward. The result of the <code>sits_classify</code> function applied to a data cube is set of probability images, one per class. The next step is to apply the <code>sits_smooth</code> function. By default, this function selects the most likely class for each pixel considering only the probabilities of each class for each pixel. To allow for Bayesian smoothing, it suffices to include the <code>type = bayesian</code> parameter (which is also the default). If desired, the <code>smoothness</code> parameter (associated to the hyperparameter <span class="math inline">\(\sigma^2_k\)</span> described above) can control the degree of smoothness. If so desired, the <code>smoothness</code> parameter can also be expressed as a matrix.</p>
<p>In the case of continuous probability distributions, Bayesian inference is expressed by the rule:</p>
<p><span class="math display">\[
\pi(\theta|x) \propto \pi(x|\theta)\pi(\theta)
\]</span></p>
<p>Bayesian inference involves the estimation of an unknown parameter <span class="math inline">\(\theta\)</span>, which is the random variable that describe what we are trying to measure. In the case of smoothing of image classification, <span class="math inline">\(\theta\)</span> is the class probability for a given pixel. We model our initial belief about this value by a probability distribution, <span class="math inline">\(\pi(\theta)\)</span>, called the distribution. It represents what we know about <span class="math inline">\(\theta\)</span> observing the data. The distribution <span class="math inline">\(\pi(x|\theta)\)</span>, called the , is estimated based on the observed data. It represents the added information provided by our observations. The distribution <span class="math inline">\(\pi(\theta|x)\)</span> is our improved belief of <span class="math inline">\(\theta\)</span> seeing the data. Bayes’s rule states that the probability is proportional to the product of the and the probability.</p>
<div id="derivation-of-bayesian-parameters-for-spatiotemporal-smoothing" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Derivation of bayesian parameters for spatiotemporal smoothing</h3>
<p>In our post-classification smoothing model, we consider the output of a machine learning algorithm that provides the probabilities of each pixel in the image to belong to target classes. More formally, consider a set of <span class="math inline">\(K\)</span> classes that are candidates for labelling each pixel. Let <span class="math inline">\(p_{i,t,k}\)</span> be the probability of pixel <span class="math inline">\(i\)</span> belonging to class <span class="math inline">\(k\)</span>, <span class="math inline">\(k = 1, \dots, K\)</span> at a time <span class="math inline">\(t\)</span>, <span class="math inline">\(t=1,\dots{},T\)</span>. We have
<span class="math display">\[
\sum_{k=1}^K p_{i,t,k} = 1, p_{i,t,k} &gt; 0
\]</span>
We label a pixel <span class="math inline">\(p_i\)</span> as being of class <span class="math inline">\(k\)</span> if
<span class="math display">\[
    p_{i,t,k} &gt; p_{i,t,m}, \forall m = 1, \dots, K, m \neq k
\]</span></p>
<p>For each pixel <span class="math inline">\(i\)</span>, we take the odds of the classification for class <span class="math inline">\(k\)</span>, expressed as
<span class="math display">\[
    O_{i,t,k} = p_{i,t,k} / (1-p_{i,t,k})
\]</span>
where <span class="math inline">\(p_{i,t,k}\)</span> is the probability of class <span class="math inline">\(k\)</span> at time <span class="math inline">\(t\)</span>. We have more confidence in pixels with higher odds since their class assignment is stronger. There are situations, such as border pixels or mixed ones, where the odds of different classes are similar in magnitude. We take them as cases of low confidence in the classification result. To assess and correct these cases, Bayesian smoothing methods borrow strength from the neighbors and reduces the variance of the estimated class for each pixel.</p>
<p>We further make the transformation
<span class="math display">\[
    x_{i,t,k} = \log [O_{i,t,k}]
\]</span>
which measures the <em>logit</em> (log of the odds) associated to classifying the pixel <span class="math inline">\(i\)</span> as being of class <span class="math inline">\(k\)</span> at time <span class="math inline">\(t\)</span>. The support of <span class="math inline">\(x_{i,t,k}\)</span> is <span class="math inline">\(\mathbb{R}\)</span>. We can express the pixel data as a <span class="math inline">\(K\)</span>-dimensional multivariate logit vector</p>
<p><span class="math display">\[
\mathbf{x}_{i,t}=(x_{i,t,k_{0}},x_{i,t,k_{1}},\dots{},x_{i,t,k_{K}})
\]</span></p>
<p>For each pixel, the random variable that describes the class probability <span class="math inline">\(k\)</span> at time <span class="math inline">\(t\)</span> is denoted by <span class="math inline">\(\theta_{i,t,k}\)</span>. This formulation allows uses to use the class covariance matrix in our formulations. We can express Bayes’ rule for all combinations of pixel and classes for a time interval as</p>
<p><span class="math display">\[
\pi(\boldsymbol\theta_{i,t}|\mathbf{x}_{i,t}) \propto \pi(\mathbf{x}_{i,t}|\boldsymbol\theta_{i,t})\pi(\boldsymbol\theta_{i,t}).    
\]</span></p>
<p>We assume the conditional distribution <span class="math inline">\(\mathbf{x}_{i,t}|\boldsymbol\theta_{i,t}\)</span> follows a multivariate normal distribution</p>
<p><span class="math display">\[
    [\mathbf{x}_{i,t}|\boldsymbol\theta_{i,t}]\sim\mathcal{N}_{K}(\boldsymbol\theta_{i,t},\boldsymbol\Sigma_{i,t}),
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol\theta_{i,t}\)</span> is the mean parameter vector for the pixel <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span> is a known <span class="math inline">\(k\times{}k\)</span> covariance matrix that we will use as a parameter to control the level of smoothness effect. We will discuss later on how to estimate <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span>. To model our uncertainty about the parameter <span class="math inline">\(\boldsymbol\theta_{i,t}\)</span>, we will assume it also follows a multivariate normal distribution with hyper-parameters <span class="math inline">\(\mathbf{m}_{i,t}\)</span> for the mean vector, and <span class="math inline">\(\mathbf{S}_{i,t}\)</span> for the covariance matrix.</p>
<p><span class="math display">\[
    [\boldsymbol\theta_{i,t}]\sim\mathcal{N}_{K}(\mathbf{m}_{i,t}, \mathbf{S}_{i,t}).
\]</span></p>
<p>The above equation defines our prior distribution. The hyper-parameters <span class="math inline">\(\mathbf{m}_{i,t}\)</span> and <span class="math inline">\(\mathbf{S}_{i,t}\)</span> are obtained by considering the neighboring pixels of pixel <span class="math inline">\(i\)</span>. The neighborhood can be defined as any graph scheme (e.g. a given Chebyshev distance on the time-space lattice) and can include the referencing pixel <span class="math inline">\(i\)</span> as a neighbor. Also, it can make no reference to time steps other than <span class="math inline">\(t\)</span> defining a space-only neighborhood. More formally, let</p>
<p><span class="math display">\[
    \mathbf{V}_{i,t}=\{\mathbf{x}_{i_{j},t_{j}}\}_{j=1}^{N},
\]</span>
denote the <span class="math inline">\(N\)</span> logit vectors of a spatiotemporal neighborhood <span class="math inline">\(N\)</span> of pixel <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>. Then the prior mean is calculated by</p>
<p><span class="math display">\[
    \mathbf{m}_{i,t}=\operatorname{E}[\mathbf{V}_{i,t}],
\]</span></p>
<p>and the prior covariance matrix by</p>
<p><span class="math display">\[
    \mathbf{S}_{i,t}=\operatorname{E}\left[
      \left(\mathbf{V}_{i,t}-\mathbf{m}_{i,t}\right)
      \left(\mathbf{V}_{i,t}-\mathbf{m}_{i,t}\right)^\intercal
    \right].
\]</span></p>
<p>Since the likelihood and prior are multivariate normal distributions, the posterior will also be a multivariate normal distribution, whose updated parameters can be derived by applying the density functions associated to the above equations. The posterior distribution is given by</p>
<p><span class="math display">\[
    [\boldsymbol\theta_{i,t}|\mathbf{x}_{i,t}]\sim\mathcal{N}_{K}\left(
    (\mathbf{S}_{i,t}^{-1} + \boldsymbol\Sigma^{-1})^{-1}( \mathbf{S}_{i,t}^{-1}\mathbf{m}_{i,t} + \boldsymbol\Sigma^{-1} \mathbf{x}_{i,t}),
    (\mathbf{S}_{i,t}^{-1} + \boldsymbol\Sigma^{-1})^{-1}
    \right).
\]</span></p>
<p>The <span class="math inline">\(\boldsymbol\theta_{i,t}\)</span> parameter model is our initial belief about a pixel vector using the neighborhood information in the prior distribution. It represents what we know about the probable value of <span class="math inline">\(\mathbf{x}_{i,t}\)</span> (and hence, about the class probabilities as the logit function is a monotonically increasing function) observing it. The function <span class="math inline">\(P[\mathbf{x}_{i,t}|\boldsymbol\theta_{i,t}]\)</span> represents the added information provided by our observation of <span class="math inline">\(\mathbf{x}_{i,t}\)</span>. The probability density function <span class="math inline">\(P[\boldsymbol\theta_{i,t}|\mathbf{x}_{i,t}]\)</span> is our improved belief of the pixel vector seeing <span class="math inline">\(\mathbf{x}_{i,t}\)</span>.</p>
<p>At this point, we are able to infer a point estimator <span class="math inline">\(\hat{\boldsymbol\theta}_{i,t}\)</span> for the <span class="math inline">\(\boldsymbol\theta_{i,t}|\mathbf{x}_{i,t}\)</span> parameter. For the multivariate normal distribution, the posterior mean minimises not only the quadratic loss but the absolute and zero-one loss functions. It can be taken from the updated mean parameter of the posterior distribution which, after some algebra, can be expressed as</p>
<p><span class="math display">\[
    \hat{\boldsymbol{\theta}}_{i,t}=\operatorname{E}[\boldsymbol\theta_{i,t}|\mathbf{x}_{i,t}]=\boldsymbol\Sigma_{i,t}\left(\boldsymbol\Sigma_{i,t}+\mathbf{S}_{i,t}\right)^{-1}\mathbf{m}_{i,t} +
    \mathbf{S}_{i,t}\left(\boldsymbol\Sigma_{i,t}+\mathbf{S}_{i,t}\right)^{-1}\mathbf{x}_{i,t}.
\]</span></p>
<p>The estimator value for the logit vector <span class="math inline">\(\hat{\boldsymbol\theta}_{i,t}\)</span> is a weighted combination of the original logit vector <span class="math inline">\(\mathbf{x}_{i,t}\)</span> and the neighborhood mean vector <span class="math inline">\(\mathbf{m}_{i,t}\)</span>. The weights are given by the covariance matrix <span class="math inline">\(\mathbf{S}_{i,t}\)</span> of the prior distribution and the covariance matrix of the conditional distribution. The matrix <span class="math inline">\(\mathbf{S}_{i,t}\)</span> is calculated considering the spatiotemporal neighbors and the matrix <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span> corresponds to the smoothing factor provided as prior belief by the user.</p>
<p>When the values of local class covariance <span class="math inline">\(\mathbf{S}_{i,t}\)</span> are relative to the conditional covariance <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span>, our confidence on the influence of the neighbors is low, and the smoothing algorithm gives more weight to the original pixel value <span class="math inline">\(x_{i,k}\)</span>. When the local class covariance <span class="math inline">\(\mathbf{S}_{i,t}\)</span> decreases relative to the smoothness factor <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span>, then our confidence on the influence of the neighborhood increases. The smoothing procedure will be most relevant in situations where the original classification odds ratio is low, showing a low level of separability between classes. In these cases, the updated values of the classes will be influenced by the local class variances.</p>
<p>In practice, <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span> is a user-controlled covariance matrix parameter that will be set by users based on their knowledge of the region to be classified. In the simplest case, users can associate the conditional covariance <span class="math inline">\(\boldsymbol\Sigma_{i,t}\)</span> to a diagonal matrix, using only one hyperparameter <span class="math inline">\(\sigma^2_k\)</span> to set the level of smoothness. Higher values of <span class="math inline">\(\sigma^2_k\)</span> will cause the assignment of the local mean to the pixel updated probability. In our case, after some classification tests, we decided to <span class="math inline">\(\sigma^2_k=20\)</span> by default for all <span class="math inline">\(k\)</span>.</p>
</div>
</div>
<p style="text-align: center;">
<a href="technical-annex.html"><button class="btn btn-default">Previous</button></a>
<a href="7.3-bilateral-smoothing-1.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
