---
output:
  pdf_document: default
  html_document: default
---

# Introduction to `sits`{-}

```{r, include = FALSE}
source("common.R")
dir.create("./tempdir/chp3")
```

<a href="https://www.kaggle.com/esensing/introduction-to-sits" target="_blank"><img src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a>

## Why work with satellite image time series?{-}

Satellite images are the most comprehensive source of data about our environment.  Covering a large area of the Earth's surface, images allow researchers to study regional and global changes. Sensors capture data in multiple spectral bands to measure the physical, chemical, and biological properties of the Earth's surface. By observing the same location multiple times, satellites provide data on changes in the environment and survey areas that are difficult to observe from the ground. Given its unique features, images offer essential information for many applications, including deforestation, crop production, food security, urban footprints, water scarcity, and land degradation.

A time series is a set of data points collected at regular intervals over time. Time series data is used to analyze trends, patterns, and changes. Satellite image time series refer to time series obtained from a collection of images captured by a satellite over a period of time, typically months or years. 
<!---
PEDRO: 6) "weeks or months"?
-->
Using time series, experts improve their understanding of ecological patterns and processes. Instead of selecting individual images from specific dates and comparing them, researchers track change continuously [@Woodcock2020]. 

## Time-first, space-later{-}

"Time-first, space-later" is a concept in satellite image classification that takes time series analysis as the first step for analyzing remote sensing data, with spatial information being considered after all time series are classified. The *time-first* part brings a better understanding of changes in landscapes. Detecting and tracking seasonal and long-term trends becomes feasible, as well as identifying anomalous events or patterns in the data, such as wildfires, floods, or droughts.


The *space-later* part requires spatial data analysis that uses the neighborhood of each pixel. The classification assigned to each pixel by time series classification is taken as prior probability information. 
<!---
PEDRO: 7) a parte do "assigned to each pixel by time series classification" na verdade vem do time-first, mas nao foi falado nada no paragrafo anterior sobre isto
-->
Using additional data from the pixel's neighborhood, users obtain the posterior probability distribution per pixel. This Bayesian inference method allows combining the spatial with the temporal information for each pixel.  

## How `sits` works {.unnumbered}

The `sits` package uses satellite image time series for land classification, using  a *time-first, space-later* approach. In the data preparation part, collections of big Earth observation images are organized as data cubes. Each spatial location of a data cube is associated with a time series. Locations with known labels train a machine learning classifier, which classifies all time series of a data cube, as shown in Figure 1.
<!---
PEDRO: 8) "classifier, which classifies" -> classifier, which assigns classes/labels?
-->


```{r, echo = FALSE, out.width = "70%", out.height = "70%", fig.align="center", fig.cap="Using time series for land classification (source: authors)."}
knitr::include_graphics("images/sits_general_view.png")
```

The package provides tools for analysis, visualization, and classification of satellite image time series. Users follow a typical workflow:

1.  Select an analysis-ready data image collection on cloud providers such as AWS, Microsoft Planetary Computer, Digital Earth Africa, or Brazil Data Cube.
2.  Build a regular data cube using the chosen image collection.
3.  Obtain new bands and indices with operations on data cubes.
4.  Extract time series samples from the data cube to be used as training data.
5.  Perform quality control and filtering on the time series samples.
6.  Train a machine learning model using the extracted samples.
<!---
PEDRO: 9) "extracted samples" e' a mesma coisa de "Locations with known labels" (mais acima), certo? Talvez seja melhor usar o mesmo termo.
-->
7.  Classify the data cube using the model to get class probabilities for each pixel.
8.  Post-process the probability cube to remove outliers.
9.  Produce a labeled map from the post-processed probability cube.
10. Evaluate the accuracy of the classification using best practices.

Each workflow step corresponds to a function of the `sits` API, as shown in the table and figure below. These functions have convenient default parameters and behaviors. A single function builds machine learning (ML) models. The classification function processes big data cubes with efficient parallel processing. Since the `sits` API is simple to learn, users can achieve good results without in-depth knowledge about machine learning and parallel processing.

```{r, echo = FALSE}
library(kableExtra)

sits_api <- data.frame(
    API_function = c("sits_cube()", 
                     "sits_regularize()",
                     "sits_apply()",
                     "sits_get_data()",
                     "sits_train()", 
                     "sits_classify()", 
                     "sits_smooth()",
                     "sits_label_classification()", 
                     "sits_accuracy()"),
    Inputs = c("ARD image collection", 
               "Irregular data cube", 
               "Regular data cube", 
               "Data cube and sample locations",
               "Time series and ML method", 
               "ML classification model and regular data cube",
               "Probability cube", 
               "Post-processed probability cube",
               "Classified map and validation samples"),
    Output = c("Irregular data cube", 
               "Regular data cube",
               "Regular data cube with new bands and indices",
               "Time series",
               "ML classification model", 
               "Probability cube", 
               "Post-processed probability cube",
               "Classified map",
               "Accuracy assessment")
)
kableExtra::kbl(sits_api, 
                caption = "The sits API workflow for land classification",
                booktabs = TRUE) %>%
    kableExtra::kable_styling(position = "center", 
                              font_size = 14,
                              latex_options = c("scale_down", "HOLD_position")) %>% 
    kableExtra::column_spec(column = 1, monospace = TRUE, color =  "RawSienna")
```


```{r, echo = FALSE, out.width = "100%", out.height = "100%", fig.align="center", fig.cap="Main functions of the sits API (source: authors)."}

knitr::include_graphics("images/sits_api.png") 
```

## Creating a Data Cube {.unnumbered}

There are two kinds of data cubes in `sits`: (a) irregular data cubes generated by selecting image collections on cloud providers such as AWS and Planetary Computer; (b) regular data cubes with images fully covering a chosen area, where each image has the same spectral bands and spatial resolution, and images follow a set of adjacent and regular time intervals. Machine learning applications need regular data cubes. Please refer to Chapter "Earth observation data cubes" for further details.
<!---
PEDRO: 10) posso colocar links para os capitulos?
-->

The first steps in using `sits` are: (a) select an analysis-ready data image collection available in a cloud provider or stored locally using `sits_cube()`; (b) if the collection is not regular, use `sits_regularize()` to build a regular data cube.

This section shows how to build a data cube from local images already organized as a regular data cube. The data cube is composed of MODIS MOD13Q1 images for the Sinop region in Mato Grosso, Brazil. All images have indexes "NDVI" and "EVI" covering a one-year period from 2013-09-14 to 2014-08-29 (we use "year-month-day" for dates). There are 23 time instances, each covering a 16-day period. The data is available in the R package `sitsdata`.

To build a data cube from local files, users must provide information about the original source from which the data was obtained. In this case, `sits_cube()` needs the parameters:

(a) `source`, the cloud provider from where the data has been obtained (in this case, the Brazil Data Cube "BDC");
(b) `collection`, the collection of the cloud provider from where the images have been extracted. In this case, data comes from the MOD13Q1 collection 6; 
(c) `data_dir`, the local directory where the image files are stored; 
(d) `parse_info`, a vector of strings stating how file names store information on "tile", "band", and "date". In this case, local images are stored in files like `TERRA_MODIS_012010_EVI_2014-07-28.tif`. This file represents tile 012010, band "EVI", and date 2014-07-28.
<!---
PEDRO: 1) o separador aqui Ã© sempre "_", certo? O que acontece com X1, X2? Viram atributos ou sao ignorados?
-->

```{r, out.width = "100%", tidy="styler", fig.align = 'center', fig.cap="Color composite image MODIS cube for 2013-09-14 (red = EVI, green = NDVI, blue = EVI)."}
# Create a data cube object based on the information about the files
sinop <- sits_cube(
  source = "BDC", 
  collection  = "MOD13Q1-6",
  data_dir = system.file("extdata/sinop", package = "sitsdata"),  
  parse_info = c("X1", "X2", "tile", "band", "date")
)

# Plot the NDVI for the first date (2013-09-14)
plot(sinop, 
     band = "NDVI", 
     dates = "2013-09-14",
     palette = "RdYlGn"
)
```


The R object returned by `sits_cube()` contains the metadata describing the contents of the data cube. It includes data source and collection, satellite, sensor, tile in the collection, bounding box, projection, and list of files. Each file refers to one band of an image at one of the temporal instances of the cube.

```{r}
# Show the R object that describes the data cube
sinop
```

## The time series table {-}

<!---
PEDRO: 2) aqui o termo "table" e' usado como sinonimo de tibble, mas tibble ainda nao foi definido (so' veja que na saida do codigo abaixo aparece o termo tibble)
-->
To handle time series information, `sits` uses a tabular data structure. The example below shows a table with 1,218 time series obtained from MODIS MOD13Q1 images. Each series has four attributes: two bands ("NIR" and "MIR") and two indexes ("NDVI" and "EVI"). This data set is available in package `sitsdata`.

```{r}
# Load the MODIS samples for Mato Grosso from the "sitsdata" package
library(tibble)
library(sitsdata)
data("samples_matogrosso_mod13q1", package = "sitsdata")
samples_matogrosso_mod13q1[1:2,]
```

The data structure associated with the time series is a table that contains data and metadata. The first six columns contain the metadata: spatial and temporal information, the label assigned to the sample, and the data cube from where the data has been extracted. The `time_series` column contains the time series data for each spatiotemporal location. This data is also organized as a table, with a column with the dates and the other columns with the values for each spectral band. For more details on handling time series data, please see the "Working with time series" Chapter.

It is helpful to plot the dispersion of the time series. In what follows, for brevity, we will filter only one label ("Forest") and select one index ("NDVI"). Note that for filtering the label we use a function from `dplyr` package, while for selecting the index we use `sits_select()`.  The resulting plot shows all the time series associated with the label "Forest" and index "NDVI", highlighting the median and the first and third quartiles.

```{r, out.width = "80%", tidy="styler", fig.align = 'center', fig.cap="Joint plot of all samples in band NDVI for class Forest.", strip.white = FALSE}
samples_forest <- dplyr::filter(
    samples_matogrosso_mod13q1, 
    label == "Forest"
)
samples_forest_ndvi <- sits_select(
    samples_forest, 
    band = "NDVI"
)
plot(samples_forest_ndvi)
```

## Training a machine learning model {.unnumbered}

The next step is to train a machine learning (ML) model using `sits_train()`. It takes two inputs, `samples` (a time series table) and `ml_method` (a function that implements a machine learning algorithm). The result is a model that is used for classification. Each ML algorithm requires specific parameters that are user-controllable. For novice users, `sits` provides default parameters that produce good results. Please see the "Machine learning for data cubes" Chapter for more details.

Since the time series data has four attributes ("EVI", "NDVI", "NIR", and "MIR") and the data cube images have only two, we select the "NDVI" and "EVI" values and use the resulting data for training. To build the classification model, we use a random forest model called by the `sits_rfor()` function.
<!---
PEDRO: 3) tem uma regra em documentacoes de pacotes que diz que se o cÃ³digo tem () Ã© porque Ã© uma funcao, e portanto nao deveria ser seguido de "function". Essa regra sera seguida neste livro?
-->

```{r, out.width = "80%", tidy="styler", fig.align="center", fig.cap="Most relevant variables of trained random forests model."}
# Select the bands "NDVI", "EVI"
samples_2bands <- sits_select(
    data = samples_matogrosso_mod13q1, 
    bands = c("NDVI", "EVI"))

# Train a random forest model
rf_model <- sits_train(
    samples = samples_2bands, 
    ml_method = sits_rfor()
)
# Plot the most important variables of the model
plot(rf_model)
```

## Data cube classification {.unnumbered}

After training the machine learning model, the next step is to classify the data cube using `sits_classify()`. This function produces a set of raster probability maps, one for each class. For each of these maps, the value of a pixel is proportional to the probability that it belongs to the class. This function has two mandatory parameters: `data`, the data cube or time series tibble 
<!---
PEDRO: 4) veja que aqui ja esta chamando de tibble, nao mais de table
-->
to be classified; and `ml_model`, the trained ML model. Optional parameters include: (a) `multicores`, number of cores to be used; (b) `memsize`, RAM used in the classification; (c) `output_dir`, the directory where the classified raster files will be written. Details of the classification process are available in "Image classification in data cubes".

```{r, out.width = "90%", tidy="styler", fig.align = 'center', fig.cap = "Probability map for class Forest."}

# Classify the raster image
sinop_probs <- sits_classify(
    data = sinop, 
    ml_model = rf_model,
    multicores = 2,
    memsize = 8,
    output_dir = "./tempdir/chp3"
)
# Plot the probability cube for class Forest
plot(sinop_probs, labels = "Forest", palette = "BuGn")
```

After completing the classification, we plot the probability maps for class "Forest". Probability maps are helpful to visualize the degree of confidence the classifier assigns to the labels for each pixel. They can be used to produce uncertainty information and support active learning, as described in Chapter "Image classification in data cubes".

## Spatial smoothing {.unnumbered}

When working with big EO data, 
<!---
PEDRO: 5) nao definiu EO antes, nem big. EO e' definido em 04-datacubes.Rmd e depois so' e' usado em 09-rasterclassification.Rmd. big e' usado em varios lugares.
-->
there is much variability in each class. As a result, some pixels will be misclassified. These errors are more likely to occur in transition areas between classes. To address these problems, `sits_smooth()` takes a probability cube as input and  uses the class probabilities of each pixel's neighborhood to reduce labeling uncertainty. Plotting the smoothed probability map for class "Forest" shows that most outliers have been removed.

```{r, out.width = "90%",  tidy="styler", fig.align = 'center', fig.cap = "Smoothed probability map for class Forest."}
# Perform spatial smoothing
sinop_bayes <- sits_smooth(
    cube = sinop_probs,
    multicores = 2,
    memsize = 8,
    output_dir = "./tempdir/chp3"
)
plot(sinop_bayes, labels = c("Forest"), palette = "BuGn")
```

## Labeling a probability data cube {.unnumbered}

After removing outliers using local smoothing, the labeled classification map can be obtained using the function `sits_label_classification()`. This function assigns each pixel to the class with the highest probability.
\newpage

```{r, out.width = "100%", out.height = "75%", tidy="styler", fig.cap = "Classification map for Sinop.", fig.align="center"}

# Label the probability file 
sinop_map <- sits_label_classification(
    cube = sinop_bayes, 
    output_dir = "./tempdir/chp3"
)
plot(sinop_map, title = "Sinop Classification Map")
```

The resulting classification files can be read by QGIS. Links to the associated files are available in the `sinop_map` object in the nested table `file_info`.

```{r}
# Show the location of the classification file
sinop_map$file_info[[1]]
```

As shown in this "Introduction", `sits` provides an end-to-end API to land classification.
In what follows, each chapter provides a detailed description of the training, modeling, and classification workflow. 
